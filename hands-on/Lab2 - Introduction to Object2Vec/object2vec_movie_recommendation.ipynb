{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Introduction to SageMaker Object2Vec model for MovieLens recommendations\n",
    "\n",
    "\n",
    "1. [Background](#Background)\n",
    "1. [Data exploration and preparation](#Data-exploration-and-preparation)\n",
    "1. [Rating prediction task](#Rating-prediction-task)\n",
    "1. [Recommendation task](#Recommendation-task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "### Object2Vec\n",
    "*Object2Vec* is a highly customizable multi-purpose algorithm that can learn embeddings of pairs of objects. The embeddings are learned such that it preserves their pairwise **similarities** in the original space.\n",
    "- **Similarity** is user-defined: users need to provide the algorithm with pairs of objects that they define as similar (1) or dissimilar (0); alternatively, the users can define similarity in a continuous sense (provide a real-valued similarity score)\n",
    "- The learned embeddings can be used to efficiently compute nearest neighbors of objects, as well as to visualize natural clusters of related objects in the embedding space. In addition, the embeddings can also be used as features of the corresponding objects in downstream supervised tasks such as classification or regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this notebook example:\n",
    "We demonstrate how Object2Vec can be used to solve problems arising in recommendation systems. Specifically,\n",
    "\n",
    "- We provide the algorithm with (UserID, MovieID) pairs; for each such pair, we also provide a \"label\" that tells the algorithm whether the user and movie are similar or not\n",
    "\n",
    "     * When the labels are real-valued, we use the algorithm to predict the exact ratings of a movie given a user\n",
    "     * When the labels are binary, we use the algorithm to recommendation movies to users\n",
    "\n",
    "- The diagram below shows the customization of our model to the problem of predicting movie ratings, using a dataset that provides `(UserID, ItemID, Rating)` samples. Here, ratings are real-valued"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float:middle\" src=\"images/image_ml_rating.png\" width=\"480\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "We use the MovieLens 100k dataset: https://grouplens.org/datasets/movielens/100k/\n",
    "\n",
    "#### License\n",
    "Please be aware of the following requirements about ackonwledgment, copyright and availability, cited from the [data set description page](http://files.grouplens.org/datasets/movielens/ml-100k-README.txt).\n",
    ">The data set may be used for any research\n",
    "purposes under the following conditions:\n",
    "     * The user may not state or imply any endorsement from the\n",
    "       University of Minnesota or the GroupLens Research Group.\n",
    "     * The user must acknowledge the use of the data set in\n",
    "       publications resulting from the use of the data set\n",
    "       (see below for citation information).\n",
    "     * The user may not redistribute the data without separate\n",
    "       permission.\n",
    "     * The user may not use this information for any commercial or\n",
    "       revenue-bearing purposes without first obtaining permission\n",
    "       from a faculty member of the GroupLens Research Project at the\n",
    "       University of Minnesota.\n",
    "If you have any further questions or comments, please contact GroupLens \\<grouplens-info@cs.umn.edu\\>. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use cases\n",
    "\n",
    "- Task 1: Rating prediction (regression)\n",
    "- Task 2: Movie recommendation (classification)\n",
    "- Task 3: Nearest-neighbor movie retrieval in the learned embedding space (will do this in a Lambda function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before running the notebook\n",
    "- Please use a Python 3 kernel for the notebook (e.g. conda_python3).\n",
    "- Go to S3 and make a note of the name of the bucket you created for this Lab.\n",
    "- Please make sure you have `jsonlines` package installed (if not, you can run the command below to install it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::349934754982:role/service-role/AmazonSageMaker-ExecutionRole-20190918T150782\n",
      "CPU times: user 377 ms, sys: 36 ms, total: 413 ms\n",
      "Wall time: 1.23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "print(role)\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jsonlines in /home/ec2-user/anaconda3/envs/mxnet_p27/lib/python2.7/site-packages (1.2.0)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/mxnet_p27/lib/python2.7/site-packages (from jsonlines) (1.11.0)\n",
      "\u001b[31mtyping-extensions 3.7.4 has requirement typing>=3.7.4, but you'll have typing 3.6.4 which is incompatible.\u001b[0m\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install jsonlines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by importing the libraries needed to complete the Lab. Please note that customutil is a custom library included with this notebook. It provides utility methods for loading data, transforming data, and writing data. Take a look at the methods in `customutil.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv, jsonlines\n",
    "import numpy as np\n",
    "import copy\n",
    "import random\n",
    "import customutil as cu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploration and preparation\n",
    "Start by downloading the dataset and unzipping it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ml-100k.zip\n",
      "   creating: ml-100k/\n",
      "  inflating: ml-100k/allbut.pl       \n",
      "  inflating: ml-100k/mku.sh          \n",
      "  inflating: ml-100k/README          \n",
      "  inflating: ml-100k/u.data          \n",
      "  inflating: ml-100k/u.genre         \n",
      "  inflating: ml-100k/u.info          \n",
      "  inflating: ml-100k/u.item          \n",
      "  inflating: ml-100k/u.occupation    \n",
      "  inflating: ml-100k/u.user          \n",
      "  inflating: ml-100k/u1.base         \n",
      "  inflating: ml-100k/u1.test         \n",
      "  inflating: ml-100k/u2.base         \n",
      "  inflating: ml-100k/u2.test         \n",
      "  inflating: ml-100k/u3.base         \n",
      "  inflating: ml-100k/u3.test         \n",
      "  inflating: ml-100k/u4.base         \n",
      "  inflating: ml-100k/u4.test         \n",
      "  inflating: ml-100k/u5.base         \n",
      "  inflating: ml-100k/u5.test         \n",
      "  inflating: ml-100k/ua.base         \n",
      "  inflating: ml-100k/ua.test         \n",
      "  inflating: ml-100k/ub.base         \n",
      "  inflating: ml-100k/ub.test         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r",
      "  0 4808k    0 19993    0     0  18632      0  0:04:24  0:00:01  0:04:23 18632\r",
      " 18 4808k   18  889k    0     0   423k      0  0:00:11  0:00:02  0:00:09  423k\r",
      "100 4808k  100 4808k    0     0  1762k      0  0:00:02  0:00:02 --:--:-- 1762k\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "curl -o ml-100k.zip http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
    "unzip ml-100k.zip\n",
    "rm ml-100k.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to explore the data from two angles - from a per-user perspective and from a per-movie perspective. To achieve this, use the custom utility methods to:\n",
    "- Load the data from the CSV file\n",
    "- Shuffle the data\n",
    "- Re-format the data into a per-user set and a per-movie set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In file ml-100k/ua.base, there are 90570 ratings\n",
      "The ratings have mean: 3.52, median: 4.0, and variance: 1.27\n",
      "There are 943 unique users and 1680 unique movies\n",
      "In file ml-100k/ua.test, there are 9430 ratings\n",
      "The ratings have mean: 3.59, median: 4.0, and variance: 1.25\n",
      "There are 943 unique users and 1129 unique movies\n"
     ]
    }
   ],
   "source": [
    "# Set the data paths\n",
    "prefix = 'ml-100k'\n",
    "train_path = os.path.join(prefix, 'ua.base')\n",
    "valid_path = os.path.join(prefix, 'ua.test')\n",
    "\n",
    "# Load data and shuffle\n",
    "train_data_list = cu.load_csv_data(train_path, '\\t')\n",
    "random.shuffle(train_data_list)\n",
    "validation_data_list = cu.load_csv_data(valid_path, '\\t')\n",
    "random.shuffle(validation_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a per-user dataset and a per-movie dataset\n",
    "to_users_dict, to_movies_dict = cu.csv_to_augmented_data_dict(train_path, '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We perform some data exploration\n",
    "To gain a better understanding of the data we are working with, do some basic data exploration in three steps:\n",
    "1. Calculate some basic stats such as minimum, maximum, and mean to understand how many movies are watched per user, and to understand how many users watch a movie.\n",
    "2. Check if there are users who have watched very few movies, or movies which have been watched by very few users. It could be wise to remove these from the dataset.\n",
    "3. Plot some graphs to visually explore the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The min, max, and median 'movies per user' is 10, 727, and 55.0\n",
      "The min, max, and median 'users per movie' is 1, 495, and 25.0\n",
      "In the training set\n",
      "There are 213 users with no more than 20 movies\n",
      "There are 12 movies with no more than 2 user\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Users per movie')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate min, max, median of number of movies per user\n",
    "movies_per_user = [len(val) for key, val in to_users_dict.items()]\n",
    "print(\"The min, max, and median 'movies per user' is {}, {}, and {}\".format(np.amin(movies_per_user),\n",
    "                                                                        np.amax(movies_per_user),\n",
    "                                                                         np.median(movies_per_user)))\n",
    "# Calculate min, max, median of number of users per movie\n",
    "users_per_movie = [len(val) for key, val in to_movies_dict.items()]\n",
    "print(\"The min, max, and median 'users per movie' is {}, {}, and {}\".format(np.amin(users_per_movie),\n",
    "                                                                         np.amax(users_per_movie),\n",
    "                                                                          np.median(users_per_movie)))\n",
    "\n",
    "\n",
    "# Calculate how many users have watched less than a certain number of movies\n",
    "count = 0\n",
    "n_movies_lower_bound = 20\n",
    "for n_movies in movies_per_user:\n",
    "    if n_movies <= n_movies_lower_bound:\n",
    "        count += 1\n",
    "print(\"In the training set\")\n",
    "print('There are {} users with no more than {} movies'.format(count, n_movies_lower_bound))\n",
    "\n",
    "# Calculate how many movies have been watched by less than a certain threshold of users\n",
    "count = 0\n",
    "n_users_lower_bound = 2\n",
    "for n_users in users_per_movie:\n",
    "    if n_users <= n_users_lower_bound:\n",
    "        count += 1\n",
    "print('There are {} movies with no more than {} user'.format(count, n_users_lower_bound))\n",
    "\n",
    "# Generate histogram for the number of movies watched per user \n",
    "f = plt.figure(1)\n",
    "plt.hist(movies_per_user)\n",
    "plt.title(\"Movies per user\")\n",
    "\n",
    "# Generate histogram for the number of users who watched a movie\n",
    "g = plt.figure(2)\n",
    "plt.hist(users_per_movie)\n",
    "plt.title(\"Users per movie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the number of movies with an extremely small number of users (<3) is negligible compared to the total number of movies, we will not remove movies from the data set (same applies for users)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rating prediction task \n",
    "In the rating prediction task, the model will predict the rating that a user will give to a movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created train_r.jsonl jsonline file\n",
      "Created validation_r.jsonl jsonline file\n"
     ]
    }
   ],
   "source": [
    "# Save training and validation data locally for rating-prediction (regression) task.\n",
    "cu.write_data_list_to_jsonl(copy.deepcopy(train_data_list), 'train_r.jsonl')\n",
    "cu.write_data_list_to_jsonl(copy.deepcopy(validation_data_list), 'validation_r.jsonl')\n",
    "\n",
    "# Format the validation data for testing in the inference step later.\n",
    "valid_r_data, valid_r_label = cu.data_list_to_inference_format(copy.deepcopy(validation_data_list), binarize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to evaluate the performance.\n",
    "def get_mse_loss(res, labels):\n",
    "    if type(res) is dict:\n",
    "        res = res['predictions']\n",
    "    assert len(res)==len(labels), 'result and label length mismatch!'\n",
    "    loss = 0\n",
    "    for row, label in zip(res, labels):\n",
    "        if type(row)is dict:\n",
    "            loss += (row['scores'][0]-label)**2\n",
    "        else:\n",
    "            loss += (row-label)**2\n",
    "    return round(loss/float(len(labels)), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We first test the problem on two baseline algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline 1\n",
    "\n",
    "A naive approach to predict movie ratings on unseen data is to use the global average of the user predictions in the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Baseline 1 (global rating average) prediction is 3.52\n",
      "The validation mse loss of the Baseline 1 is 1.26\n"
     ]
    }
   ],
   "source": [
    "train_r_label = [row['label'] for row in copy.deepcopy(train_data_list)]\n",
    "\n",
    "bs1_prediction = round(np.mean(train_r_label), 2)\n",
    "print('The Baseline 1 (global rating average) prediction is {}'.format(bs1_prediction))\n",
    "print(\"The validation mse loss of the Baseline 1 is {}\".format(\n",
    "                                     get_mse_loss(len(valid_r_label)*[bs1_prediction], valid_r_label)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use a better baseline, which is to perform prediction on unseen data based on the user-averaged ratings of movies on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bs2_predictor(test_data, user_dict, is_classification=False, thres=3):\n",
    "    test_data = copy.deepcopy(test_data['instances'])\n",
    "    predictions = list()\n",
    "    for row in test_data:\n",
    "        userID = str(row[\"in0\"][0])\n",
    "        # predict movie ID based on local average of user's prediction\n",
    "        local_movies, local_ratings = zip(*user_dict[userID])\n",
    "        local_ratings = [float(score) for score in local_ratings]\n",
    "        predictions.append(np.mean(local_ratings))\n",
    "        if is_classification:\n",
    "            predictions[-1] = int(predictions[-1] > 3)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation loss of the Baseline 2 (user-based rating average) is 1.09\n"
     ]
    }
   ],
   "source": [
    "bs2_prediction = bs2_predictor(valid_r_data, to_users_dict, is_classification=False)\n",
    "print(\"The validation loss of the Baseline 2 (user-based rating average) is {}\".format(\n",
    "                                     get_mse_loss(bs2_prediction, valid_r_label)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will use *Object2Vec* to predict the movie ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training and inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define S3 bucket that hosts data and model, and upload data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3 \n",
    "import os\n",
    " \n",
    "input_prefix = 'object2vec/movielens/input'\n",
    "output_prefix = 'object2vec/movielens/output'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upload data to S3 and make data paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded train data to s3://sagemaker-ap-southeast-1-349934754982/object2vec/movielens/input/rating/train/train_r.jsonl and defined input path\n",
      "Uploaded validation data to s3://sagemaker-ap-southeast-1-349934754982/object2vec/movielens/input/rating/validation/validation_r.jsonl and defined input path\n",
      "('Trained model will be saved at', 's3://sagemaker-ap-southeast-1-349934754982/object2vec/movielens/output')\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.session import s3_input\n",
    "\n",
    "s3_client = boto3.client('s3')\n",
    "input_paths = {}\n",
    "output_path = os.path.join('s3://', bucket, output_prefix)\n",
    "\n",
    "for data_name in ['train', 'validation']:\n",
    "    pre_key = os.path.join(input_prefix, 'rating', str(data_name))\n",
    "    fname = '{}_r.jsonl'.format(data_name)\n",
    "    data_path = os.path.join('s3://', bucket, pre_key, fname)\n",
    "    s3_client.upload_file(fname, bucket, os.path.join(pre_key, fname))\n",
    "    input_paths[data_name] = s3_input(data_path, distribution='ShardedByS3Key', content_type='application/jsonlines')\n",
    "    print('Uploaded {} data to {} and defined input path'.format(data_name, data_path))\n",
    "\n",
    "print('Trained model will be saved at', output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get ObjectToVec algorithm image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::349934754982:role/service-role/AmazonSageMaker-ExecutionRole-20190918T150782\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "role = get_execution_role()\n",
    "print(role)\n",
    "\n",
    "## Get docker image of ObjectToVec algorithm\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "container = get_image_uri(boto3.Session().region_name, 'object2vec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We first define training hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"_kvstore\": \"device\",\n",
    "    \"_num_gpus\": \"auto\",\n",
    "    \"_num_kv_servers\": \"auto\",\n",
    "    \"bucket_width\": 0,\n",
    "    \"early_stopping_patience\": 3,\n",
    "    \"early_stopping_tolerance\": 0.01,\n",
    "    \"enc0_cnn_filter_width\": 3,\n",
    "    \"enc0_layers\": \"auto\",\n",
    "    \"enc0_max_seq_len\": 1,\n",
    "    \"enc0_network\": \"pooled_embedding\",\n",
    "    \"enc0_token_embedding_dim\": 300,\n",
    "    \"enc0_vocab_size\": 944,\n",
    "    \"enc1_layers\": \"auto\",\n",
    "    \"enc1_max_seq_len\": 1,\n",
    "    \"enc1_network\": \"pooled_embedding\",\n",
    "    \"enc1_token_embedding_dim\": 300,\n",
    "    \"enc1_vocab_size\": 1684,\n",
    "    \"enc_dim\": 1024,\n",
    "    \"epochs\": 20,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"mini_batch_size\": 64,\n",
    "    \"mlp_activation\": \"tanh\",\n",
    "    \"mlp_dim\": 256,\n",
    "    \"mlp_layers\": 1,\n",
    "    \"num_classes\": 2,\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"output_layer\": \"mean_squared_error\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-29 18:33:20 Starting - Starting the training job...\n",
      "2019-10-29 18:33:23 Starting - Launching requested ML instances...\n",
      "2019-10-29 18:34:20 Starting - Preparing the instances for training......\n",
      "2019-10-29 18:35:16 Downloading - Downloading input data...\n",
      "2019-10-29 18:35:44 Training - Downloading the training image....\u001b[31mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:26 INFO 139714520221504] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/default-input.json: {u'comparator_list': u'hadamard, concat, abs_diff', u'enc0_vocab_file': u'', u'output_layer': u'softmax', u'enc0_cnn_filter_width': 3, u'epochs': 30, u'mlp_dim': 512, u'enc0_freeze_pretrained_embedding': u'true', u'mlp_layers': 2, u'_num_kv_servers': u'auto', u'weight_decay': 0, u'enc0_pretrained_embedding_file': u'', u'token_embedding_storage_type': u'dense', u'enc0_token_embedding_dim': 300, u'tied_token_embedding_weight': u'false', u'learning_rate': 0.0004, u'enc1_cnn_filter_width': 3, u'negative_sampling_rate': 0, u'enc0_network': u'hcnn', u'enc1_layers': u'auto', u'early_stopping_patience': 3, u'optimizer': u'adam', u'_tuning_objective_metric': u'', u'early_stopping_tolerance': 0.01, u'dropout': 0, u'bucket_width': 0, u'enc_dim': 4096, u'enc1_vocab_file': u'', u'enc1_freeze_pretrained_embedding': u'true', u'enc0_layers': u'auto', u'mini_batch_size': 32, u'enc1_pretrained_embedding_file': u'', u'num_classes': 2, u'_num_gpus': u'auto', u'enc1_token_embedding_dim': 300, u'mlp_activation': u'linear', u'enc1_network': u'enc0', u'_kvstore': u'auto_gpu'}\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:26 INFO 139714520221504] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'output_layer': u'mean_squared_error', u'enc0_cnn_filter_width': u'3', u'epochs': u'20', u'mlp_dim': u'256', u'mlp_layers': u'1', u'_num_kv_servers': u'auto', u'mini_batch_size': u'64', u'enc0_token_embedding_dim': u'300', u'enc1_network': u'pooled_embedding', u'enc0_network': u'pooled_embedding', u'enc1_layers': u'auto', u'early_stopping_patience': u'3', u'optimizer': u'adam', u'enc1_max_seq_len': u'1', u'early_stopping_tolerance': u'0.01', u'learning_rate': u'0.001', u'bucket_width': u'0', u'enc_dim': u'1024', u'enc0_layers': u'auto', u'enc0_max_seq_len': u'1', u'num_classes': u'2', u'_num_gpus': u'auto', u'mlp_activation': u'tanh', u'enc1_token_embedding_dim': u'300', u'_kvstore': u'device', u'enc1_vocab_size': u'1684', u'enc0_vocab_size': u'944'}\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:26 INFO 139714520221504] Final configuration: {u'comparator_list': u'hadamard, concat, abs_diff', u'enc0_vocab_file': u'', u'output_layer': u'mean_squared_error', u'enc0_cnn_filter_width': u'3', u'epochs': u'20', u'mlp_dim': u'256', u'enc0_freeze_pretrained_embedding': u'true', u'mlp_layers': u'1', u'_num_kv_servers': u'auto', u'weight_decay': 0, u'enc0_pretrained_embedding_file': u'', u'enc0_max_seq_len': u'1', u'token_embedding_storage_type': u'dense', u'enc0_token_embedding_dim': u'300', u'tied_token_embedding_weight': u'false', u'learning_rate': u'0.001', u'enc1_cnn_filter_width': 3, u'negative_sampling_rate': 0, u'enc0_network': u'pooled_embedding', u'enc1_layers': u'auto', u'early_stopping_patience': u'3', u'optimizer': u'adam', u'enc1_max_seq_len': u'1', u'_tuning_objective_metric': u'', u'early_stopping_tolerance': u'0.01', u'dropout': 0, u'bucket_width': u'0', u'enc_dim': u'1024', u'enc1_vocab_file': u'', u'enc1_freeze_pretrained_embedding': u'true', u'enc0_layers': u'auto', u'mini_batch_size': u'64', u'enc1_pretrained_embedding_file': u'', u'num_classes': u'2', u'_num_gpus': u'auto', u'enc1_token_embedding_dim': u'300', u'mlp_activation': u'tanh', u'enc1_network': u'pooled_embedding', u'_kvstore': u'device', u'enc1_vocab_size': u'1684', u'enc0_vocab_size': u'944'}\u001b[0m\n",
      "\u001b[31mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:26 INFO 139714520221504] Using default worker.\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:26 INFO 139714520221504] Loaded iterator creator application/jsonlines for content type ('application/jsonlines', '1.0')\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:26 INFO 139714520221504] create_iter params {u'comparator_list': u'hadamard, concat, abs_diff', u'enc0_vocab_file': u'', u'output_layer': u'mean_squared_error', u'enc0_cnn_filter_width': u'3', u'epochs': u'20', u'mlp_dim': u'256', u'enc0_freeze_pretrained_embedding': u'true', u'mlp_layers': u'1', u'_num_kv_servers': u'auto', u'weight_decay': 0, u'enc0_pretrained_embedding_file': u'', u'enc0_max_seq_len': u'1', u'token_embedding_storage_type': u'dense', u'enc0_token_embedding_dim': u'300', u'tied_token_embedding_weight': u'false', u'learning_rate': u'0.001', u'enc1_cnn_filter_width': 3, u'negative_sampling_rate': 0, u'enc0_network': u'pooled_embedding', u'enc1_layers': u'auto', u'early_stopping_patience': u'3', u'optimizer': u'adam', u'enc1_max_seq_len': u'1', u'_tuning_objective_metric': u'', u'early_stopping_tolerance': u'0.01', u'dropout': 0, u'bucket_width': u'0', u'enc_dim': u'1024', u'enc1_vocab_file': u'', u'enc1_freeze_pretrained_embedding': u'true', u'enc0_layers': u'auto', u'mini_batch_size': u'64', u'enc1_pretrained_embedding_file': u'', u'num_classes': u'2', u'_num_gpus': u'auto', u'enc1_token_embedding_dim': u'300', u'mlp_activation': u'tanh', u'enc1_network': u'pooled_embedding', u'_kvstore': u'device', u'enc1_vocab_size': u'1684', u'enc0_vocab_size': u'944'}\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:26 INFO 139714520221504] create_iter content_params {}\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:26 INFO 139714520221504] Parameters of encoders: [{u'layers': u'auto', u'vocab_size': u'944', u'network': u'pooled_embedding', u'vocab_file': u'', u'cnn_filter_width': u'3', u'token_embedding_dim': u'300', u'max_seq_len': u'1', u'freeze_pretrained_embedding': u'true', u'pretrained_embedding_file': u''}, {u'layers': u'auto', u'vocab_size': u'1684', u'network': u'pooled_embedding', u'vocab_file': u'', u'cnn_filter_width': 3, u'token_embedding_dim': u'300', u'max_seq_len': u'1', u'freeze_pretrained_embedding': u'true', u'pretrained_embedding_file': u''}]\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:26 INFO 139714520221504] output_layer is set to mean_squared_error. Ignoring the hyperparameter 'num_classes'.\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:26 INFO 139714520221504] Inconsistent enc_dim and token_embedding_dim found for token-embedding-encoder: 1024 vs 300. Setting token embedding dim to be 1024\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:26 INFO 139714520221504] Inconsistent enc_dim and token_embedding_dim found for token-embedding-encoder: 1024 vs 300. Setting token embedding dim to be 1024\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:26 INFO 139714520221504] Encoder configs: [{'vocab_size': 944, 'enc_index': 0, 'pretrained_embedding_file_path': None, 'vocab_dict': None, 'token_embedding_dim': 1024, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'num_layers': 1, 'is_train': True, 'dropout': 0.0, 'pretrained_embedding_file': ''}, {'vocab_size': 1684, 'enc_index': 1, 'pretrained_embedding_file_path': None, 'vocab_dict': None, 'token_embedding_dim': 1024, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'num_layers': 1, 'is_train': True, 'dropout': 0.0, 'pretrained_embedding_file': ''}]\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:26 INFO 139714520221504] Config: {'comparator_list': ['hadamard', 'concat', 'abs_diff'], 'epochs': 20, 'mini_batch_size': 64, 'optimizer': 'adam', 'output_layer': 'mean_squared_error', 'token_embedding_storage_type': 'dense', 'mlp_dim': 256, 'early_stopping_tolerance': 0.01, 'dropout': 0.0, 'bucket_width': 0, 'enc_dim': 1024, 'negative_sampling_rate': 0, 'early_stopping_patience': 3, 'learning_rate': 0.001, 'max_seq_lens': [1, 1], 'tied_token_embedding_weight': False, 'enc_configs': [{'vocab_size': 944, 'enc_index': 0, 'pretrained_embedding_file_path': None, 'vocab_dict': None, 'token_embedding_dim': 1024, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'num_layers': 1, 'is_train': True, 'dropout': 0.0, 'pretrained_embedding_file': ''}, {'vocab_size': 1684, 'enc_index': 1, 'pretrained_embedding_file_path': None, 'vocab_dict': None, 'token_embedding_dim': 1024, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'num_layers': 1, 'is_train': True, 'dropout': 0.0, 'pretrained_embedding_file': ''}], 'mlp_layers': 1, 'weight_decay': 0.0, 'mlp_activation': 'tanh', 'num_classes': None}\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:26 INFO 139714520221504] use bucketing: False\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:26 INFO 139714520221504] Creating data iterator for /opt/ml/input/data/train\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[10/29/2019 18:36:29 INFO 139714520221504] Source words: 90570\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:29 INFO 139714520221504] Target words: 90570\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:29 INFO 139714520221504] Total: 90570 samples in 1 buckets\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:29 INFO 139714520221504] Bucket of (1, 1) : 90570 samples in 1415 batches of 64, approx 64.0 words/batch\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:29 INFO 139714520221504] 0 sentence pairs discarded\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:29 INFO 139714520221504] fill up mode: replicate\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:29 INFO 139714520221504] \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:29 INFO 139714520221504] Negative sampling not used\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:29 INFO 139714520221504] Replicating 54 random sentences from bucket (1, 1) to size it to multiple of 64\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:29 INFO 139714520221504] Bucket batch sizes: [BucketBatchSize(batch_size=64, average_words_per_batch=64)]\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:29 INFO 139714520221504] create_iter params {u'comparator_list': u'hadamard, concat, abs_diff', u'enc0_vocab_file': u'', u'output_layer': u'mean_squared_error', u'enc0_cnn_filter_width': u'3', u'epochs': u'20', u'mlp_dim': u'256', u'enc0_freeze_pretrained_embedding': u'true', u'mlp_layers': u'1', u'_num_kv_servers': u'auto', u'weight_decay': 0, u'enc0_pretrained_embedding_file': u'', u'enc0_max_seq_len': u'1', u'token_embedding_storage_type': u'dense', u'enc0_token_embedding_dim': u'300', u'tied_token_embedding_weight': u'false', u'learning_rate': u'0.001', u'enc1_cnn_filter_width': 3, u'negative_sampling_rate': 0, u'enc0_network': u'pooled_embedding', u'enc1_layers': u'auto', u'early_stopping_patience': u'3', u'optimizer': u'adam', u'enc1_max_seq_len': u'1', u'_tuning_objective_metric': u'', u'early_stopping_tolerance': u'0.01', u'dropout': 0, u'bucket_width': u'0', u'enc_dim': u'1024', u'enc1_vocab_file': u'', u'enc1_freeze_pretrained_embedding': u'true', u'enc0_layers': u'auto', u'mini_batch_size': u'64', u'enc1_pretrained_embedding_file': u'', u'num_classes': u'2', u'_num_gpus': u'auto', u'enc1_token_embedding_dim': u'300', u'mlp_activation': u'tanh', u'enc1_network': u'pooled_embedding', u'_kvstore': u'device', u'enc1_vocab_size': u'1684', u'enc0_vocab_size': u'944'}\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:29 INFO 139714520221504] create_iter content_params {}\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:29 INFO 139714520221504] Parameters of encoders: [{u'layers': u'auto', u'vocab_size': u'944', u'network': u'pooled_embedding', u'vocab_file': u'', u'cnn_filter_width': u'3', u'token_embedding_dim': u'300', u'max_seq_len': u'1', u'freeze_pretrained_embedding': u'true', u'pretrained_embedding_file': u''}, {u'layers': u'auto', u'vocab_size': u'1684', u'network': u'pooled_embedding', u'vocab_file': u'', u'cnn_filter_width': 3, u'token_embedding_dim': u'300', u'max_seq_len': u'1', u'freeze_pretrained_embedding': u'true', u'pretrained_embedding_file': u''}]\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:29 INFO 139714520221504] output_layer is set to mean_squared_error. Ignoring the hyperparameter 'num_classes'.\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:29 INFO 139714520221504] Inconsistent enc_dim and token_embedding_dim found for token-embedding-encoder: 1024 vs 300. Setting token embedding dim to be 1024\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:29 INFO 139714520221504] Inconsistent enc_dim and token_embedding_dim found for token-embedding-encoder: 1024 vs 300. Setting token embedding dim to be 1024\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:29 INFO 139714520221504] Encoder configs: [{'vocab_size': 944, 'enc_index': 0, 'pretrained_embedding_file_path': None, 'vocab_dict': None, 'token_embedding_dim': 1024, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'num_layers': 1, 'is_train': True, 'dropout': 0.0, 'pretrained_embedding_file': ''}, {'vocab_size': 1684, 'enc_index': 1, 'pretrained_embedding_file_path': None, 'vocab_dict': None, 'token_embedding_dim': 1024, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'num_layers': 1, 'is_train': True, 'dropout': 0.0, 'pretrained_embedding_file': ''}]\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:29 INFO 139714520221504] Config: {'comparator_list': ['hadamard', 'concat', 'abs_diff'], 'epochs': 20, 'mini_batch_size': 64, 'optimizer': 'adam', 'output_layer': 'mean_squared_error', 'token_embedding_storage_type': 'dense', 'mlp_dim': 256, 'early_stopping_tolerance': 0.01, 'dropout': 0.0, 'bucket_width': 0, 'enc_dim': 1024, 'negative_sampling_rate': 0, 'early_stopping_patience': 3, 'learning_rate': 0.001, 'max_seq_lens': [1, 1], 'tied_token_embedding_weight': False, 'enc_configs': [{'vocab_size': 944, 'enc_index': 0, 'pretrained_embedding_file_path': None, 'vocab_dict': None, 'token_embedding_dim': 1024, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'num_layers': 1, 'is_train': True, 'dropout': 0.0, 'pretrained_embedding_file': ''}, {'vocab_size': 1684, 'enc_index': 1, 'pretrained_embedding_file_path': None, 'vocab_dict': None, 'token_embedding_dim': 1024, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'num_layers': 1, 'is_train': True, 'dropout': 0.0, 'pretrained_embedding_file': ''}], 'mlp_layers': 1, 'weight_decay': 0.0, 'mlp_activation': 'tanh', 'num_classes': None}\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:29 INFO 139714520221504] use bucketing: False\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:29 INFO 139714520221504] Creating data iterator for /opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:29 INFO 139714520221504] Source words: 9430\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:29 INFO 139714520221504] Target words: 9430\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:29 INFO 139714520221504] Total: 9430 samples in 1 buckets\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:29 INFO 139714520221504] Bucket of (1, 1) : 9430 samples in 147 batches of 64, approx 64.0 words/batch\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:29 INFO 139714520221504] 0 sentence pairs discarded\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:29 INFO 139714520221504] fill up mode: replicate\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:29 INFO 139714520221504] \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:29 INFO 139714520221504] Negative sampling not used\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:29 INFO 139714520221504] Replicating 42 random sentences from bucket (1, 1) to size it to multiple of 64\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:29 INFO 139714520221504] Parameters of encoders: [{u'layers': u'auto', u'vocab_size': u'944', u'network': u'pooled_embedding', u'vocab_file': u'', u'cnn_filter_width': u'3', u'token_embedding_dim': u'300', u'max_seq_len': u'1', u'freeze_pretrained_embedding': u'true', u'pretrained_embedding_file': u''}, {u'layers': u'auto', u'vocab_size': u'1684', u'network': u'pooled_embedding', u'vocab_file': u'', u'cnn_filter_width': 3, u'token_embedding_dim': u'300', u'max_seq_len': u'1', u'freeze_pretrained_embedding': u'true', u'pretrained_embedding_file': u''}]\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:29 INFO 139714520221504] output_layer is set to mean_squared_error. Ignoring the hyperparameter 'num_classes'.\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:29 INFO 139714520221504] Inconsistent enc_dim and token_embedding_dim found for token-embedding-encoder: 1024 vs 300. Setting token embedding dim to be 1024\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:29 INFO 139714520221504] Inconsistent enc_dim and token_embedding_dim found for token-embedding-encoder: 1024 vs 300. Setting token embedding dim to be 1024\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:29 INFO 139714520221504] Encoder configs: [{'vocab_size': 944, 'enc_index': 0, 'pretrained_embedding_file_path': None, 'vocab_dict': None, 'token_embedding_dim': 1024, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'num_layers': 1, 'is_train': True, 'dropout': 0.0, 'pretrained_embedding_file': ''}, {'vocab_size': 1684, 'enc_index': 1, 'pretrained_embedding_file_path': None, 'vocab_dict': None, 'token_embedding_dim': 1024, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'num_layers': 1, 'is_train': True, 'dropout': 0.0, 'pretrained_embedding_file': ''}]\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:29 INFO 139714520221504] Config: {'comparator_list': ['hadamard', 'concat', 'abs_diff'], 'epochs': 20, 'mini_batch_size': 64, 'optimizer': 'adam', 'output_layer': 'mean_squared_error', 'token_embedding_storage_type': 'dense', 'mlp_dim': 256, 'early_stopping_tolerance': 0.01, 'dropout': 0.0, 'bucket_width': 0, 'enc_dim': 1024, 'negative_sampling_rate': 0, 'early_stopping_patience': 3, 'learning_rate': 0.001, 'max_seq_lens': [1, 1], 'tied_token_embedding_weight': False, 'enc_configs': [{'vocab_size': 944, 'enc_index': 0, 'pretrained_embedding_file_path': None, 'vocab_dict': None, 'token_embedding_dim': 1024, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'num_layers': 1, 'is_train': True, 'dropout': 0.0, 'pretrained_embedding_file': ''}, {'vocab_size': 1684, 'enc_index': 1, 'pretrained_embedding_file_path': None, 'vocab_dict': None, 'token_embedding_dim': 1024, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'num_layers': 1, 'is_train': True, 'dropout': 0.0, 'pretrained_embedding_file': ''}], 'mlp_layers': 1, 'weight_decay': 0.0, 'mlp_activation': 'tanh', 'num_classes': None}\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:29 INFO 139714520221504] Creating new state\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:29 INFO 139714520221504] params {u'comparator_list': u'hadamard, concat, abs_diff', u'enc0_vocab_file': u'', u'output_layer': u'mean_squared_error', u'enc0_cnn_filter_width': u'3', u'epochs': u'20', u'mlp_dim': u'256', u'enc0_freeze_pretrained_embedding': u'true', u'mlp_layers': u'1', u'_num_kv_servers': u'auto', u'weight_decay': 0, u'enc0_pretrained_embedding_file': u'', u'enc0_max_seq_len': u'1', u'token_embedding_storage_type': u'dense', u'enc0_token_embedding_dim': u'300', u'tied_token_embedding_weight': u'false', u'learning_rate': u'0.001', u'enc1_cnn_filter_width': 3, u'negative_sampling_rate': 0, u'enc0_network': u'pooled_embedding', u'enc1_layers': u'auto', u'early_stopping_patience': u'3', u'optimizer': u'adam', u'enc1_max_seq_len': u'1', u'_tuning_objective_metric': u'', u'early_stopping_tolerance': u'0.01', u'dropout': 0, u'bucket_width': u'0', u'enc_dim': u'1024', 'default_bucket_key': (1, 1), u'enc1_vocab_file': u'', u'enc1_freeze_pretrained_embedding': u'true', u'enc0_layers': u'auto', u'mini_batch_size': u'64', u'enc1_pretrained_embedding_file': u'', u'num_classes': u'2', u'_num_gpus': u'auto', u'enc1_token_embedding_dim': u'300', u'mlp_activation': u'tanh', u'enc1_network': u'pooled_embedding', u'_kvstore': u'device', u'enc1_vocab_size': u'1684', u'enc0_vocab_size': u'944'}\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:29 INFO 139714520221504] default_bucket_key (1, 1)\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:29 INFO 139714520221504] nvidia-smi took: 0.0251860618591 secs to identify 1 gpus\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:29 INFO 139714520221504] Number of GPUs being used: 1\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:29 INFO 139714520221504] context [gpu(0)]\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:29 INFO 139714520221504] Create Store: device\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:29 INFO 139714520221504] Number of GPUs being used: 1\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:29 WARNING 139714520221504] dense token embedding is used in a multi-gpu setting...consider changing 'token_embedding_storage_type' to 'row_sparse'\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:29 INFO 139714520221504] data_names: ['source', 'target']\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:29 INFO 139714520221504] label_names: ['out_layer_label']\u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mLayer (type)                                        Output Shape            Param #     Previous Layer                  \u001b[0m\n",
      "\u001b[31m========================================================================================================================\u001b[0m\n",
      "\u001b[31msource(null)                                        1                       0                                           \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31membed_0(Embedding)                                  1x1024                  0           source                          \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31m_not_equal_scalar0(_not_equal_scalar)               1                       0           source                          \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mreshape0(Reshape)                                   1x1                     0           _not_equal_scalar0              \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mbroadcast_mul0(broadcast_mul)                       1x1024                  0           embed_0                         \n",
      "                                                                                        reshape0                        \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31msum0(sum)                                           1024                    0           broadcast_mul0                  \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31msum1(sum)                                           1                       0           reshape0                        \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mzeros_like0(zeros_like)                             1                       0           sum1                            \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31m_equal0(_equal)                                     1                       0           sum1                            \n",
      "                                                                                        zeros_like0                     \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31m_plus0(elemwise_add)                                1                       0           sum1                            \n",
      "                                                                                        _equal0                         \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mbroadcast_div0(broadcast_div)                       1024                    0           sum0                            \n",
      "                                                                                        _plus0                          \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mdropout0(Dropout)                                   1024                    0           broadcast_div0                  \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31membed_1(Embedding)                                  1x1024                  0                                           \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31m_not_equal_scalar1(_not_equal_scalar)               1                       0                                           \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mreshape1(Reshape)                                   1x1                     0           _not_equal_scalar1              \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mbroadcast_mul1(broadcast_mul)                       1x1024                  0           embed_1                         \n",
      "                                                                                        reshape1                        \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31msum2(sum)                                           1024                    0           broadcast_mul1                  \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31msum3(sum)                                           1                       0           reshape1                        \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mzeros_like1(zeros_like)                             1                       0           sum3                            \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31m_equal1(_equal)                                     1                       0           sum3                            \n",
      "                                                                                        zeros_like1                     \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31m_plus1(elemwise_add)                                1                       0           sum3                            \n",
      "                                                                                        _equal1                         \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mbroadcast_div1(broadcast_div)                       1024                    0           sum2                            \n",
      "                                                                                        _plus1                          \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mdropout1(Dropout)                                   1024                    0           broadcast_div1                  \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31m_mul0(elemwise_mul)                                 1024                    0           dropout0                        \n",
      "                                                                                        dropout1                        \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31m_minus0(elemwise_sub)                               1024                    0           dropout0                        \n",
      "                                                                                        dropout1                        \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mabs0(abs)                                           1024                    0           _minus0                         \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mconcat0(Concat)                                     4096                    0           _mul0                           \n",
      "                                                                                        dropout0                        \n",
      "                                                                                        dropout1                        \n",
      "                                                                                        abs0                            \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mmlp_fc0(FullyConnected)                             256                     1048832     concat0                         \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mactivation0(Activation)                             256                     0           mlp_fc0                         \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mdropout2(Dropout)                                   256                     0           activation0                     \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31moutput_layer(FullyConnected)                        1                       257         dropout2                        \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mout_layer(LinearRegressionOutput)                   1                       0           output_layer                    \u001b[0m\n",
      "\u001b[31m========================================================================================================================\u001b[0m\n",
      "\u001b[31mTotal params: 1049089\u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:29 INFO 139714520221504] data_shapes [DataDesc[source,(64, 1),<type 'numpy.float32'>,NTC], DataDesc[target,(64, 1),<type 'numpy.float32'>,NTC]]\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:29 INFO 139714520221504] label_shapes [DataDesc[out_layer_label,(64,),<type 'numpy.float32'>,NTC]]\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:29 INFO 139714520221504] fixed_param_names: []\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:29 INFO 139714520221504] Initialized BucketingPlus Module\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:34 INFO 139714520221504] arg_params keys for module initialization: []\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:34 INFO 139714520221504] all params:['output_layer_weight', 'mlp_fc0_weight', 'mlp_fc0_bias', 'output_layer_bias', 'embed_1_weight', 'embed_0_weight']\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"initialize.time\": {\"count\": 1, \"max\": 4900.4058837890625, \"sum\": 4900.4058837890625, \"min\": 4900.4058837890625}}, \"EndTime\": 1572374194.306643, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1572374186.19488}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}}, \"EndTime\": 1572374194.306987, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1572374194.30678}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:34 INFO 139714520221504] Epoch: 0, batches: 100, num_examples: 6400, 15107.6 samples/sec, epoch time so far: 0:00:00.423628\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:34 INFO 139714520221504] #011Training metrics: mean_squared_error: 1.638 mean_absolute_error: 0.991 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:35 INFO 139714520221504] Epoch: 0, batches: 200, num_examples: 12800, 15575.7 samples/sec, epoch time so far: 0:00:00.821791\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:35 INFO 139714520221504] #011Training metrics: mean_squared_error: 1.374 mean_absolute_error: 0.916 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:35 INFO 139714520221504] Epoch: 0, batches: 300, num_examples: 19200, 15767.8 samples/sec, epoch time so far: 0:00:01.217669\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:35 INFO 139714520221504] #011Training metrics: mean_squared_error: 1.263 mean_absolute_error: 0.881 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:35 INFO 139714520221504] Epoch: 0, batches: 400, num_examples: 25600, 15842.2 samples/sec, epoch time so far: 0:00:01.615937\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:35 INFO 139714520221504] #011Training metrics: mean_squared_error: 1.207 mean_absolute_error: 0.865 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:36 INFO 139714520221504] Epoch: 0, batches: 500, num_examples: 32000, 15904.3 samples/sec, epoch time so far: 0:00:02.012032\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:36 INFO 139714520221504] #011Training metrics: mean_squared_error: 1.172 mean_absolute_error: 0.854 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:36 INFO 139714520221504] Epoch: 0, batches: 600, num_examples: 38400, 15760.9 samples/sec, epoch time so far: 0:00:02.436416\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:36 INFO 139714520221504] #011Training metrics: mean_squared_error: 1.142 mean_absolute_error: 0.844 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:37 INFO 139714520221504] Epoch: 0, batches: 700, num_examples: 44800, 15820.4 samples/sec, epoch time so far: 0:00:02.831785\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:37 INFO 139714520221504] #011Training metrics: mean_squared_error: 1.117 mean_absolute_error: 0.835 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:37 INFO 139714520221504] Epoch: 0, batches: 800, num_examples: 51200, 15860.7 samples/sec, epoch time so far: 0:00:03.228099\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:37 INFO 139714520221504] #011Training metrics: mean_squared_error: 1.101 mean_absolute_error: 0.829 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:38 INFO 139714520221504] Epoch: 0, batches: 900, num_examples: 57600, 15808.3 samples/sec, epoch time so far: 0:00:03.643663\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:38 INFO 139714520221504] #011Training metrics: mean_squared_error: 1.080 mean_absolute_error: 0.821 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:38 INFO 139714520221504] Epoch: 0, batches: 1000, num_examples: 64000, 15841.0 samples/sec, epoch time so far: 0:00:04.040159\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:38 INFO 139714520221504] #011Training metrics: mean_squared_error: 1.065 mean_absolute_error: 0.816 \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2019-10-29 18:36:22 Training - Training image download completed. Training in progress.\u001b[31m[10/29/2019 18:36:38 INFO 139714520221504] Epoch: 0, batches: 1100, num_examples: 70400, 15862.6 samples/sec, epoch time so far: 0:00:04.438125\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:38 INFO 139714520221504] #011Training metrics: mean_squared_error: 1.052 mean_absolute_error: 0.810 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:39 INFO 139714520221504] Epoch: 0, batches: 1200, num_examples: 76800, 15885.4 samples/sec, epoch time so far: 0:00:04.834640\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:39 INFO 139714520221504] #011Training metrics: mean_squared_error: 1.043 mean_absolute_error: 0.807 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:39 INFO 139714520221504] Epoch: 0, batches: 1300, num_examples: 83200, 15905.9 samples/sec, epoch time so far: 0:00:05.230759\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:39 INFO 139714520221504] #011Training metrics: mean_squared_error: 1.033 mean_absolute_error: 0.804 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:39 INFO 139714520221504] Epoch: 0, batches: 1400, num_examples: 89600, 15919.5 samples/sec, epoch time so far: 0:00:05.628320\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:39 INFO 139714520221504] #011Training metrics: mean_squared_error: 1.022 mean_absolute_error: 0.800 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:40 INFO 139714520221504] **************\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:40 INFO 139714520221504] Completed Epoch: 0, time taken: 0:00:05.692699\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:40 INFO 139714520221504] Epoch 0 Training metrics:   mean_squared_error: 1.021 mean_absolute_error: 0.799 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:40 INFO 139714520221504] #quality_metric: host=algo-1, epoch=0, train mean_squared_error <loss>=1.02100443688\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:40 INFO 139714520221504] Epoch 0 Validation metrics: mean_squared_error: 0.980 mean_absolute_error: 0.801 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:40 INFO 139714520221504] #quality_metric: host=algo-1, epoch=0, validation mean_squared_error <loss>=0.979866780139\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:40 INFO 139714520221504] **************\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"epochs\": {\"count\": 1, \"max\": 20, \"sum\": 20.0, \"min\": 20}, \"early_stop.time\": {\"count\": 1, \"max\": 0.2810955047607422, \"sum\": 0.2810955047607422, \"min\": 0.2810955047607422}, \"update.time\": {\"count\": 1, \"max\": 5885.377883911133, \"sum\": 5885.377883911133, \"min\": 5885.377883911133}}, \"EndTime\": 1572374200.248986, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1572374194.306724}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:40 INFO 139714520221504] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1416, \"sum\": 1416.0, \"min\": 1416}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1416, \"sum\": 1416.0, \"min\": 1416}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90624, \"sum\": 90624.0, \"min\": 90624}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1416, \"sum\": 1416.0, \"min\": 1416}, \"Total Records Seen\": {\"count\": 1, \"max\": 90624, \"sum\": 90624.0, \"min\": 90624}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90624, \"sum\": 90624.0, \"min\": 90624}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1572374200.24927, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\", \"epoch\": 0}, \"StartTime\": 1572374194.363587}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:40 INFO 139714520221504] #throughput_metric: host=algo-1, train throughput=15396.9553405 records/second\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:40 INFO 139714520221504] Epoch: 1, batches: 100, num_examples: 6400, 16154.3 samples/sec, epoch time so far: 0:00:00.396179\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:40 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.713 mean_absolute_error: 0.664 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:41 INFO 139714520221504] Epoch: 1, batches: 200, num_examples: 12800, 16104.5 samples/sec, epoch time so far: 0:00:00.794810\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:41 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.712 mean_absolute_error: 0.664 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:41 INFO 139714520221504] Epoch: 1, batches: 300, num_examples: 19200, 16131.2 samples/sec, epoch time so far: 0:00:01.190239\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:41 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.709 mean_absolute_error: 0.664 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:41 INFO 139714520221504] Epoch: 1, batches: 400, num_examples: 25600, 16140.4 samples/sec, epoch time so far: 0:00:01.586087\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:41 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.701 mean_absolute_error: 0.659 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:42 INFO 139714520221504] Epoch: 1, batches: 500, num_examples: 32000, 16142.5 samples/sec, epoch time so far: 0:00:01.982341\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:42 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.698 mean_absolute_error: 0.657 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:42 INFO 139714520221504] Epoch: 1, batches: 600, num_examples: 38400, 16145.3 samples/sec, epoch time so far: 0:00:02.378397\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:42 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.692 mean_absolute_error: 0.654 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:43 INFO 139714520221504] Epoch: 1, batches: 700, num_examples: 44800, 16012.8 samples/sec, epoch time so far: 0:00:02.797755\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:43 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.687 mean_absolute_error: 0.652 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:43 INFO 139714520221504] Epoch: 1, batches: 800, num_examples: 51200, 16028.1 samples/sec, epoch time so far: 0:00:03.194398\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:43 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.684 mean_absolute_error: 0.650 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:43 INFO 139714520221504] Epoch: 1, batches: 900, num_examples: 57600, 15830.6 samples/sec, epoch time so far: 0:00:03.638531\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:43 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.678 mean_absolute_error: 0.647 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:44 INFO 139714520221504] Epoch: 1, batches: 1000, num_examples: 64000, 15604.1 samples/sec, epoch time so far: 0:00:04.101482\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:44 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.674 mean_absolute_error: 0.645 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:44 INFO 139714520221504] Epoch: 1, batches: 1100, num_examples: 70400, 15496.7 samples/sec, epoch time so far: 0:00:04.542893\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:44 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.670 mean_absolute_error: 0.643 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:45 INFO 139714520221504] Epoch: 1, batches: 1200, num_examples: 76800, 15546.0 samples/sec, epoch time so far: 0:00:04.940188\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:45 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.667 mean_absolute_error: 0.641 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:45 INFO 139714520221504] Epoch: 1, batches: 1300, num_examples: 83200, 15591.0 samples/sec, epoch time so far: 0:00:05.336406\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:45 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.664 mean_absolute_error: 0.640 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:46 INFO 139714520221504] Epoch: 1, batches: 1400, num_examples: 89600, 15628.1 samples/sec, epoch time so far: 0:00:05.733279\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:46 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.661 mean_absolute_error: 0.639 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:46 INFO 139714520221504] **************\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:46 INFO 139714520221504] Completed Epoch: 1, time taken: 0:00:05.796953\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:46 INFO 139714520221504] Epoch 1 Training metrics:   mean_squared_error: 0.661 mean_absolute_error: 0.638 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:46 INFO 139714520221504] #quality_metric: host=algo-1, epoch=1, train mean_squared_error <loss>=0.661103346211\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:46 INFO 139714520221504] Epoch 1 Validation metrics: mean_squared_error: 0.986 mean_absolute_error: 0.792 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:46 INFO 139714520221504] #quality_metric: host=algo-1, epoch=1, validation mean_squared_error <loss>=0.985973315867\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:46 INFO 139714520221504] **************\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"early_stop.time\": {\"count\": 1, \"max\": 0.026941299438476562, \"sum\": 0.026941299438476562, \"min\": 0.026941299438476562}, \"update.time\": {\"count\": 1, \"max\": 5986.995220184326, \"sum\": 5986.995220184326, \"min\": 5986.995220184326}}, \"EndTime\": 1572374206.261503, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1572374200.249071}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:46 INFO 139714520221504] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1416, \"sum\": 1416.0, \"min\": 1416}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1416, \"sum\": 1416.0, \"min\": 1416}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90624, \"sum\": 90624.0, \"min\": 90624}, \"Total Batches Seen\": {\"count\": 1, \"max\": 2832, \"sum\": 2832.0, \"min\": 2832}, \"Total Records Seen\": {\"count\": 1, \"max\": 181248, \"sum\": 181248.0, \"min\": 181248}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90624, \"sum\": 90624.0, \"min\": 90624}, \"Reset Count\": {\"count\": 1, \"max\": 2, \"sum\": 2.0, \"min\": 2}}, \"EndTime\": 1572374206.261781, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\", \"epoch\": 1}, \"StartTime\": 1572374200.274485}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:46 INFO 139714520221504] #throughput_metric: host=algo-1, train throughput=15135.6439777 records/second\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:46 INFO 139714520221504] Epoch: 2, batches: 100, num_examples: 6400, 16250.1 samples/sec, epoch time so far: 0:00:00.393844\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:46 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.266 mean_absolute_error: 0.396 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:47 INFO 139714520221504] Epoch: 2, batches: 200, num_examples: 12800, 16119.1 samples/sec, epoch time so far: 0:00:00.794089\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:47 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.262 mean_absolute_error: 0.394 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:47 INFO 139714520221504] Epoch: 2, batches: 300, num_examples: 19200, 16127.4 samples/sec, epoch time so far: 0:00:01.190524\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:47 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.260 mean_absolute_error: 0.391 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:47 INFO 139714520221504] Epoch: 2, batches: 400, num_examples: 25600, 16127.2 samples/sec, epoch time so far: 0:00:01.587384\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:47 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.262 mean_absolute_error: 0.393 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:48 INFO 139714520221504] Epoch: 2, batches: 500, num_examples: 32000, 15984.3 samples/sec, epoch time so far: 0:00:02.001967\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:48 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.263 mean_absolute_error: 0.393 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:48 INFO 139714520221504] Epoch: 2, batches: 600, num_examples: 38400, 16020.6 samples/sec, epoch time so far: 0:00:02.396917\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:48 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.265 mean_absolute_error: 0.394 \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[10/29/2019 18:36:49 INFO 139714520221504] Epoch: 2, batches: 700, num_examples: 44800, 16019.3 samples/sec, epoch time so far: 0:00:02.796621\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:49 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.265 mean_absolute_error: 0.394 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:49 INFO 139714520221504] Epoch: 2, batches: 800, num_examples: 51200, 16036.0 samples/sec, epoch time so far: 0:00:03.192818\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:49 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.268 mean_absolute_error: 0.397 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:49 INFO 139714520221504] Epoch: 2, batches: 900, num_examples: 57600, 16022.4 samples/sec, epoch time so far: 0:00:03.594969\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:49 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.269 mean_absolute_error: 0.398 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:50 INFO 139714520221504] Epoch: 2, batches: 1000, num_examples: 64000, 16037.9 samples/sec, epoch time so far: 0:00:03.990555\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:50 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.271 mean_absolute_error: 0.399 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:50 INFO 139714520221504] Epoch: 2, batches: 1100, num_examples: 70400, 16048.5 samples/sec, epoch time so far: 0:00:04.386703\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:50 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.272 mean_absolute_error: 0.401 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:51 INFO 139714520221504] Epoch: 2, batches: 1200, num_examples: 76800, 16050.8 samples/sec, epoch time so far: 0:00:04.784798\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:51 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.272 mean_absolute_error: 0.401 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:51 INFO 139714520221504] Epoch: 2, batches: 1300, num_examples: 83200, 16054.7 samples/sec, epoch time so far: 0:00:05.182295\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:51 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.274 mean_absolute_error: 0.402 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:51 INFO 139714520221504] Epoch: 2, batches: 1400, num_examples: 89600, 16062.2 samples/sec, epoch time so far: 0:00:05.578307\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:51 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.276 mean_absolute_error: 0.403 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:51 INFO 139714520221504] **************\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:51 INFO 139714520221504] Completed Epoch: 2, time taken: 0:00:05.642488\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:51 INFO 139714520221504] Epoch 2 Training metrics:   mean_squared_error: 0.275 mean_absolute_error: 0.403 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:51 INFO 139714520221504] #quality_metric: host=algo-1, epoch=2, train mean_squared_error <loss>=0.275433086459\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:52 INFO 139714520221504] Epoch 2 Validation metrics: mean_squared_error: 0.959 mean_absolute_error: 0.763 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:52 INFO 139714520221504] #quality_metric: host=algo-1, epoch=2, validation mean_squared_error <loss>=0.959191136666\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:52 INFO 139714520221504] **************\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"early_stop.time\": {\"count\": 1, \"max\": 2.313852310180664, \"sum\": 2.313852310180664, \"min\": 2.313852310180664}, \"update.time\": {\"count\": 1, \"max\": 5835.078001022339, \"sum\": 5835.078001022339, \"min\": 5835.078001022339}}, \"EndTime\": 1572374212.101408, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1572374206.261601}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:52 INFO 139714520221504] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1416, \"sum\": 1416.0, \"min\": 1416}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1416, \"sum\": 1416.0, \"min\": 1416}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90624, \"sum\": 90624.0, \"min\": 90624}, \"Total Batches Seen\": {\"count\": 1, \"max\": 4248, \"sum\": 4248.0, \"min\": 4248}, \"Total Records Seen\": {\"count\": 1, \"max\": 271872, \"sum\": 271872.0, \"min\": 271872}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90624, \"sum\": 90624.0, \"min\": 90624}, \"Reset Count\": {\"count\": 1, \"max\": 3, \"sum\": 3.0, \"min\": 3}}, \"EndTime\": 1572374212.101703, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\", \"epoch\": 2}, \"StartTime\": 1572374206.266312}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:52 INFO 139714520221504] #throughput_metric: host=algo-1, train throughput=15529.6813801 records/second\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:52 INFO 139714520221504] Epoch: 3, batches: 100, num_examples: 6400, 16159.9 samples/sec, epoch time so far: 0:00:00.396041\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:52 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.176 mean_absolute_error: 0.310 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:52 INFO 139714520221504] Epoch: 3, batches: 200, num_examples: 12800, 16140.3 samples/sec, epoch time so far: 0:00:00.793045\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:52 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.170 mean_absolute_error: 0.303 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:53 INFO 139714520221504] Epoch: 3, batches: 300, num_examples: 19200, 15909.7 samples/sec, epoch time so far: 0:00:01.206808\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:53 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.169 mean_absolute_error: 0.302 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:53 INFO 139714520221504] Epoch: 3, batches: 400, num_examples: 25600, 15970.3 samples/sec, epoch time so far: 0:00:01.602978\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:53 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.169 mean_absolute_error: 0.302 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:54 INFO 139714520221504] Epoch: 3, batches: 500, num_examples: 32000, 15987.1 samples/sec, epoch time so far: 0:00:02.001610\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:54 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.167 mean_absolute_error: 0.300 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:54 INFO 139714520221504] Epoch: 3, batches: 600, num_examples: 38400, 16017.3 samples/sec, epoch time so far: 0:00:02.397411\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:54 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.166 mean_absolute_error: 0.300 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:54 INFO 139714520221504] Epoch: 3, batches: 700, num_examples: 44800, 16039.4 samples/sec, epoch time so far: 0:00:02.793125\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:54 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.167 mean_absolute_error: 0.302 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:55 INFO 139714520221504] Epoch: 3, batches: 800, num_examples: 51200, 16054.8 samples/sec, epoch time so far: 0:00:03.189079\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:55 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.166 mean_absolute_error: 0.302 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:55 INFO 139714520221504] Epoch: 3, batches: 900, num_examples: 57600, 16061.9 samples/sec, epoch time so far: 0:00:03.586121\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:55 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.166 mean_absolute_error: 0.302 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:56 INFO 139714520221504] Epoch: 3, batches: 1000, num_examples: 64000, 16057.7 samples/sec, epoch time so far: 0:00:03.985623\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:56 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.166 mean_absolute_error: 0.303 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:56 INFO 139714520221504] Epoch: 3, batches: 1100, num_examples: 70400, 16070.9 samples/sec, epoch time so far: 0:00:04.380579\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:56 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.166 mean_absolute_error: 0.303 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:56 INFO 139714520221504] Epoch: 3, batches: 1200, num_examples: 76800, 16080.2 samples/sec, epoch time so far: 0:00:04.776066\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:56 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.166 mean_absolute_error: 0.303 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:57 INFO 139714520221504] Epoch: 3, batches: 1300, num_examples: 83200, 16084.5 samples/sec, epoch time so far: 0:00:05.172687\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:57 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.166 mean_absolute_error: 0.304 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:57 INFO 139714520221504] Epoch: 3, batches: 1400, num_examples: 89600, 16094.1 samples/sec, epoch time so far: 0:00:05.567274\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:57 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.167 mean_absolute_error: 0.305 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:57 INFO 139714520221504] **************\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:57 INFO 139714520221504] Completed Epoch: 3, time taken: 0:00:05.630720\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:57 INFO 139714520221504] Epoch 3 Training metrics:   mean_squared_error: 0.167 mean_absolute_error: 0.305 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:57 INFO 139714520221504] #quality_metric: host=algo-1, epoch=3, train mean_squared_error <loss>=0.166711450765\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:57 INFO 139714520221504] Epoch 3 Validation metrics: mean_squared_error: 0.952 mean_absolute_error: 0.773 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:57 INFO 139714520221504] #quality_metric: host=algo-1, epoch=3, validation mean_squared_error <loss>=0.952157629704\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:57 INFO 139714520221504] **************\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:57 INFO 139714520221504] patience losses: [0.9798667801393045, 0.9859733158672178, 0.9591911366662463]\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:57 INFO 139714520221504] min patience losses: 0.959191136666\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:57 INFO 139714520221504] current loss: 0.952157629704\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:57 INFO 139714520221504] absolute loss difference: 0.00703350696209\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:57 INFO 139714520221504] Bad epoch: loss has not improved (enough). Bad count:1\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"early_stop.time\": {\"count\": 1, \"max\": 2.7899742126464844, \"sum\": 2.7899742126464844, \"min\": 2.7899742126464844}, \"update.time\": {\"count\": 1, \"max\": 5823.261022567749, \"sum\": 5823.261022567749, \"min\": 5823.261022567749}}, \"EndTime\": 1572374217.948527, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1572374212.101489}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:57 INFO 139714520221504] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1416, \"sum\": 1416.0, \"min\": 1416}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1416, \"sum\": 1416.0, \"min\": 1416}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90624, \"sum\": 90624.0, \"min\": 90624}, \"Total Batches Seen\": {\"count\": 1, \"max\": 5664, \"sum\": 5664.0, \"min\": 5664}, \"Total Records Seen\": {\"count\": 1, \"max\": 362496, \"sum\": 362496.0, \"min\": 362496}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90624, \"sum\": 90624.0, \"min\": 90624}, \"Reset Count\": {\"count\": 1, \"max\": 4, \"sum\": 4.0, \"min\": 4}}, \"EndTime\": 1572374217.948799, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\", \"epoch\": 3}, \"StartTime\": 1572374212.125238}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:57 INFO 139714520221504] #throughput_metric: host=algo-1, train throughput=15561.1960342 records/second\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:58 INFO 139714520221504] Epoch: 4, batches: 100, num_examples: 6400, 15577.5 samples/sec, epoch time so far: 0:00:00.410849\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:58 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.125 mean_absolute_error: 0.265 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:58 INFO 139714520221504] Epoch: 4, batches: 200, num_examples: 12800, 15870.8 samples/sec, epoch time so far: 0:00:00.806512\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:58 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.121 mean_absolute_error: 0.260 \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[10/29/2019 18:36:59 INFO 139714520221504] Epoch: 4, batches: 300, num_examples: 19200, 15924.5 samples/sec, epoch time so far: 0:00:01.205689\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:59 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.116 mean_absolute_error: 0.254 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:59 INFO 139714520221504] Epoch: 4, batches: 400, num_examples: 25600, 15980.6 samples/sec, epoch time so far: 0:00:01.601945\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:59 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.113 mean_absolute_error: 0.252 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:59 INFO 139714520221504] Epoch: 4, batches: 500, num_examples: 32000, 15999.4 samples/sec, epoch time so far: 0:00:02.000070\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:36:59 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.111 mean_absolute_error: 0.251 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:00 INFO 139714520221504] Epoch: 4, batches: 600, num_examples: 38400, 16034.7 samples/sec, epoch time so far: 0:00:02.394813\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:00 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.111 mean_absolute_error: 0.251 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:00 INFO 139714520221504] Epoch: 4, batches: 700, num_examples: 44800, 16045.7 samples/sec, epoch time so far: 0:00:02.792033\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:00 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.111 mean_absolute_error: 0.251 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:01 INFO 139714520221504] Epoch: 4, batches: 800, num_examples: 51200, 16047.9 samples/sec, epoch time so far: 0:00:03.190442\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:01 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.111 mean_absolute_error: 0.251 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:01 INFO 139714520221504] Epoch: 4, batches: 900, num_examples: 57600, 16063.3 samples/sec, epoch time so far: 0:00:03.585816\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:01 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.111 mean_absolute_error: 0.251 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:01 INFO 139714520221504] Epoch: 4, batches: 1000, num_examples: 64000, 16043.6 samples/sec, epoch time so far: 0:00:03.989121\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:01 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.111 mean_absolute_error: 0.251 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:02 INFO 139714520221504] Epoch: 4, batches: 1100, num_examples: 70400, 16047.3 samples/sec, epoch time so far: 0:00:04.387026\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:02 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.111 mean_absolute_error: 0.251 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:02 INFO 139714520221504] Epoch: 4, batches: 1200, num_examples: 76800, 16059.4 samples/sec, epoch time so far: 0:00:04.782258\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:02 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.111 mean_absolute_error: 0.251 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:03 INFO 139714520221504] Epoch: 4, batches: 1300, num_examples: 83200, 16065.2 samples/sec, epoch time so far: 0:00:05.178908\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:03 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.111 mean_absolute_error: 0.252 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:03 INFO 139714520221504] Epoch: 4, batches: 1400, num_examples: 89600, 16024.5 samples/sec, epoch time so far: 0:00:05.591434\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:03 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.112 mean_absolute_error: 0.253 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:03 INFO 139714520221504] **************\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:03 INFO 139714520221504] Completed Epoch: 4, time taken: 0:00:05.655198\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:03 INFO 139714520221504] Epoch 4 Training metrics:   mean_squared_error: 0.112 mean_absolute_error: 0.253 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:03 INFO 139714520221504] #quality_metric: host=algo-1, epoch=4, train mean_squared_error <loss>=0.111813668982\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:03 INFO 139714520221504] Epoch 4 Validation metrics: mean_squared_error: 0.934 mean_absolute_error: 0.761 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:03 INFO 139714520221504] #quality_metric: host=algo-1, epoch=4, validation mean_squared_error <loss>=0.933606903497\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:03 INFO 139714520221504] **************\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:03 INFO 139714520221504] patience losses: [0.9859733158672178, 0.9591911366662463, 0.9521576297041532]\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:03 INFO 139714520221504] min patience losses: 0.952157629704\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:03 INFO 139714520221504] current loss: 0.933606903497\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:03 INFO 139714520221504] absolute loss difference: 0.0185507262075\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"early_stop.time\": {\"count\": 1, \"max\": 2.866029739379883, \"sum\": 2.866029739379883, \"min\": 2.866029739379883}, \"update.time\": {\"count\": 1, \"max\": 5850.505113601685, \"sum\": 5850.505113601685, \"min\": 5850.505113601685}}, \"EndTime\": 1572374223.822768, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1572374217.948614}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:03 INFO 139714520221504] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1416, \"sum\": 1416.0, \"min\": 1416}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1416, \"sum\": 1416.0, \"min\": 1416}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90624, \"sum\": 90624.0, \"min\": 90624}, \"Total Batches Seen\": {\"count\": 1, \"max\": 7080, \"sum\": 7080.0, \"min\": 7080}, \"Total Records Seen\": {\"count\": 1, \"max\": 453120, \"sum\": 453120.0, \"min\": 453120}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90624, \"sum\": 90624.0, \"min\": 90624}, \"Reset Count\": {\"count\": 1, \"max\": 5, \"sum\": 5.0, \"min\": 5}}, \"EndTime\": 1572374223.823025, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\", \"epoch\": 4}, \"StartTime\": 1572374217.972241}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:03 INFO 139714520221504] #throughput_metric: host=algo-1, train throughput=15488.8223155 records/second\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:04 INFO 139714520221504] Epoch: 5, batches: 100, num_examples: 6400, 16044.8 samples/sec, epoch time so far: 0:00:00.398883\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:04 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.091 mean_absolute_error: 0.232 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:04 INFO 139714520221504] Epoch: 5, batches: 200, num_examples: 12800, 16005.1 samples/sec, epoch time so far: 0:00:00.799743\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:04 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.089 mean_absolute_error: 0.229 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:05 INFO 139714520221504] Epoch: 5, batches: 300, num_examples: 19200, 16033.1 samples/sec, epoch time so far: 0:00:01.197521\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:05 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.088 mean_absolute_error: 0.227 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:05 INFO 139714520221504] Epoch: 5, batches: 400, num_examples: 25600, 16060.8 samples/sec, epoch time so far: 0:00:01.593942\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:05 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.087 mean_absolute_error: 0.226 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:05 INFO 139714520221504] Epoch: 5, batches: 500, num_examples: 32000, 16080.3 samples/sec, epoch time so far: 0:00:01.990007\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:05 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.087 mean_absolute_error: 0.226 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:06 INFO 139714520221504] Epoch: 5, batches: 600, num_examples: 38400, 16062.7 samples/sec, epoch time so far: 0:00:02.390632\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:06 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.086 mean_absolute_error: 0.225 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:06 INFO 139714520221504] Epoch: 5, batches: 700, num_examples: 44800, 16073.7 samples/sec, epoch time so far: 0:00:02.787164\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:06 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.087 mean_absolute_error: 0.226 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:07 INFO 139714520221504] Epoch: 5, batches: 800, num_examples: 51200, 16075.5 samples/sec, epoch time so far: 0:00:03.184978\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:07 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.086 mean_absolute_error: 0.226 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:07 INFO 139714520221504] Epoch: 5, batches: 900, num_examples: 57600, 16076.1 samples/sec, epoch time so far: 0:00:03.582965\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:07 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.086 mean_absolute_error: 0.226 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:07 INFO 139714520221504] Epoch: 5, batches: 1000, num_examples: 64000, 16083.6 samples/sec, epoch time so far: 0:00:03.979200\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:07 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.086 mean_absolute_error: 0.226 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:08 INFO 139714520221504] Epoch: 5, batches: 1100, num_examples: 70400, 16081.3 samples/sec, epoch time so far: 0:00:04.377757\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:08 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.086 mean_absolute_error: 0.226 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:08 INFO 139714520221504] Epoch: 5, batches: 1200, num_examples: 76800, 16037.1 samples/sec, epoch time so far: 0:00:04.788894\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:08 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.087 mean_absolute_error: 0.227 \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[10/29/2019 18:37:09 INFO 139714520221504] Epoch: 5, batches: 1300, num_examples: 83200, 16036.1 samples/sec, epoch time so far: 0:00:05.188282\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:09 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.087 mean_absolute_error: 0.227 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:09 INFO 139714520221504] Epoch: 5, batches: 1400, num_examples: 89600, 16051.9 samples/sec, epoch time so far: 0:00:05.581906\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:09 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.087 mean_absolute_error: 0.227 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:09 INFO 139714520221504] **************\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:09 INFO 139714520221504] Completed Epoch: 5, time taken: 0:00:05.645101\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:09 INFO 139714520221504] Epoch 5 Training metrics:   mean_squared_error: 0.087 mean_absolute_error: 0.227 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:09 INFO 139714520221504] #quality_metric: host=algo-1, epoch=5, train mean_squared_error <loss>=0.0867871826878\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:09 INFO 139714520221504] Epoch 5 Validation metrics: mean_squared_error: 0.932 mean_absolute_error: 0.755 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:09 INFO 139714520221504] #quality_metric: host=algo-1, epoch=5, validation mean_squared_error <loss>=0.931865350419\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:09 INFO 139714520221504] **************\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:09 INFO 139714520221504] patience losses: [0.9591911366662463, 0.9521576297041532, 0.9336069034966262]\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:09 INFO 139714520221504] min patience losses: 0.933606903497\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:09 INFO 139714520221504] current loss: 0.931865350419\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:09 INFO 139714520221504] absolute loss difference: 0.00174155307783\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:09 INFO 139714520221504] Bad epoch: loss has not improved (enough). Bad count:1\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"early_stop.time\": {\"count\": 1, \"max\": 2.874135971069336, \"sum\": 2.874135971069336, \"min\": 2.874135971069336}, \"update.time\": {\"count\": 1, \"max\": 5852.219820022583, \"sum\": 5852.219820022583, \"min\": 5852.219820022583}}, \"EndTime\": 1572374229.698527, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1572374223.822843}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:09 INFO 139714520221504] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1416, \"sum\": 1416.0, \"min\": 1416}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1416, \"sum\": 1416.0, \"min\": 1416}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90624, \"sum\": 90624.0, \"min\": 90624}, \"Total Batches Seen\": {\"count\": 1, \"max\": 8496, \"sum\": 8496.0, \"min\": 8496}, \"Total Records Seen\": {\"count\": 1, \"max\": 543744, \"sum\": 543744.0, \"min\": 543744}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90624, \"sum\": 90624.0, \"min\": 90624}, \"Reset Count\": {\"count\": 1, \"max\": 6, \"sum\": 6.0, \"min\": 6}}, \"EndTime\": 1572374229.698796, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\", \"epoch\": 5}, \"StartTime\": 1572374223.846276}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:09 INFO 139714520221504] #throughput_metric: host=algo-1, train throughput=15484.1380634 records/second\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:10 INFO 139714520221504] Epoch: 6, batches: 100, num_examples: 6400, 16076.6 samples/sec, epoch time so far: 0:00:00.398094\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:10 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.088 mean_absolute_error: 0.229 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:10 INFO 139714520221504] Epoch: 6, batches: 200, num_examples: 12800, 16110.0 samples/sec, epoch time so far: 0:00:00.794538\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:10 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.085 mean_absolute_error: 0.225 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:10 INFO 139714520221504] Epoch: 6, batches: 300, num_examples: 19200, 16129.2 samples/sec, epoch time so far: 0:00:01.190384\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:10 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.084 mean_absolute_error: 0.224 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:11 INFO 139714520221504] Epoch: 6, batches: 400, num_examples: 25600, 16135.1 samples/sec, epoch time so far: 0:00:01.586607\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:11 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.083 mean_absolute_error: 0.222 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:11 INFO 139714520221504] Epoch: 6, batches: 500, num_examples: 32000, 16147.7 samples/sec, epoch time so far: 0:00:01.981705\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:11 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.082 mean_absolute_error: 0.221 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:12 INFO 139714520221504] Epoch: 6, batches: 600, num_examples: 38400, 16125.0 samples/sec, epoch time so far: 0:00:02.381390\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:12 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.082 mean_absolute_error: 0.221 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:12 INFO 139714520221504] Epoch: 6, batches: 700, num_examples: 44800, 16134.8 samples/sec, epoch time so far: 0:00:02.776614\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:12 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.081 mean_absolute_error: 0.220 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:12 INFO 139714520221504] Epoch: 6, batches: 800, num_examples: 51200, 16142.3 samples/sec, epoch time so far: 0:00:03.171790\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:12 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.081 mean_absolute_error: 0.220 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:13 INFO 139714520221504] Epoch: 6, batches: 900, num_examples: 57600, 16137.7 samples/sec, epoch time so far: 0:00:03.569279\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:13 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.081 mean_absolute_error: 0.220 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:13 INFO 139714520221504] Epoch: 6, batches: 1000, num_examples: 64000, 16069.0 samples/sec, epoch time so far: 0:00:03.982819\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:13 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.081 mean_absolute_error: 0.220 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:14 INFO 139714520221504] Epoch: 6, batches: 1100, num_examples: 70400, 16065.4 samples/sec, epoch time so far: 0:00:04.382087\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:14 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.081 mean_absolute_error: 0.220 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:14 INFO 139714520221504] Epoch: 6, batches: 1200, num_examples: 76800, 16072.4 samples/sec, epoch time so far: 0:00:04.778392\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:14 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.081 mean_absolute_error: 0.221 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:14 INFO 139714520221504] Epoch: 6, batches: 1300, num_examples: 83200, 16075.6 samples/sec, epoch time so far: 0:00:05.175551\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:14 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.081 mean_absolute_error: 0.221 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:15 INFO 139714520221504] Epoch: 6, batches: 1400, num_examples: 89600, 16080.7 samples/sec, epoch time so far: 0:00:05.571892\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:15 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.082 mean_absolute_error: 0.221 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:15 INFO 139714520221504] **************\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:15 INFO 139714520221504] Completed Epoch: 6, time taken: 0:00:05.635516\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:15 INFO 139714520221504] Epoch 6 Training metrics:   mean_squared_error: 0.082 mean_absolute_error: 0.221 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:15 INFO 139714520221504] #quality_metric: host=algo-1, epoch=6, train mean_squared_error <loss>=0.0816055565644\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:15 INFO 139714520221504] Epoch 6 Validation metrics: mean_squared_error: 0.931 mean_absolute_error: 0.760 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:15 INFO 139714520221504] #quality_metric: host=algo-1, epoch=6, validation mean_squared_error <loss>=0.931220081006\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:15 INFO 139714520221504] **************\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:15 INFO 139714520221504] patience losses: [0.9521576297041532, 0.9336069034966262, 0.9318653504187996]\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:15 INFO 139714520221504] min patience losses: 0.931865350419\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:15 INFO 139714520221504] current loss: 0.931220081006\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:15 INFO 139714520221504] absolute loss difference: 0.000645269413252\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:15 INFO 139714520221504] Bad epoch: loss has not improved (enough). Bad count:2\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"early_stop.time\": {\"count\": 1, \"max\": 2.8810501098632812, \"sum\": 2.8810501098632812, \"min\": 2.8810501098632812}, \"update.time\": {\"count\": 1, \"max\": 5828.374147415161, \"sum\": 5828.374147415161, \"min\": 5828.374147415161}}, \"EndTime\": 1572374235.549393, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1572374229.698619}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:15 INFO 139714520221504] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1416, \"sum\": 1416.0, \"min\": 1416}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1416, \"sum\": 1416.0, \"min\": 1416}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90624, \"sum\": 90624.0, \"min\": 90624}, \"Total Batches Seen\": {\"count\": 1, \"max\": 9912, \"sum\": 9912.0, \"min\": 9912}, \"Total Records Seen\": {\"count\": 1, \"max\": 634368, \"sum\": 634368.0, \"min\": 634368}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90624, \"sum\": 90624.0, \"min\": 90624}, \"Reset Count\": {\"count\": 1, \"max\": 7, \"sum\": 7.0, \"min\": 7}}, \"EndTime\": 1572374235.549681, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\", \"epoch\": 6}, \"StartTime\": 1572374229.72099}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:15 INFO 139714520221504] #throughput_metric: host=algo-1, train throughput=15547.4736907 records/second\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:15 INFO 139714520221504] Epoch: 7, batches: 100, num_examples: 6400, 16253.2 samples/sec, epoch time so far: 0:00:00.393768\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:15 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.084 mean_absolute_error: 0.222 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:16 INFO 139714520221504] Epoch: 7, batches: 200, num_examples: 12800, 16199.0 samples/sec, epoch time so far: 0:00:00.790170\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:16 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.081 mean_absolute_error: 0.219 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:16 INFO 139714520221504] Epoch: 7, batches: 300, num_examples: 19200, 16185.5 samples/sec, epoch time so far: 0:00:01.186248\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:16 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.080 mean_absolute_error: 0.218 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:17 INFO 139714520221504] Epoch: 7, batches: 400, num_examples: 25600, 16153.3 samples/sec, epoch time so far: 0:00:01.584820\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:17 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.080 mean_absolute_error: 0.217 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:17 INFO 139714520221504] Epoch: 7, batches: 500, num_examples: 32000, 16157.8 samples/sec, epoch time so far: 0:00:01.980470\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:17 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.079 mean_absolute_error: 0.216 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:17 INFO 139714520221504] Epoch: 7, batches: 600, num_examples: 38400, 16154.6 samples/sec, epoch time so far: 0:00:02.377028\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:17 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.078 mean_absolute_error: 0.215 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:18 INFO 139714520221504] Epoch: 7, batches: 700, num_examples: 44800, 16120.2 samples/sec, epoch time so far: 0:00:02.779125\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:18 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.077 mean_absolute_error: 0.214 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:18 INFO 139714520221504] Epoch: 7, batches: 800, num_examples: 51200, 16025.4 samples/sec, epoch time so far: 0:00:03.194930\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:18 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.077 mean_absolute_error: 0.214 \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[10/29/2019 18:37:19 INFO 139714520221504] Epoch: 7, batches: 900, num_examples: 57600, 16030.8 samples/sec, epoch time so far: 0:00:03.593088\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:19 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.077 mean_absolute_error: 0.214 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:19 INFO 139714520221504] Epoch: 7, batches: 1000, num_examples: 64000, 16045.2 samples/sec, epoch time so far: 0:00:03.988743\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:19 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.077 mean_absolute_error: 0.214 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:19 INFO 139714520221504] Epoch: 7, batches: 1100, num_examples: 70400, 16043.9 samples/sec, epoch time so far: 0:00:04.387954\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:19 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.077 mean_absolute_error: 0.214 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:20 INFO 139714520221504] Epoch: 7, batches: 1200, num_examples: 76800, 16050.3 samples/sec, epoch time so far: 0:00:04.784952\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:20 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.077 mean_absolute_error: 0.214 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:20 INFO 139714520221504] Epoch: 7, batches: 1300, num_examples: 83200, 16060.4 samples/sec, epoch time so far: 0:00:05.180449\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:20 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.077 mean_absolute_error: 0.214 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:21 INFO 139714520221504] Epoch: 7, batches: 1400, num_examples: 89600, 16069.2 samples/sec, epoch time so far: 0:00:05.575892\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:21 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.077 mean_absolute_error: 0.214 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:21 INFO 139714520221504] **************\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:21 INFO 139714520221504] Completed Epoch: 7, time taken: 0:00:05.639981\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:21 INFO 139714520221504] Epoch 7 Training metrics:   mean_squared_error: 0.077 mean_absolute_error: 0.214 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:21 INFO 139714520221504] #quality_metric: host=algo-1, epoch=7, train mean_squared_error <loss>=0.077157545448\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:21 INFO 139714520221504] Epoch 7 Validation metrics: mean_squared_error: 0.928 mean_absolute_error: 0.767 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:21 INFO 139714520221504] #quality_metric: host=algo-1, epoch=7, validation mean_squared_error <loss>=0.928095356033\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:21 INFO 139714520221504] **************\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:21 INFO 139714520221504] patience losses: [0.9336069034966262, 0.9318653504187996, 0.9312200810055475]\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:21 INFO 139714520221504] min patience losses: 0.931220081006\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:21 INFO 139714520221504] current loss: 0.928095356033\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:21 INFO 139714520221504] absolute loss difference: 0.00312472497289\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:21 INFO 139714520221504] Bad epoch: loss has not improved (enough). Bad count:3\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"early_stop.time\": {\"count\": 1, \"max\": 2.788066864013672, \"sum\": 2.788066864013672, \"min\": 2.788066864013672}, \"update.time\": {\"count\": 1, \"max\": 5829.177141189575, \"sum\": 5829.177141189575, \"min\": 5829.177141189575}}, \"EndTime\": 1572374241.400657, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1572374235.549491}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:21 INFO 139714520221504] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1416, \"sum\": 1416.0, \"min\": 1416}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1416, \"sum\": 1416.0, \"min\": 1416}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90624, \"sum\": 90624.0, \"min\": 90624}, \"Total Batches Seen\": {\"count\": 1, \"max\": 11328, \"sum\": 11328.0, \"min\": 11328}, \"Total Records Seen\": {\"count\": 1, \"max\": 724992, \"sum\": 724992.0, \"min\": 724992}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90624, \"sum\": 90624.0, \"min\": 90624}, \"Reset Count\": {\"count\": 1, \"max\": 8, \"sum\": 8.0, \"min\": 8}}, \"EndTime\": 1572374241.400947, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\", \"epoch\": 7}, \"StartTime\": 1572374235.571451}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:21 INFO 139714520221504] #throughput_metric: host=algo-1, train throughput=15545.3588401 records/second\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:21 INFO 139714520221504] Epoch: 8, batches: 100, num_examples: 6400, 16185.9 samples/sec, epoch time so far: 0:00:00.395405\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:21 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.070 mean_absolute_error: 0.203 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:22 INFO 139714520221504] Epoch: 8, batches: 200, num_examples: 12800, 16132.9 samples/sec, epoch time so far: 0:00:00.793409\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:22 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.067 mean_absolute_error: 0.199 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:22 INFO 139714520221504] Epoch: 8, batches: 300, num_examples: 19200, 16145.6 samples/sec, epoch time so far: 0:00:01.189182\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:22 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.066 mean_absolute_error: 0.197 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:23 INFO 139714520221504] Epoch: 8, batches: 400, num_examples: 25600, 16159.0 samples/sec, epoch time so far: 0:00:01.584254\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:23 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.066 mean_absolute_error: 0.197 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:23 INFO 139714520221504] Epoch: 8, batches: 500, num_examples: 32000, 16156.7 samples/sec, epoch time so far: 0:00:01.980597\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:23 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.067 mean_absolute_error: 0.198 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:23 INFO 139714520221504] Epoch: 8, batches: 600, num_examples: 38400, 16109.6 samples/sec, epoch time so far: 0:00:02.383668\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:23 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.066 mean_absolute_error: 0.197 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:24 INFO 139714520221504] Epoch: 8, batches: 700, num_examples: 44800, 16106.8 samples/sec, epoch time so far: 0:00:02.781429\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:24 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.066 mean_absolute_error: 0.196 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:24 INFO 139714520221504] Epoch: 8, batches: 800, num_examples: 51200, 16113.4 samples/sec, epoch time so far: 0:00:03.177489\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:24 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.065 mean_absolute_error: 0.195 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:24 INFO 139714520221504] Epoch: 8, batches: 900, num_examples: 57600, 16122.0 samples/sec, epoch time so far: 0:00:03.572761\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:24 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.065 mean_absolute_error: 0.195 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:25 INFO 139714520221504] Epoch: 8, batches: 1000, num_examples: 64000, 16105.8 samples/sec, epoch time so far: 0:00:03.973717\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:25 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.065 mean_absolute_error: 0.195 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:25 INFO 139714520221504] Epoch: 8, batches: 1100, num_examples: 70400, 16107.9 samples/sec, epoch time so far: 0:00:04.370529\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:25 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.065 mean_absolute_error: 0.195 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:26 INFO 139714520221504] Epoch: 8, batches: 1200, num_examples: 76800, 16109.2 samples/sec, epoch time so far: 0:00:04.767471\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:26 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.065 mean_absolute_error: 0.195 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:26 INFO 139714520221504] Epoch: 8, batches: 1300, num_examples: 83200, 16110.0 samples/sec, epoch time so far: 0:00:05.164500\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:26 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.065 mean_absolute_error: 0.195 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:26 INFO 139714520221504] Epoch: 8, batches: 1400, num_examples: 89600, 16112.8 samples/sec, epoch time so far: 0:00:05.560791\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:26 INFO 139714520221504] #011Training metrics: mean_squared_error: 0.065 mean_absolute_error: 0.195 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:27 INFO 139714520221504] **************\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:27 INFO 139714520221504] Completed Epoch: 8, time taken: 0:00:05.623979\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:27 INFO 139714520221504] Epoch 8 Training metrics:   mean_squared_error: 0.065 mean_absolute_error: 0.195 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:27 INFO 139714520221504] #quality_metric: host=algo-1, epoch=8, train mean_squared_error <loss>=0.0649084720003\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:27 INFO 139714520221504] Epoch 8 Validation metrics: mean_squared_error: 0.919 mean_absolute_error: 0.758 \u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:27 INFO 139714520221504] #quality_metric: host=algo-1, epoch=8, validation mean_squared_error <loss>=0.919467305211\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:27 INFO 139714520221504] **************\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:27 INFO 139714520221504] patience losses: [0.9318653504187996, 0.9312200810055475, 0.928095356032655]\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:27 INFO 139714520221504] min patience losses: 0.928095356033\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:27 INFO 139714520221504] current loss: 0.919467305211\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:27 INFO 139714520221504] absolute loss difference: 0.00862805082186\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:27 INFO 139714520221504] Bad epoch: loss has not improved (enough). Bad count:4\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:27 INFO 139714520221504] Bad epochs exceeded patience. Stopping training early!\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:27 INFO 139714520221504] Early stopping criterion met! Stopping training at epoch: 8\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"early_stop.time\": {\"count\": 1, \"max\": 2.998828887939453, \"sum\": 2.998828887939453, \"min\": 2.998828887939453}, \"update.time\": {\"count\": 1, \"max\": 5819.163084030151, \"sum\": 5819.163084030151, \"min\": 5819.163084030151}}, \"EndTime\": 1572374247.242604, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1572374241.400754}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:27 INFO 139714520221504] Early stop condition met. Stopping training.\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:27 INFO 139714520221504] #progress_metric: host=algo-1, completed 100 % epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1416, \"sum\": 1416.0, \"min\": 1416}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1416, \"sum\": 1416.0, \"min\": 1416}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90624, \"sum\": 90624.0, \"min\": 90624}, \"Total Batches Seen\": {\"count\": 1, \"max\": 12744, \"sum\": 12744.0, \"min\": 12744}, \"Total Records Seen\": {\"count\": 1, \"max\": 815616, \"sum\": 815616.0, \"min\": 815616}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90624, \"sum\": 90624.0, \"min\": 90624}, \"Reset Count\": {\"count\": 1, \"max\": 9, \"sum\": 9.0, \"min\": 9}}, \"EndTime\": 1572374247.242959, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\", \"epoch\": 8}, \"StartTime\": 1572374241.423419}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:27 INFO 139714520221504] #throughput_metric: host=algo-1, train throughput=15571.9877263 records/second\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:27 WARNING 139714520221504] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:27 INFO 139714520221504] Best model based on epoch 8. Best loss: 0.919\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 0.8921623229980469, \"sum\": 0.8921623229980469, \"min\": 0.8921623229980469}}, \"EndTime\": 1572374247.244171, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1572374247.24268}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:27 INFO 139714520221504] Serializing model to /opt/ml/model/model_algo-1\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:27 INFO 139714520221504] Saved checkpoint to \"/tmp/tmpTvqsFl/state-0001.params\"\u001b[0m\n",
      "\u001b[31m[10/29/2019 18:37:27 INFO 139714520221504] Test data is not provided.\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 61238.43002319336, \"sum\": 61238.43002319336, \"min\": 61238.43002319336}, \"model.serialize.time\": {\"count\": 1, \"max\": 75.67811012268066, \"sum\": 75.67811012268066, \"min\": 75.67811012268066}, \"setuptime\": {\"count\": 1, \"max\": 61.58304214477539, \"sum\": 61.58304214477539, \"min\": 61.58304214477539}}, \"EndTime\": 1572374247.321247, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1572374247.244228}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2019-10-29 18:37:35 Uploading - Uploading generated training model\n",
      "2019-10-29 18:37:35 Completed - Training job completed\n",
      "Training seconds: 139\n",
      "Billable seconds: 139\n"
     ]
    }
   ],
   "source": [
    "## get estimator\n",
    "regressor = sagemaker.estimator.Estimator(container,\n",
    "                                          role, \n",
    "                                          train_instance_count=1, \n",
    "                                          train_instance_type='ml.p2.xlarge',\n",
    "                                          output_path=output_path,\n",
    "                                          sagemaker_session=sess)\n",
    "\n",
    "## set hyperparameters\n",
    "regressor.set_hyperparameters(**hyperparameters)\n",
    "\n",
    "## train the model\n",
    "regressor.fit(input_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have seen that we can upload train (validation) data through the input data channel, and the algorithm will print out train (validation) evaluation metric during training. In addition, the algorithm uses the validation metric to perform early stopping. \n",
    "\n",
    "What if we want to send additional unlabeled data to the algorithm and get predictions from the trained model?\n",
    "This step is called *inference* in the Sagemaker framework. Next, we demonstrate how to use a trained model to perform inference on unseen data points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference using trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and deploy the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import json_serializer, json_deserializer\n",
    "\n",
    "# create a model using the trained algorithm\n",
    "regression_model = regressor.create_model(\n",
    "                        serializer=json_serializer,\n",
    "                        deserializer=json_deserializer,\n",
    "                        content_type='application/json',\n",
    "                        name='ratingModel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "# deploy the model\n",
    "predictor = regression_model.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we send validation data (without labels) to the deployed endpoint for inference. We will see that the resulting prediction error we get from post-training inference matches the best validation error from the training log in the console above (up to floating point error). If you follow the training instruction and parameter setup, you should get mean squared error on the validation set approximately 0.91."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instances': ({'in0': [165], 'in1': [69]},\n",
       "  {'in0': [209], 'in1': [898]},\n",
       "  {'in0': [763], 'in1': [28]},\n",
       "  {'in0': [844], 'in1': [423]},\n",
       "  {'in0': [613], 'in1': [471]},\n",
       "  {'in0': [411], 'in1': [451]},\n",
       "  {'in0': [349], 'in1': [370]},\n",
       "  {'in0': [286], 'in1': [143]},\n",
       "  {'in0': [636], 'in1': [100]},\n",
       "  {'in0': [555], 'in1': [7]},\n",
       "  {'in0': [322], 'in1': [318]},\n",
       "  {'in0': [514], 'in1': [302]},\n",
       "  {'in0': [889], 'in1': [654]},\n",
       "  {'in0': [218], 'in1': [695]},\n",
       "  {'in0': [627], 'in1': [699]},\n",
       "  {'in0': [44], 'in1': [443]},\n",
       "  {'in0': [890], 'in1': [237]},\n",
       "  {'in0': [240], 'in1': [300]},\n",
       "  {'in0': [74], 'in1': [126]},\n",
       "  {'in0': [802], 'in1': [327]},\n",
       "  {'in0': [631], 'in1': [346]},\n",
       "  {'in0': [790], 'in1': [1063]},\n",
       "  {'in0': [611], 'in1': [286]},\n",
       "  {'in0': [190], 'in1': [974]},\n",
       "  {'in0': [634], 'in1': [237]},\n",
       "  {'in0': [342], 'in1': [746]},\n",
       "  {'in0': [500], 'in1': [836]},\n",
       "  {'in0': [902], 'in1': [134]},\n",
       "  {'in0': [408], 'in1': [286]},\n",
       "  {'in0': [636], 'in1': [121]},\n",
       "  {'in0': [742], 'in1': [1012]},\n",
       "  {'in0': [524], 'in1': [1268]},\n",
       "  {'in0': [343], 'in1': [55]},\n",
       "  {'in0': [100], 'in1': [321]},\n",
       "  {'in0': [782], 'in1': [1600]},\n",
       "  {'in0': [717], 'in1': [322]},\n",
       "  {'in0': [30], 'in1': [678]},\n",
       "  {'in0': [798], 'in1': [998]},\n",
       "  {'in0': [460], 'in1': [257]},\n",
       "  {'in0': [340], 'in1': [418]},\n",
       "  {'in0': [450], 'in1': [142]},\n",
       "  {'in0': [231], 'in1': [846]},\n",
       "  {'in0': [795], 'in1': [235]},\n",
       "  {'in0': [259], 'in1': [176]},\n",
       "  {'in0': [156], 'in1': [12]},\n",
       "  {'in0': [654], 'in1': [66]},\n",
       "  {'in0': [601], 'in1': [419]},\n",
       "  {'in0': [817], 'in1': [118]},\n",
       "  {'in0': [655], 'in1': [198]},\n",
       "  {'in0': [395], 'in1': [255]},\n",
       "  {'in0': [716], 'in1': [91]},\n",
       "  {'in0': [60], 'in1': [60]},\n",
       "  {'in0': [277], 'in1': [257]},\n",
       "  {'in0': [871], 'in1': [515]},\n",
       "  {'in0': [350], 'in1': [228]},\n",
       "  {'in0': [569], 'in1': [3]},\n",
       "  {'in0': [139], 'in1': [303]},\n",
       "  {'in0': [236], 'in1': [729]},\n",
       "  {'in0': [576], 'in1': [381]},\n",
       "  {'in0': [551], 'in1': [864]},\n",
       "  {'in0': [188], 'in1': [769]},\n",
       "  {'in0': [545], 'in1': [554]},\n",
       "  {'in0': [800], 'in1': [742]},\n",
       "  {'in0': [894], 'in1': [405]},\n",
       "  {'in0': [61], 'in1': [1127]},\n",
       "  {'in0': [52], 'in1': [748]},\n",
       "  {'in0': [831], 'in1': [333]},\n",
       "  {'in0': [883], 'in1': [68]},\n",
       "  {'in0': [706], 'in1': [333]},\n",
       "  {'in0': [701], 'in1': [285]},\n",
       "  {'in0': [420], 'in1': [288]},\n",
       "  {'in0': [753], 'in1': [182]},\n",
       "  {'in0': [600], 'in1': [92]},\n",
       "  {'in0': [627], 'in1': [467]},\n",
       "  {'in0': [700], 'in1': [28]},\n",
       "  {'in0': [387], 'in1': [199]},\n",
       "  {'in0': [282], 'in1': [269]},\n",
       "  {'in0': [919], 'in1': [690]},\n",
       "  {'in0': [736], 'in1': [1388]},\n",
       "  {'in0': [570], 'in1': [303]},\n",
       "  {'in0': [407], 'in1': [205]},\n",
       "  {'in0': [446], 'in1': [288]},\n",
       "  {'in0': [593], 'in1': [392]},\n",
       "  {'in0': [910], 'in1': [245]},\n",
       "  {'in0': [569], 'in1': [111]},\n",
       "  {'in0': [360], 'in1': [303]},\n",
       "  {'in0': [90], 'in1': [347]},\n",
       "  {'in0': [209], 'in1': [906]},\n",
       "  {'in0': [630], 'in1': [717]},\n",
       "  {'in0': [321], 'in1': [521]},\n",
       "  {'in0': [519], 'in1': [336]},\n",
       "  {'in0': [60], 'in1': [403]},\n",
       "  {'in0': [708], 'in1': [1]},\n",
       "  {'in0': [32], 'in1': [151]},\n",
       "  {'in0': [455], 'in1': [282]},\n",
       "  {'in0': [462], 'in1': [895]},\n",
       "  {'in0': [409], 'in1': [1242]},\n",
       "  {'in0': [606], 'in1': [473]},\n",
       "  {'in0': [625], 'in1': [602]},\n",
       "  {'in0': [175], 'in1': [56]},\n",
       "  {'in0': [371], 'in1': [663]},\n",
       "  {'in0': [409], 'in1': [99]},\n",
       "  {'in0': [186], 'in1': [983]},\n",
       "  {'in0': [416], 'in1': [250]},\n",
       "  {'in0': [325], 'in1': [514]},\n",
       "  {'in0': [867], 'in1': [956]},\n",
       "  {'in0': [874], 'in1': [289]},\n",
       "  {'in0': [898], 'in1': [242]},\n",
       "  {'in0': [219], 'in1': [347]},\n",
       "  {'in0': [716], 'in1': [318]},\n",
       "  {'in0': [876], 'in1': [178]},\n",
       "  {'in0': [866], 'in1': [302]},\n",
       "  {'in0': [256], 'in1': [452]},\n",
       "  {'in0': [934], 'in1': [50]},\n",
       "  {'in0': [400], 'in1': [689]},\n",
       "  {'in0': [913], 'in1': [527]},\n",
       "  {'in0': [220], 'in1': [333]},\n",
       "  {'in0': [533], 'in1': [526]},\n",
       "  {'in0': [520], 'in1': [25]},\n",
       "  {'in0': [800], 'in1': [127]},\n",
       "  {'in0': [338], 'in1': [494]},\n",
       "  {'in0': [301], 'in1': [554]},\n",
       "  {'in0': [267], 'in1': [518]},\n",
       "  {'in0': [881], 'in1': [671]},\n",
       "  {'in0': [796], 'in1': [418]},\n",
       "  {'in0': [453], 'in1': [246]},\n",
       "  {'in0': [276], 'in1': [2]},\n",
       "  {'in0': [89], 'in1': [1048]},\n",
       "  {'in0': [698], 'in1': [83]},\n",
       "  {'in0': [273], 'in1': [690]},\n",
       "  {'in0': [625], 'in1': [96]},\n",
       "  {'in0': [633], 'in1': [143]},\n",
       "  {'in0': [444], 'in1': [1483]},\n",
       "  {'in0': [483], 'in1': [271]},\n",
       "  {'in0': [727], 'in1': [105]},\n",
       "  {'in0': [296], 'in1': [258]},\n",
       "  {'in0': [822], 'in1': [432]},\n",
       "  {'in0': [495], 'in1': [658]},\n",
       "  {'in0': [462], 'in1': [678]},\n",
       "  {'in0': [494], 'in1': [126]},\n",
       "  {'in0': [859], 'in1': [111]},\n",
       "  {'in0': [850], 'in1': [490]},\n",
       "  {'in0': [258], 'in1': [751]},\n",
       "  {'in0': [940], 'in1': [272]},\n",
       "  {'in0': [528], 'in1': [751]},\n",
       "  {'in0': [865], 'in1': [928]},\n",
       "  {'in0': [39], 'in1': [313]},\n",
       "  {'in0': [260], 'in1': [272]},\n",
       "  {'in0': [419], 'in1': [514]},\n",
       "  {'in0': [886], 'in1': [1303]},\n",
       "  {'in0': [366], 'in1': [443]},\n",
       "  {'in0': [632], 'in1': [419]},\n",
       "  {'in0': [49], 'in1': [1003]},\n",
       "  {'in0': [767], 'in1': [207]},\n",
       "  {'in0': [785], 'in1': [183]},\n",
       "  {'in0': [23], 'in1': [170]},\n",
       "  {'in0': [410], 'in1': [286]},\n",
       "  {'in0': [267], 'in1': [121]},\n",
       "  {'in0': [4], 'in1': [264]},\n",
       "  {'in0': [659], 'in1': [601]},\n",
       "  {'in0': [315], 'in1': [8]},\n",
       "  {'in0': [333], 'in1': [894]},\n",
       "  {'in0': [244], 'in1': [550]},\n",
       "  {'in0': [779], 'in1': [243]},\n",
       "  {'in0': [903], 'in1': [203]},\n",
       "  {'in0': [830], 'in1': [288]},\n",
       "  {'in0': [214], 'in1': [213]},\n",
       "  {'in0': [62], 'in1': [257]},\n",
       "  {'in0': [926], 'in1': [258]},\n",
       "  {'in0': [173], 'in1': [323]},\n",
       "  {'in0': [942], 'in1': [323]},\n",
       "  {'in0': [641], 'in1': [59]},\n",
       "  {'in0': [152], 'in1': [132]},\n",
       "  {'in0': [581], 'in1': [919]},\n",
       "  {'in0': [653], 'in1': [444]},\n",
       "  {'in0': [538], 'in1': [496]},\n",
       "  {'in0': [301], 'in1': [401]},\n",
       "  {'in0': [390], 'in1': [181]},\n",
       "  {'in0': [127], 'in1': [229]},\n",
       "  {'in0': [367], 'in1': [665]},\n",
       "  {'in0': [511], 'in1': [294]},\n",
       "  {'in0': [739], 'in1': [1429]},\n",
       "  {'in0': [472], 'in1': [1011]},\n",
       "  {'in0': [79], 'in1': [303]},\n",
       "  {'in0': [719], 'in1': [281]},\n",
       "  {'in0': [329], 'in1': [258]},\n",
       "  {'in0': [935], 'in1': [476]},\n",
       "  {'in0': [756], 'in1': [178]},\n",
       "  {'in0': [821], 'in1': [742]},\n",
       "  {'in0': [72], 'in1': [48]},\n",
       "  {'in0': [104], 'in1': [287]},\n",
       "  {'in0': [65], 'in1': [97]},\n",
       "  {'in0': [146], 'in1': [1294]},\n",
       "  {'in0': [884], 'in1': [179]},\n",
       "  {'in0': [322], 'in1': [479]},\n",
       "  {'in0': [377], 'in1': [288]},\n",
       "  {'in0': [778], 'in1': [193]},\n",
       "  {'in0': [231], 'in1': [126]},\n",
       "  {'in0': [450], 'in1': [801]},\n",
       "  {'in0': [444], 'in1': [50]},\n",
       "  {'in0': [368], 'in1': [567]},\n",
       "  {'in0': [664], 'in1': [179]},\n",
       "  {'in0': [811], 'in1': [258]},\n",
       "  {'in0': [454], 'in1': [493]},\n",
       "  {'in0': [740], 'in1': [300]},\n",
       "  {'in0': [805], 'in1': [321]},\n",
       "  {'in0': [749], 'in1': [366]},\n",
       "  {'in0': [144], 'in1': [106]},\n",
       "  {'in0': [640], 'in1': [204]},\n",
       "  {'in0': [392], 'in1': [258]},\n",
       "  {'in0': [801], 'in1': [300]},\n",
       "  {'in0': [248], 'in1': [185]},\n",
       "  {'in0': [909], 'in1': [286]},\n",
       "  {'in0': [897], 'in1': [227]},\n",
       "  {'in0': [260], 'in1': [322]},\n",
       "  {'in0': [505], 'in1': [99]},\n",
       "  {'in0': [507], 'in1': [892]},\n",
       "  {'in0': [221], 'in1': [327]},\n",
       "  {'in0': [909], 'in1': [1121]},\n",
       "  {'in0': [343], 'in1': [569]},\n",
       "  {'in0': [694], 'in1': [229]},\n",
       "  {'in0': [903], 'in1': [708]},\n",
       "  {'in0': [633], 'in1': [1132]},\n",
       "  {'in0': [731], 'in1': [197]},\n",
       "  {'in0': [673], 'in1': [269]},\n",
       "  {'in0': [457], 'in1': [366]},\n",
       "  {'in0': [847], 'in1': [434]},\n",
       "  {'in0': [696], 'in1': [689]},\n",
       "  {'in0': [59], 'in1': [951]},\n",
       "  {'in0': [809], 'in1': [272]},\n",
       "  {'in0': [153], 'in1': [510]},\n",
       "  {'in0': [507], 'in1': [147]},\n",
       "  {'in0': [796], 'in1': [540]},\n",
       "  {'in0': [836], 'in1': [880]},\n",
       "  {'in0': [632], 'in1': [71]},\n",
       "  {'in0': [249], 'in1': [88]},\n",
       "  {'in0': [378], 'in1': [52]},\n",
       "  {'in0': [854], 'in1': [122]},\n",
       "  {'in0': [575], 'in1': [506]},\n",
       "  {'in0': [884], 'in1': [165]},\n",
       "  {'in0': [836], 'in1': [12]},\n",
       "  {'in0': [414], 'in1': [272]},\n",
       "  {'in0': [917], 'in1': [25]},\n",
       "  {'in0': [193], 'in1': [407]},\n",
       "  {'in0': [141], 'in1': [472]},\n",
       "  {'in0': [154], 'in1': [357]},\n",
       "  {'in0': [2], 'in1': [297]},\n",
       "  {'in0': [789], 'in1': [1012]},\n",
       "  {'in0': [515], 'in1': [292]},\n",
       "  {'in0': [97], 'in1': [222]},\n",
       "  {'in0': [820], 'in1': [271]},\n",
       "  {'in0': [387], 'in1': [56]},\n",
       "  {'in0': [875], 'in1': [923]},\n",
       "  {'in0': [780], 'in1': [202]},\n",
       "  {'in0': [287], 'in1': [294]},\n",
       "  {'in0': [481], 'in1': [313]},\n",
       "  {'in0': [184], 'in1': [153]},\n",
       "  {'in0': [899], 'in1': [751]},\n",
       "  {'in0': [228], 'in1': [204]},\n",
       "  {'in0': [243], 'in1': [93]},\n",
       "  {'in0': [449], 'in1': [1194]},\n",
       "  {'in0': [133], 'in1': [304]},\n",
       "  {'in0': [292], 'in1': [86]},\n",
       "  {'in0': [99], 'in1': [246]},\n",
       "  {'in0': [269], 'in1': [522]},\n",
       "  {'in0': [820], 'in1': [748]},\n",
       "  {'in0': [767], 'in1': [56]},\n",
       "  {'in0': [778], 'in1': [1035]},\n",
       "  {'in0': [660], 'in1': [510]},\n",
       "  {'in0': [16], 'in1': [64]},\n",
       "  {'in0': [453], 'in1': [421]},\n",
       "  {'in0': [601], 'in1': [181]},\n",
       "  {'in0': [536], 'in1': [441]},\n",
       "  {'in0': [402], 'in1': [126]},\n",
       "  {'in0': [470], 'in1': [1097]},\n",
       "  {'in0': [772], 'in1': [313]},\n",
       "  {'in0': [87], 'in1': [401]},\n",
       "  {'in0': [913], 'in1': [301]},\n",
       "  {'in0': [469], 'in1': [499]},\n",
       "  {'in0': [69], 'in1': [240]},\n",
       "  {'in0': [280], 'in1': [1]},\n",
       "  {'in0': [270], 'in1': [558]},\n",
       "  {'in0': [736], 'in1': [296]},\n",
       "  {'in0': [95], 'in1': [1]},\n",
       "  {'in0': [875], 'in1': [474]},\n",
       "  {'in0': [793], 'in1': [298]},\n",
       "  {'in0': [775], 'in1': [343]},\n",
       "  {'in0': [359], 'in1': [295]},\n",
       "  {'in0': [931], 'in1': [237]},\n",
       "  {'in0': [449], 'in1': [1009]},\n",
       "  {'in0': [580], 'in1': [294]},\n",
       "  {'in0': [509], 'in1': [319]},\n",
       "  {'in0': [206], 'in1': [903]},\n",
       "  {'in0': [484], 'in1': [195]},\n",
       "  {'in0': [585], 'in1': [1266]},\n",
       "  {'in0': [218], 'in1': [504]},\n",
       "  {'in0': [273], 'in1': [321]},\n",
       "  {'in0': [633], 'in1': [176]},\n",
       "  {'in0': [689], 'in1': [250]},\n",
       "  {'in0': [724], 'in1': [266]},\n",
       "  {'in0': [487], 'in1': [76]},\n",
       "  {'in0': [285], 'in1': [538]},\n",
       "  {'in0': [426], 'in1': [211]},\n",
       "  {'in0': [657], 'in1': [690]},\n",
       "  {'in0': [591], 'in1': [286]},\n",
       "  {'in0': [602], 'in1': [127]},\n",
       "  {'in0': [849], 'in1': [143]},\n",
       "  {'in0': [452], 'in1': [736]},\n",
       "  {'in0': [928], 'in1': [187]},\n",
       "  {'in0': [230], 'in1': [963]},\n",
       "  {'in0': [582], 'in1': [258]},\n",
       "  {'in0': [791], 'in1': [299]},\n",
       "  {'in0': [308], 'in1': [81]},\n",
       "  {'in0': [451], 'in1': [262]},\n",
       "  {'in0': [120], 'in1': [257]},\n",
       "  {'in0': [653], 'in1': [402]},\n",
       "  {'in0': [336], 'in1': [571]},\n",
       "  {'in0': [649], 'in1': [323]},\n",
       "  {'in0': [221], 'in1': [69]},\n",
       "  {'in0': [247], 'in1': [272]},\n",
       "  {'in0': [49], 'in1': [47]},\n",
       "  {'in0': [406], 'in1': [962]},\n",
       "  {'in0': [162], 'in1': [1019]},\n",
       "  {'in0': [516], 'in1': [191]},\n",
       "  {'in0': [54], 'in1': [676]},\n",
       "  {'in0': [134], 'in1': [323]},\n",
       "  {'in0': [108], 'in1': [121]},\n",
       "  {'in0': [753], 'in1': [484]},\n",
       "  {'in0': [883], 'in1': [144]},\n",
       "  {'in0': [445], 'in1': [919]},\n",
       "  {'in0': [32], 'in1': [276]},\n",
       "  {'in0': [112], 'in1': [327]},\n",
       "  {'in0': [537], 'in1': [203]},\n",
       "  {'in0': [474], 'in1': [518]},\n",
       "  {'in0': [517], 'in1': [283]},\n",
       "  {'in0': [281], 'in1': [338]},\n",
       "  {'in0': [277], 'in1': [1197]},\n",
       "  {'in0': [492], 'in1': [86]},\n",
       "  {'in0': [178], 'in1': [845]},\n",
       "  {'in0': [598], 'in1': [349]},\n",
       "  {'in0': [290], 'in1': [50]},\n",
       "  {'in0': [523], 'in1': [393]},\n",
       "  {'in0': [657], 'in1': [1009]},\n",
       "  {'in0': [82], 'in1': [135]},\n",
       "  {'in0': [580], 'in1': [300]},\n",
       "  {'in0': [830], 'in1': [385]},\n",
       "  {'in0': [491], 'in1': [340]},\n",
       "  {'in0': [470], 'in1': [824]},\n",
       "  {'in0': [77], 'in1': [172]},\n",
       "  {'in0': [866], 'in1': [300]},\n",
       "  {'in0': [312], 'in1': [121]},\n",
       "  {'in0': [672], 'in1': [476]},\n",
       "  {'in0': [808], 'in1': [245]},\n",
       "  {'in0': [639], 'in1': [58]},\n",
       "  {'in0': [307], 'in1': [174]},\n",
       "  {'in0': [933], 'in1': [447]},\n",
       "  {'in0': [912], 'in1': [496]},\n",
       "  {'in0': [606], 'in1': [147]},\n",
       "  {'in0': [796], 'in1': [184]},\n",
       "  {'in0': [798], 'in1': [138]},\n",
       "  {'in0': [101], 'in1': [281]},\n",
       "  {'in0': [714], 'in1': [121]},\n",
       "  {'in0': [279], 'in1': [501]},\n",
       "  {'in0': [436], 'in1': [133]},\n",
       "  {'in0': [237], 'in1': [494]},\n",
       "  {'in0': [434], 'in1': [121]},\n",
       "  {'in0': [868], 'in1': [1]},\n",
       "  {'in0': [362], 'in1': [336]},\n",
       "  {'in0': [396], 'in1': [841]},\n",
       "  {'in0': [714], 'in1': [871]},\n",
       "  {'in0': [150], 'in1': [13]},\n",
       "  {'in0': [414], 'in1': [346]},\n",
       "  {'in0': [589], 'in1': [259]},\n",
       "  {'in0': [188], 'in1': [237]},\n",
       "  {'in0': [346], 'in1': [187]},\n",
       "  {'in0': [392], 'in1': [179]},\n",
       "  {'in0': [533], 'in1': [477]},\n",
       "  {'in0': [474], 'in1': [68]},\n",
       "  {'in0': [412], 'in1': [92]},\n",
       "  {'in0': [562], 'in1': [114]},\n",
       "  {'in0': [460], 'in1': [289]},\n",
       "  {'in0': [688], 'in1': [678]},\n",
       "  {'in0': [65], 'in1': [202]},\n",
       "  {'in0': [698], 'in1': [529]},\n",
       "  {'in0': [72], 'in1': [234]},\n",
       "  {'in0': [117], 'in1': [829]},\n",
       "  {'in0': [106], 'in1': [692]},\n",
       "  {'in0': [594], 'in1': [14]},\n",
       "  {'in0': [87], 'in1': [274]},\n",
       "  {'in0': [197], 'in1': [300]},\n",
       "  {'in0': [342], 'in1': [1007]},\n",
       "  {'in0': [691], 'in1': [294]},\n",
       "  {'in0': [755], 'in1': [302]},\n",
       "  {'in0': [603], 'in1': [11]},\n",
       "  {'in0': [192], 'in1': [1061]},\n",
       "  {'in0': [350], 'in1': [176]},\n",
       "  {'in0': [92], 'in1': [77]},\n",
       "  {'in0': [40], 'in1': [340]},\n",
       "  {'in0': [498], 'in1': [187]},\n",
       "  {'in0': [308], 'in1': [640]},\n",
       "  {'in0': [713], 'in1': [1431]},\n",
       "  {'in0': [833], 'in1': [340]},\n",
       "  {'in0': [507], 'in1': [826]},\n",
       "  {'in0': [747], 'in1': [1050]},\n",
       "  {'in0': [364], 'in1': [289]},\n",
       "  {'in0': [825], 'in1': [369]},\n",
       "  {'in0': [214], 'in1': [568]},\n",
       "  {'in0': [117], 'in1': [50]},\n",
       "  {'in0': [495], 'in1': [413]},\n",
       "  {'in0': [341], 'in1': [887]},\n",
       "  {'in0': [467], 'in1': [257]},\n",
       "  {'in0': [219], 'in1': [179]},\n",
       "  {'in0': [77], 'in1': [238]},\n",
       "  {'in0': [425], 'in1': [748]},\n",
       "  {'in0': [847], 'in1': [763]},\n",
       "  {'in0': [765], 'in1': [248]},\n",
       "  {'in0': [258], 'in1': [893]},\n",
       "  {'in0': [711], 'in1': [720]},\n",
       "  {'in0': [86], 'in1': [327]},\n",
       "  {'in0': [344], 'in1': [306]},\n",
       "  {'in0': [690], 'in1': [790]},\n",
       "  {'in0': [734], 'in1': [82]},\n",
       "  {'in0': [20], 'in1': [194]},\n",
       "  {'in0': [68], 'in1': [405]},\n",
       "  {'in0': [451], 'in1': [243]},\n",
       "  {'in0': [856], 'in1': [749]},\n",
       "  {'in0': [774], 'in1': [576]},\n",
       "  {'in0': [66], 'in1': [1]},\n",
       "  {'in0': [314], 'in1': [535]},\n",
       "  {'in0': [616], 'in1': [269]},\n",
       "  {'in0': [559], 'in1': [514]},\n",
       "  {'in0': [624], 'in1': [748]},\n",
       "  {'in0': [239], 'in1': [272]},\n",
       "  {'in0': [832], 'in1': [328]},\n",
       "  {'in0': [322], 'in1': [192]},\n",
       "  {'in0': [290], 'in1': [143]},\n",
       "  {'in0': [35], 'in1': [680]},\n",
       "  {'in0': [393], 'in1': [471]},\n",
       "  {'in0': [180], 'in1': [737]},\n",
       "  {'in0': [162], 'in1': [742]},\n",
       "  {'in0': [564], 'in1': [257]},\n",
       "  {'in0': [305], 'in1': [214]},\n",
       "  {'in0': [31], 'in1': [484]},\n",
       "  {'in0': [767], 'in1': [478]},\n",
       "  {'in0': [823], 'in1': [31]},\n",
       "  {'in0': [16], 'in1': [705]},\n",
       "  {'in0': [426], 'in1': [429]},\n",
       "  {'in0': [128], 'in1': [485]},\n",
       "  {'in0': [218], 'in1': [273]},\n",
       "  {'in0': [555], 'in1': [236]},\n",
       "  {'in0': [679], 'in1': [327]},\n",
       "  {'in0': [230], 'in1': [1444]},\n",
       "  {'in0': [801], 'in1': [259]},\n",
       "  {'in0': [686], 'in1': [357]},\n",
       "  {'in0': [227], 'in1': [286]},\n",
       "  {'in0': [87], 'in1': [210]},\n",
       "  {'in0': [643], 'in1': [419]},\n",
       "  {'in0': [90], 'in1': [900]},\n",
       "  {'in0': [610], 'in1': [11]},\n",
       "  {'in0': [243], 'in1': [129]},\n",
       "  {'in0': [586], 'in1': [628]},\n",
       "  {'in0': [812], 'in1': [288]},\n",
       "  {'in0': [681], 'in1': [898]},\n",
       "  {'in0': [819], 'in1': [1160]},\n",
       "  {'in0': [251], 'in1': [257]},\n",
       "  {'in0': [678], 'in1': [147]},\n",
       "  {'in0': [872], 'in1': [237]},\n",
       "  {'in0': [766], 'in1': [53]},\n",
       "  {'in0': [147], 'in1': [258]},\n",
       "  {'in0': [198], 'in1': [179]},\n",
       "  {'in0': [70], 'in1': [746]},\n",
       "  {'in0': [444], 'in1': [906]},\n",
       "  {'in0': [136], 'in1': [298]},\n",
       "  {'in0': [854], 'in1': [87]},\n",
       "  {'in0': [162], 'in1': [25]},\n",
       "  {'in0': [726], 'in1': [274]},\n",
       "  {'in0': [451], 'in1': [323]},\n",
       "  {'in0': [39], 'in1': [306]},\n",
       "  {'in0': [354], 'in1': [133]},\n",
       "  {'in0': [104], 'in1': [301]},\n",
       "  {'in0': [73], 'in1': [127]},\n",
       "  {'in0': [675], 'in1': [531]},\n",
       "  {'in0': [376], 'in1': [237]},\n",
       "  {'in0': [791], 'in1': [269]},\n",
       "  {'in0': [592], 'in1': [433]},\n",
       "  {'in0': [49], 'in1': [559]},\n",
       "  {'in0': [11], 'in1': [110]},\n",
       "  {'in0': [35], 'in1': [261]},\n",
       "  {'in0': [896], 'in1': [1101]},\n",
       "  {'in0': [691], 'in1': [603]},\n",
       "  {'in0': [902], 'in1': [50]},\n",
       "  {'in0': [3], 'in1': [343]},\n",
       "  {'in0': [91], 'in1': [323]},\n",
       "  {'in0': [579], 'in1': [845]},\n",
       "  {'in0': [292], 'in1': [276]},\n",
       "  {'in0': [348], 'in1': [819]},\n",
       "  {'in0': [654], 'in1': [222]},\n",
       "  {'in0': [6], 'in1': [23]},\n",
       "  {'in0': [722], 'in1': [147]},\n",
       "  {'in0': [815], 'in1': [524]},\n",
       "  {'in0': [67], 'in1': [240]},\n",
       "  {'in0': [766], 'in1': [82]},\n",
       "  {'in0': [133], 'in1': [315]},\n",
       "  {'in0': [158], 'in1': [1098]},\n",
       "  {'in0': [196], 'in1': [67]},\n",
       "  {'in0': [212], 'in1': [527]},\n",
       "  {'in0': [518], 'in1': [934]},\n",
       "  {'in0': [466], 'in1': [331]},\n",
       "  {'in0': [904], 'in1': [421]},\n",
       "  {'in0': [92], 'in1': [501]},\n",
       "  {'in0': [50], 'in1': [9]},\n",
       "  {'in0': [301], 'in1': [98]},\n",
       "  {'in0': [719], 'in1': [660]},\n",
       "  {'in0': [378], 'in1': [1267]},\n",
       "  {'in0': [270], 'in1': [736]},\n",
       "  {'in0': [925], 'in1': [948]},\n",
       "  {'in0': [99], 'in1': [274]},\n",
       "  {'in0': [674], 'in1': [118]},\n",
       "  {'in0': [347], 'in1': [416]},\n",
       "  {'in0': [640], 'in1': [385]},\n",
       "  {'in0': [301], 'in1': [604]},\n",
       "  {'in0': [190], 'in1': [977]},\n",
       "  {'in0': [592], 'in1': [20]},\n",
       "  {'in0': [730], 'in1': [815]},\n",
       "  {'in0': [312], 'in1': [133]},\n",
       "  {'in0': [721], 'in1': [87]},\n",
       "  {'in0': [481], 'in1': [42]},\n",
       "  {'in0': [907], 'in1': [100]},\n",
       "  {'in0': [667], 'in1': [651]},\n",
       "  {'in0': [622], 'in1': [993]},\n",
       "  {'in0': [738], 'in1': [151]},\n",
       "  {'in0': [908], 'in1': [173]},\n",
       "  {'in0': [788], 'in1': [480]},\n",
       "  {'in0': [53], 'in1': [845]},\n",
       "  {'in0': [913], 'in1': [92]},\n",
       "  {'in0': [662], 'in1': [515]},\n",
       "  {'in0': [7], 'in1': [492]},\n",
       "  {'in0': [638], 'in1': [183]},\n",
       "  {'in0': [593], 'in1': [633]},\n",
       "  {'in0': [342], 'in1': [792]},\n",
       "  {'in0': [700], 'in1': [180]},\n",
       "  {'in0': [211], 'in1': [310]},\n",
       "  {'in0': [645], 'in1': [675]},\n",
       "  {'in0': [842], 'in1': [751]},\n",
       "  {'in0': [109], 'in1': [475]},\n",
       "  {'in0': [700], 'in1': [96]},\n",
       "  {'in0': [259], 'in1': [750]},\n",
       "  {'in0': [345], 'in1': [88]},\n",
       "  {'in0': [932], 'in1': [105]},\n",
       "  {'in0': [755], 'in1': [689]},\n",
       "  {'in0': [943], 'in1': [356]},\n",
       "  {'in0': [659], 'in1': [569]},\n",
       "  {'in0': [469], 'in1': [641]},\n",
       "  {'in0': [859], 'in1': [762]},\n",
       "  {'in0': [727], 'in1': [117]},\n",
       "  {'in0': [774], 'in1': [739]},\n",
       "  {'in0': [536], 'in1': [70]},\n",
       "  {'in0': [448], 'in1': [292]},\n",
       "  {'in0': [682], 'in1': [68]},\n",
       "  {'in0': [766], 'in1': [229]},\n",
       "  {'in0': [495], 'in1': [174]},\n",
       "  {'in0': [848], 'in1': [164]},\n",
       "  {'in0': [836], 'in1': [507]},\n",
       "  {'in0': [554], 'in1': [87]},\n",
       "  {'in0': [488], 'in1': [198]},\n",
       "  {'in0': [587], 'in1': [347]},\n",
       "  {'in0': [107], 'in1': [340]},\n",
       "  {'in0': [651], 'in1': [683]},\n",
       "  {'in0': [53], 'in1': [199]},\n",
       "  {'in0': [905], 'in1': [245]},\n",
       "  {'in0': [923], 'in1': [762]},\n",
       "  {'in0': [770], 'in1': [508]},\n",
       "  {'in0': [721], 'in1': [879]},\n",
       "  {'in0': [41], 'in1': [28]},\n",
       "  {'in0': [782], 'in1': [984]},\n",
       "  {'in0': [914], 'in1': [155]},\n",
       "  {'in0': [557], 'in1': [262]},\n",
       "  {'in0': [847], 'in1': [826]},\n",
       "  {'in0': [271], 'in1': [346]},\n",
       "  {'in0': [825], 'in1': [283]},\n",
       "  {'in0': [853], 'in1': [292]},\n",
       "  {'in0': [386], 'in1': [121]},\n",
       "  {'in0': [294], 'in1': [1245]},\n",
       "  {'in0': [510], 'in1': [678]},\n",
       "  {'in0': [212], 'in1': [515]},\n",
       "  {'in0': [296], 'in1': [228]},\n",
       "  {'in0': [546], 'in1': [288]},\n",
       "  {'in0': [776], 'in1': [442]},\n",
       "  {'in0': [241], 'in1': [294]},\n",
       "  {'in0': [66], 'in1': [7]},\n",
       "  {'in0': [577], 'in1': [662]},\n",
       "  {'in0': [940], 'in1': [14]},\n",
       "  {'in0': [917], 'in1': [740]},\n",
       "  {'in0': [113], 'in1': [294]},\n",
       "  {'in0': [683], 'in1': [511]},\n",
       "  {'in0': [229], 'in1': [315]},\n",
       "  {'in0': [300], 'in1': [872]},\n",
       "  {'in0': [382], 'in1': [276]},\n",
       "  {'in0': [630], 'in1': [127]},\n",
       "  {'in0': [258], 'in1': [873]},\n",
       "  {'in0': [598], 'in1': [750]},\n",
       "  {'in0': [865], 'in1': [7]},\n",
       "  {'in0': [903], 'in1': [746]},\n",
       "  {'in0': [595], 'in1': [289]},\n",
       "  {'in0': [635], 'in1': [294]},\n",
       "  {'in0': [426], 'in1': [603]},\n",
       "  {'in0': [203], 'in1': [282]},\n",
       "  {'in0': [499], 'in1': [238]},\n",
       "  {'in0': [668], 'in1': [354]},\n",
       "  {'in0': [820], 'in1': [264]},\n",
       "  {'in0': [125], 'in1': [134]},\n",
       "  {'in0': [559], 'in1': [524]},\n",
       "  {'in0': [158], 'in1': [24]},\n",
       "  {'in0': [502], 'in1': [539]},\n",
       "  {'in0': [345], 'in1': [708]},\n",
       "  {'in0': [229], 'in1': [347]},\n",
       "  {'in0': [188], 'in1': [96]},\n",
       "  {'in0': [124], 'in1': [550]},\n",
       "  {'in0': [176], 'in1': [324]},\n",
       "  {'in0': [751], 'in1': [568]},\n",
       "  {'in0': [327], 'in1': [192]},\n",
       "  {'in0': [670], 'in1': [174]},\n",
       "  {'in0': [446], 'in1': [311]},\n",
       "  {'in0': [212], 'in1': [511]},\n",
       "  {'in0': [431], 'in1': [307]},\n",
       "  {'in0': [708], 'in1': [1051]},\n",
       "  {'in0': [200], 'in1': [478]},\n",
       "  {'in0': [394], 'in1': [568]},\n",
       "  {'in0': [310], 'in1': [258]},\n",
       "  {'in0': [380], 'in1': [530]},\n",
       "  {'in0': [413], 'in1': [306]},\n",
       "  {'in0': [646], 'in1': [683]},\n",
       "  {'in0': [850], 'in1': [8]},\n",
       "  {'in0': [628], 'in1': [874]},\n",
       "  {'in0': [347], 'in1': [1035]},\n",
       "  {'in0': [55], 'in1': [144]},\n",
       "  {'in0': [11], 'in1': [732]},\n",
       "  {'in0': [5], 'in1': [98]},\n",
       "  {'in0': [855], 'in1': [1021]},\n",
       "  {'in0': [904], 'in1': [778]},\n",
       "  {'in0': [432], 'in1': [222]},\n",
       "  {'in0': [563], 'in1': [412]},\n",
       "  {'in0': [37], 'in1': [56]},\n",
       "  {'in0': [284], 'in1': [906]},\n",
       "  {'in0': [550], 'in1': [846]},\n",
       "  {'in0': [322], 'in1': [50]},\n",
       "  {'in0': [432], 'in1': [411]},\n",
       "  {'in0': [720], 'in1': [906]},\n",
       "  {'in0': [789], 'in1': [294]},\n",
       "  {'in0': [840], 'in1': [647]},\n",
       "  {'in0': [124], 'in1': [496]},\n",
       "  {'in0': [197], 'in1': [515]},\n",
       "  {'in0': [621], 'in1': [147]},\n",
       "  {'in0': [850], 'in1': [56]},\n",
       "  {'in0': [203], 'in1': [117]},\n",
       "  {'in0': [823], 'in1': [211]},\n",
       "  {'in0': [29], 'in1': [245]},\n",
       "  {'in0': [315], 'in1': [17]},\n",
       "  {'in0': [277], 'in1': [279]},\n",
       "  {'in0': [457], 'in1': [708]},\n",
       "  {'in0': [109], 'in1': [1012]},\n",
       "  {'in0': [806], 'in1': [324]},\n",
       "  {'in0': [666], 'in1': [122]},\n",
       "  {'in0': [85], 'in1': [427]},\n",
       "  {'in0': [326], 'in1': [186]},\n",
       "  {'in0': [240], 'in1': [898]},\n",
       "  {'in0': [323], 'in1': [127]},\n",
       "  {'in0': [335], 'in1': [678]},\n",
       "  {'in0': [698], 'in1': [95]},\n",
       "  {'in0': [383], 'in1': [475]},\n",
       "  {'in0': [266], 'in1': [124]},\n",
       "  {'in0': [62], 'in1': [382]},\n",
       "  {'in0': [281], 'in1': [322]},\n",
       "  {'in0': [514], 'in1': [328]},\n",
       "  {'in0': [901], 'in1': [22]},\n",
       "  {'in0': [638], 'in1': [181]},\n",
       "  {'in0': [813], 'in1': [901]},\n",
       "  {'in0': [765], 'in1': [15]},\n",
       "  {'in0': [482], 'in1': [295]},\n",
       "  {'in0': [738], 'in1': [188]},\n",
       "  {'in0': [838], 'in1': [732]},\n",
       "  {'in0': [856], 'in1': [313]},\n",
       "  {'in0': [312], 'in1': [921]},\n",
       "  {'in0': [913], 'in1': [99]},\n",
       "  {'in0': [11], 'in1': [111]},\n",
       "  {'in0': [839], 'in1': [825]},\n",
       "  {'in0': [885], 'in1': [210]},\n",
       "  {'in0': [201], 'in1': [649]},\n",
       "  {'in0': [710], 'in1': [751]},\n",
       "  {'in0': [677], 'in1': [1]},\n",
       "  {'in0': [37], 'in1': [117]},\n",
       "  {'in0': [207], 'in1': [1115]},\n",
       "  {'in0': [520], 'in1': [269]},\n",
       "  {'in0': [177], 'in1': [69]},\n",
       "  {'in0': [616], 'in1': [300]},\n",
       "  {'in0': [595], 'in1': [1134]},\n",
       "  {'in0': [661], 'in1': [132]},\n",
       "  {'in0': [856], 'in1': [750]},\n",
       "  {'in0': [179], 'in1': [305]},\n",
       "  {'in0': [844], 'in1': [90]},\n",
       "  {'in0': [412], 'in1': [427]},\n",
       "  {'in0': [313], 'in1': [99]},\n",
       "  {'in0': [229], 'in1': [875]},\n",
       "  {'in0': [129], 'in1': [339]},\n",
       "  {'in0': [371], 'in1': [24]},\n",
       "  {'in0': [569], 'in1': [151]},\n",
       "  {'in0': [359], 'in1': [313]},\n",
       "  {'in0': [725], 'in1': [245]},\n",
       "  {'in0': [932], 'in1': [55]},\n",
       "  {'in0': [285], 'in1': [216]},\n",
       "  {'in0': [536], 'in1': [274]},\n",
       "  {'in0': [638], 'in1': [50]},\n",
       "  {'in0': [442], 'in1': [98]},\n",
       "  {'in0': [841], 'in1': [331]},\n",
       "  {'in0': [88], 'in1': [750]},\n",
       "  {'in0': [508], 'in1': [223]},\n",
       "  {'in0': [560], 'in1': [203]},\n",
       "  {'in0': [211], 'in1': [678]},\n",
       "  {'in0': [623], 'in1': [642]},\n",
       "  {'in0': [875], 'in1': [171]},\n",
       "  {'in0': [622], 'in1': [2]},\n",
       "  {'in0': [825], 'in1': [276]},\n",
       "  {'in0': [198], 'in1': [118]},\n",
       "  {'in0': [389], 'in1': [124]},\n",
       "  {'in0': [390], 'in1': [328]},\n",
       "  {'in0': [585], 'in1': [463]},\n",
       "  {'in0': [551], 'in1': [365]},\n",
       "  {'in0': [523], 'in1': [382]},\n",
       "  {'in0': [478], 'in1': [282]},\n",
       "  {'in0': [415], 'in1': [479]},\n",
       "  {'in0': [663], 'in1': [658]},\n",
       "  {'in0': [352], 'in1': [7]},\n",
       "  {'in0': [385], 'in1': [606]},\n",
       "  {'in0': [175], 'in1': [183]},\n",
       "  {'in0': [459], 'in1': [194]},\n",
       "  {'in0': [832], 'in1': [334]},\n",
       "  {'in0': [229], 'in1': [260]},\n",
       "  {'in0': [397], 'in1': [7]},\n",
       "  {'in0': [402], 'in1': [255]},\n",
       "  {'in0': [895], 'in1': [597]},\n",
       "  {'in0': [880], 'in1': [386]},\n",
       "  {'in0': [555], 'in1': [249]},\n",
       "  {'in0': [915], 'in1': [304]},\n",
       "  {'in0': [244], 'in1': [186]},\n",
       "  {'in0': [770], 'in1': [118]},\n",
       "  {'in0': [414], 'in1': [300]},\n",
       "  {'in0': [124], 'in1': [50]},\n",
       "  {'in0': [861], 'in1': [86]},\n",
       "  {'in0': [138], 'in1': [496]},\n",
       "  {'in0': [38], 'in1': [679]},\n",
       "  {'in0': [773], 'in1': [64]},\n",
       "  {'in0': [747], 'in1': [208]},\n",
       "  {'in0': [414], 'in1': [260]},\n",
       "  {'in0': [58], 'in1': [709]},\n",
       "  {'in0': [209], 'in1': [251]},\n",
       "  {'in0': [854], 'in1': [979]},\n",
       "  {'in0': [672], 'in1': [1061]},\n",
       "  {'in0': [189], 'in1': [20]},\n",
       "  {'in0': [675], 'in1': [306]},\n",
       "  {'in0': [428], 'in1': [875]},\n",
       "  {'in0': [677], 'in1': [148]},\n",
       "  {'in0': [413], 'in1': [301]},\n",
       "  {'in0': [339], 'in1': [856]},\n",
       "  {'in0': [550], 'in1': [259]},\n",
       "  {'in0': [695], 'in1': [995]},\n",
       "  {'in0': [863], 'in1': [301]},\n",
       "  {'in0': [704], 'in1': [209]},\n",
       "  {'in0': [875], 'in1': [772]},\n",
       "  {'in0': [302], 'in1': [307]},\n",
       "  {'in0': [616], 'in1': [1313]},\n",
       "  {'in0': [919], 'in1': [358]},\n",
       "  {'in0': [791], 'in1': [286]},\n",
       "  {'in0': [94], 'in1': [1224]},\n",
       "  {'in0': [325], 'in1': [179]},\n",
       "  {'in0': [299], 'in1': [144]},\n",
       "  {'in0': [55], 'in1': [257]},\n",
       "  {'in0': [97], 'in1': [482]},\n",
       "  {'in0': [284], 'in1': [259]},\n",
       "  {'in0': [393], 'in1': [402]},\n",
       "  {'in0': [83], 'in1': [78]},\n",
       "  {'in0': [193], 'in1': [941]},\n",
       "  {'in0': [597], 'in1': [824]},\n",
       "  {'in0': [284], 'in1': [258]},\n",
       "  {'in0': [263], 'in1': [568]},\n",
       "  {'in0': [404], 'in1': [313]},\n",
       "  {'in0': [427], 'in1': [319]},\n",
       "  {'in0': [851], 'in1': [1009]},\n",
       "  {'in0': [847], 'in1': [238]},\n",
       "  {'in0': [74], 'in1': [272]},\n",
       "  {'in0': [805], 'in1': [755]},\n",
       "  {'in0': [220], 'in1': [306]},\n",
       "  {'in0': [516], 'in1': [50]},\n",
       "  {'in0': [29], 'in1': [332]},\n",
       "  {'in0': [205], 'in1': [304]},\n",
       "  {'in0': [574], 'in1': [321]},\n",
       "  {'in0': [25], 'in1': [222]},\n",
       "  {'in0': [604], 'in1': [234]},\n",
       "  {'in0': [499], 'in1': [210]},\n",
       "  {'in0': [606], 'in1': [620]},\n",
       "  {'in0': [664], 'in1': [187]},\n",
       "  {'in0': [37], 'in1': [403]},\n",
       "  {'in0': [418], 'in1': [362]},\n",
       "  {'in0': [792], 'in1': [1132]},\n",
       "  {'in0': [158], 'in1': [177]},\n",
       "  {'in0': [98], 'in1': [938]},\n",
       "  {'in0': [313], 'in1': [616]},\n",
       "  {'in0': [75], 'in1': [121]},\n",
       "  {'in0': [915], 'in1': [328]},\n",
       "  {'in0': [773], 'in1': [72]},\n",
       "  {'in0': [48], 'in1': [661]},\n",
       "  {'in0': [717], 'in1': [294]},\n",
       "  {'in0': [226], 'in1': [180]},\n",
       "  {'in0': [743], 'in1': [224]},\n",
       "  {'in0': [911], 'in1': [168]},\n",
       "  {'in0': [772], 'in1': [321]},\n",
       "  {'in0': [117], 'in1': [150]},\n",
       "  {'in0': [681], 'in1': [690]},\n",
       "  {'in0': [710], 'in1': [627]},\n",
       "  {'in0': [757], 'in1': [196]},\n",
       "  {'in0': [481], 'in1': [318]},\n",
       "  {'in0': [459], 'in1': [978]},\n",
       "  {'in0': [295], 'in1': [72]},\n",
       "  {'in0': [900], 'in1': [121]},\n",
       "  {'in0': [109], 'in1': [8]},\n",
       "  {'in0': [252], 'in1': [275]},\n",
       "  {'in0': [870], 'in1': [466]},\n",
       "  {'in0': [73], 'in1': [588]},\n",
       "  {'in0': [678], 'in1': [7]},\n",
       "  {'in0': [339], 'in1': [55]},\n",
       "  {'in0': [398], 'in1': [504]},\n",
       "  {'in0': [532], 'in1': [603]},\n",
       "  {'in0': [370], 'in1': [116]},\n",
       "  {'in0': [637], 'in1': [831]},\n",
       "  {'in0': [378], 'in1': [202]},\n",
       "  {'in0': [162], 'in1': [685]},\n",
       "  {'in0': [771], 'in1': [88]},\n",
       "  {'in0': [293], 'in1': [249]},\n",
       "  {'in0': [421], 'in1': [238]},\n",
       "  {'in0': [816], 'in1': [288]},\n",
       "  {'in0': [151], 'in1': [197]},\n",
       "  {'in0': [26], 'in1': [685]},\n",
       "  {'in0': [739], 'in1': [132]},\n",
       "  {'in0': [167], 'in1': [404]},\n",
       "  {'in0': [605], 'in1': [527]},\n",
       "  {'in0': [38], 'in1': [95]},\n",
       "  {'in0': [225], 'in1': [480]},\n",
       "  {'in0': [347], 'in1': [168]},\n",
       "  {'in0': [480], 'in1': [234]},\n",
       "  {'in0': [506], 'in1': [385]},\n",
       "  {'in0': [303], 'in1': [842]},\n",
       "  {'in0': [678], 'in1': [111]},\n",
       "  {'in0': [890], 'in1': [181]},\n",
       "  {'in0': [138], 'in1': [483]},\n",
       "  {'in0': [809], 'in1': [748]},\n",
       "  {'in0': [545], 'in1': [25]},\n",
       "  {'in0': [286], 'in1': [153]},\n",
       "  {'in0': [32], 'in1': [1012]},\n",
       "  {'in0': [428], 'in1': [750]},\n",
       "  {'in0': [860], 'in1': [159]},\n",
       "  {'in0': [415], 'in1': [154]},\n",
       "  {'in0': [940], 'in1': [315]},\n",
       "  {'in0': [367], 'in1': [246]},\n",
       "  {'in0': [569], 'in1': [924]},\n",
       "  {'in0': [617], 'in1': [98]},\n",
       "  {'in0': [809], 'in1': [678]},\n",
       "  {'in0': [644], 'in1': [326]},\n",
       "  {'in0': [697], 'in1': [713]},\n",
       "  {'in0': [231], 'in1': [748]},\n",
       "  {'in0': [904], 'in1': [739]},\n",
       "  {'in0': [378], 'in1': [8]},\n",
       "  {'in0': [351], 'in1': [873]},\n",
       "  {'in0': [605], 'in1': [174]},\n",
       "  {'in0': [246], 'in1': [561]},\n",
       "  {'in0': [605], 'in1': [127]},\n",
       "  {'in0': [359], 'in1': [455]},\n",
       "  {'in0': [112], 'in1': [322]},\n",
       "  {'in0': [539], 'in1': [483]},\n",
       "  {'in0': [343], 'in1': [1107]},\n",
       "  {'in0': [536], 'in1': [2]},\n",
       "  {'in0': [766], 'in1': [483]},\n",
       "  {'in0': [720], 'in1': [306]},\n",
       "  {'in0': [112], 'in1': [748]},\n",
       "  {'in0': [689], 'in1': [471]},\n",
       "  {'in0': [227], 'in1': [50]},\n",
       "  {'in0': [10], 'in1': [486]},\n",
       "  {'in0': [889], 'in1': [659]},\n",
       "  {'in0': [319], 'in1': [880]},\n",
       "  {'in0': [936], 'in1': [106]},\n",
       "  {'in0': [845], 'in1': [311]},\n",
       "  {'in0': [177], 'in1': [333]},\n",
       "  {'in0': [826], 'in1': [172]},\n",
       "  {'in0': [695], 'in1': [882]},\n",
       "  {'in0': [597], 'in1': [988]},\n",
       "  {'in0': [375], 'in1': [44]},\n",
       "  {'in0': [724], 'in1': [305]},\n",
       "  {'in0': [867], 'in1': [196]},\n",
       "  {'in0': [735], 'in1': [690]},\n",
       "  {'in0': [417], 'in1': [781]},\n",
       "  {'in0': [921], 'in1': [313]},\n",
       "  {'in0': [500], 'in1': [1012]},\n",
       "  {'in0': [816], 'in1': [294]},\n",
       "  {'in0': [349], 'in1': [847]},\n",
       "  {'in0': [854], 'in1': [475]},\n",
       "  {'in0': [371], 'in1': [237]},\n",
       "  {'in0': [189], 'in1': [526]},\n",
       "  {'in0': [160], 'in1': [462]},\n",
       "  {'in0': [149], 'in1': [312]},\n",
       "  {'in0': [218], 'in1': [208]},\n",
       "  {'in0': [351], 'in1': [984]},\n",
       "  {'in0': [639], 'in1': [88]},\n",
       "  {'in0': [531], 'in1': [288]},\n",
       "  {'in0': [768], 'in1': [1016]},\n",
       "  {'in0': [206], 'in1': [362]},\n",
       "  {'in0': [389], 'in1': [160]},\n",
       "  {'in0': [186], 'in1': [281]},\n",
       "  {'in0': [143], 'in1': [331]},\n",
       "  {'in0': [312], 'in1': [28]},\n",
       "  {'in0': [509], 'in1': [300]},\n",
       "  {'in0': [267], 'in1': [840]},\n",
       "  {'in0': [340], 'in1': [1]},\n",
       "  {'in0': [181], 'in1': [1081]},\n",
       "  {'in0': [808], 'in1': [294]},\n",
       "  {'in0': [792], 'in1': [595]},\n",
       "  {'in0': [595], 'in1': [825]},\n",
       "  {'in0': [87], 'in1': [554]},\n",
       "  {'in0': [672], 'in1': [50]},\n",
       "  {'in0': [89], 'in1': [117]},\n",
       "  {'in0': [5], 'in1': [2]},\n",
       "  {'in0': [807], 'in1': [117]},\n",
       "  {'in0': [334], 'in1': [117]},\n",
       "  {'in0': [227], 'in1': [117]},\n",
       "  {'in0': [85], 'in1': [259]},\n",
       "  {'in0': [121], 'in1': [14]},\n",
       "  {'in0': [10], 'in1': [504]},\n",
       "  {'in0': [177], 'in1': [56]},\n",
       "  {'in0': [448], 'in1': [262]},\n",
       "  {'in0': [70], 'in1': [584]},\n",
       "  {'in0': [608], 'in1': [69]},\n",
       "  {'in0': [531], 'in1': [905]},\n",
       "  {'in0': [658], 'in1': [137]},\n",
       "  {'in0': [757], 'in1': [7]},\n",
       "  {'in0': [30], 'in1': [688]},\n",
       "  {'in0': [113], 'in1': [126]},\n",
       "  {'in0': [20], 'in1': [186]},\n",
       "  {'in0': [669], 'in1': [537]},\n",
       "  {'in0': [645], 'in1': [1018]},\n",
       "  {'in0': [615], 'in1': [289]},\n",
       "  {'in0': [361], 'in1': [26]},\n",
       "  {'in0': [3], 'in1': [323]},\n",
       "  {'in0': [311], 'in1': [716]},\n",
       "  {'in0': [716], 'in1': [159]},\n",
       "  {'in0': [430], 'in1': [253]},\n",
       "  {'in0': [157], 'in1': [1132]},\n",
       "  {'in0': [834], 'in1': [269]},\n",
       "  {'in0': [173], 'in1': [294]},\n",
       "  {'in0': [645], 'in1': [175]},\n",
       "  {'in0': [865], 'in1': [929]},\n",
       "  {'in0': [747], 'in1': [432]},\n",
       "  {'in0': [268], 'in1': [147]},\n",
       "  {'in0': [672], 'in1': [931]},\n",
       "  {'in0': [90], 'in1': [1086]},\n",
       "  {'in0': [292], 'in1': [174]},\n",
       "  {'in0': [702], 'in1': [288]},\n",
       "  {'in0': [105], 'in1': [324]},\n",
       "  {'in0': [524], 'in1': [605]},\n",
       "  {'in0': [235], 'in1': [1149]},\n",
       "  {'in0': [495], 'in1': [153]},\n",
       "  {'in0': [99], 'in1': [79]},\n",
       "  {'in0': [18], 'in1': [182]},\n",
       "  {'in0': [788], 'in1': [229]},\n",
       "  {'in0': [187], 'in1': [64]},\n",
       "  {'in0': [811], 'in1': [690]},\n",
       "  {'in0': [821], 'in1': [275]},\n",
       "  {'in0': [247], 'in1': [50]},\n",
       "  {'in0': [585], 'in1': [1488]},\n",
       "  {'in0': [209], 'in1': [408]},\n",
       "  {'in0': [10], 'in1': [488]},\n",
       "  {'in0': [409], 'in1': [48]},\n",
       "  {'in0': [703], 'in1': [458]},\n",
       "  {'in0': [416], 'in1': [348]},\n",
       "  {'in0': [612], 'in1': [9]},\n",
       "  {'in0': [81], 'in1': [3]},\n",
       "  {'in0': [141], 'in1': [535]},\n",
       "  {'in0': [855], 'in1': [529]},\n",
       "  {'in0': [130], 'in1': [1014]},\n",
       "  {'in0': [586], 'in1': [148]},\n",
       "  {'in0': [370], 'in1': [42]},\n",
       "  {'in0': [750], 'in1': [270]},\n",
       "  {'in0': [93], 'in1': [477]},\n",
       "  {'in0': [548], 'in1': [1051]},\n",
       "  {'in0': [600], 'in1': [2]},\n",
       "  {'in0': [58], 'in1': [173]},\n",
       "  {'in0': [518], 'in1': [763]},\n",
       "  {'in0': [805], 'in1': [319]},\n",
       "  {'in0': [380], 'in1': [176]},\n",
       "  {'in0': [347], 'in1': [465]},\n",
       "  {'in0': [390], 'in1': [740]},\n",
       "  {'in0': [261], 'in1': [875]},\n",
       "  {'in0': [295], 'in1': [39]},\n",
       "  {'in0': [556], 'in1': [496]},\n",
       "  ...)}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_r_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean squared error on validation set is 0.920\n"
     ]
    }
   ],
   "source": [
    "# Send data to the endpoint to get predictions\n",
    "prediction = predictor.predict(valid_r_data)\n",
    "\n",
    "print(\"The mean squared error on validation set is %.3f\" %get_mse_loss(prediction, valid_r_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'predictions': [{u'scores': [3.597803115844726]},\n",
       "  {u'scores': [2.735705375671387]},\n",
       "  {u'scores': [3.625868797302246]},\n",
       "  {u'scores': [3.801055669784546]},\n",
       "  {u'scores': [3.684390544891357]},\n",
       "  {u'scores': [3.775695562362671]},\n",
       "  {u'scores': [2.241666078567505]},\n",
       "  {u'scores': [4.466606616973877]},\n",
       "  {u'scores': [4.465542793273926]},\n",
       "  {u'scores': [4.127090454101562]},\n",
       "  {u'scores': [4.563428401947022]},\n",
       "  {u'scores': [4.024839401245117]},\n",
       "  {u'scores': [3.430050373077393]},\n",
       "  {u'scores': [2.981707572937012]},\n",
       "  {u'scores': [3.621645212173462]},\n",
       "  {u'scores': [4.010890960693359]},\n",
       "  {u'scores': [3.533648490905762]},\n",
       "  {u'scores': [3.565757274627686]},\n",
       "  {u'scores': [3.840738534927368]},\n",
       "  {u'scores': [3.861855506896973]},\n",
       "  {u'scores': [3.581881761550903]},\n",
       "  {u'scores': [2.38650369644165]},\n",
       "  {u'scores': [3.386643171310425]},\n",
       "  {u'scores': [3.032790184020996]},\n",
       "  {u'scores': [3.996105432510376]},\n",
       "  {u'scores': [3.341681003570557]},\n",
       "  {u'scores': [3.370140552520752]},\n",
       "  {u'scores': [3.975619554519653]},\n",
       "  {u'scores': [3.237789630889893]},\n",
       "  {u'scores': [4.170483112335205]},\n",
       "  {u'scores': [3.675633907318115]},\n",
       "  {u'scores': [3.637822151184082]},\n",
       "  {u'scores': [4.533543109893799]},\n",
       "  {u'scores': [2.502171039581299]},\n",
       "  {u'scores': [2.710251331329346]},\n",
       "  {u'scores': [3.406121253967285]},\n",
       "  {u'scores': [2.755037546157837]},\n",
       "  {u'scores': [3.54956579208374]},\n",
       "  {u'scores': [3.462348937988281]},\n",
       "  {u'scores': [4.838602542877197]},\n",
       "  {u'scores': [3.451783895492554]},\n",
       "  {u'scores': [3.192203760147095]},\n",
       "  {u'scores': [2.865221500396728]},\n",
       "  {u'scores': [4.159383296966553]},\n",
       "  {u'scores': [3.849921226501465]},\n",
       "  {u'scores': [3.891846895217896]},\n",
       "  {u'scores': [3.997643232345581]},\n",
       "  {u'scores': [3.061802864074707]},\n",
       "  {u'scores': [3.228869676589966]},\n",
       "  {u'scores': [3.342735290527344]},\n",
       "  {u'scores': [3.715858697891235]},\n",
       "  {u'scores': [4.60994291305542]},\n",
       "  {u'scores': [3.405287981033325]},\n",
       "  {u'scores': [3.498568534851074]},\n",
       "  {u'scores': [3.741482734680176]},\n",
       "  {u'scores': [3.057437419891357]},\n",
       "  {u'scores': [3.922959804534912]},\n",
       "  {u'scores': [3.53337574005127]},\n",
       "  {u'scores': [3.061508178710938]},\n",
       "  {u'scores': [4.044018268585205]},\n",
       "  {u'scores': [2.909586668014526]},\n",
       "  {u'scores': [2.254849910736084]},\n",
       "  {u'scores': [3.817906618118286]},\n",
       "  {u'scores': [2.892485618591309]},\n",
       "  {u'scores': [2.664270877838135]},\n",
       "  {u'scores': [3.244885921478272]},\n",
       "  {u'scores': [3.514942169189453]},\n",
       "  {u'scores': [4.427985668182373]},\n",
       "  {u'scores': [3.39105224609375]},\n",
       "  {u'scores': [4.304101467132568]},\n",
       "  {u'scores': [3.228745222091675]},\n",
       "  {u'scores': [3.879961013793945]},\n",
       "  {u'scores': [3.998836517333984]},\n",
       "  {u'scores': [3.023608207702637]},\n",
       "  {u'scores': [3.715846538543701]},\n",
       "  {u'scores': [4.226496696472168]},\n",
       "  {u'scores': [3.893062591552734]},\n",
       "  {u'scores': [2.89503288269043]},\n",
       "  {u'scores': [2.726855516433716]},\n",
       "  {u'scores': [3.370683193206787]},\n",
       "  {u'scores': [4.030374526977539]},\n",
       "  {u'scores': [3.072929382324219]},\n",
       "  {u'scores': [3.435771942138672]},\n",
       "  {u'scores': [2.475815057754517]},\n",
       "  {u'scores': [3.63582706451416]},\n",
       "  {u'scores': [3.855751752853394]},\n",
       "  {u'scores': [3.394402980804443]},\n",
       "  {u'scores': [3.23088550567627]},\n",
       "  {u'scores': [3.17027473449707]},\n",
       "  {u'scores': [3.53300952911377]},\n",
       "  {u'scores': [3.872734069824219]},\n",
       "  {u'scores': [3.416500806808472]},\n",
       "  {u'scores': [3.990658760070801]},\n",
       "  {u'scores': [3.783429622650146]},\n",
       "  {u'scores': [3.555691719055176]},\n",
       "  {u'scores': [3.346667766571045]},\n",
       "  {u'scores': [3.046761512756348]},\n",
       "  {u'scores': [3.273463010787964]},\n",
       "  {u'scores': [3.008848428726196]},\n",
       "  {u'scores': [4.046188831329346]},\n",
       "  {u'scores': [3.651987552642822]},\n",
       "  {u'scores': [3.181013345718384]},\n",
       "  {u'scores': [2.854335308074951]},\n",
       "  {u'scores': [3.371426105499268]},\n",
       "  {u'scores': [4.542716503143311]},\n",
       "  {u'scores': [3.872046232223511]},\n",
       "  {u'scores': [2.315027236938477]},\n",
       "  {u'scores': [4.196183204650879]},\n",
       "  {u'scores': [3.815222263336182]},\n",
       "  {u'scores': [4.945165157318115]},\n",
       "  {u'scores': [4.350660800933838]},\n",
       "  {u'scores': [3.468892097473144]},\n",
       "  {u'scores': [3.442687511444092]},\n",
       "  {u'scores': [4.551932811737061]},\n",
       "  {u'scores': [3.265913963317871]},\n",
       "  {u'scores': [3.44120979309082]},\n",
       "  {u'scores': [3.645919322967529]},\n",
       "  {u'scores': [3.500978946685791]},\n",
       "  {u'scores': [3.469812870025635]},\n",
       "  {u'scores': [3.875129461288452]},\n",
       "  {u'scores': [4.212680816650391]},\n",
       "  {u'scores': [3.121539115905762]},\n",
       "  {u'scores': [3.789254426956177]},\n",
       "  {u'scores': [3.455570936203003]},\n",
       "  {u'scores': [3.336982727050781]},\n",
       "  {u'scores': [3.97414755821228]},\n",
       "  {u'scores': [3.381274700164795]},\n",
       "  {u'scores': [2.690767765045166]},\n",
       "  {u'scores': [3.418591022491455]},\n",
       "  {u'scores': [3.072649478912354]},\n",
       "  {u'scores': [4.119601726531982]},\n",
       "  {u'scores': [3.858683824539185]},\n",
       "  {u'scores': [2.978919982910156]},\n",
       "  {u'scores': [2.767346858978272]},\n",
       "  {u'scores': [2.519644737243652]},\n",
       "  {u'scores': [4.720869541168213]},\n",
       "  {u'scores': [3.703687191009522]},\n",
       "  {u'scores': [3.900795221328735]},\n",
       "  {u'scores': [3.060276746749878]},\n",
       "  {u'scores': [4.048705577850342]},\n",
       "  {u'scores': [3.827361822128296]},\n",
       "  {u'scores': [3.905328512191772]},\n",
       "  {u'scores': [3.675232648849487]},\n",
       "  {u'scores': [3.614500045776367]},\n",
       "  {u'scores': [3.133920669555664]},\n",
       "  {u'scores': [1.870833277702332]},\n",
       "  {u'scores': [3.546736240386963]},\n",
       "  {u'scores': [4.403317928314209]},\n",
       "  {u'scores': [3.853796482086182]},\n",
       "  {u'scores': [2.821744680404663]},\n",
       "  {u'scores': [3.897505760192871]},\n",
       "  {u'scores': [4.513556957244873]},\n",
       "  {u'scores': [1.939433097839356]},\n",
       "  {u'scores': [4.145451068878174]},\n",
       "  {u'scores': [3.635425806045532]},\n",
       "  {u'scores': [3.738485813140869]},\n",
       "  {u'scores': [3.285507202148438]},\n",
       "  {u'scores': [3.158805847167969]},\n",
       "  {u'scores': [3.068150520324707]},\n",
       "  {u'scores': [3.550609350204468]},\n",
       "  {u'scores': [4.074516773223877]},\n",
       "  {u'scores': [2.260655641555786]},\n",
       "  {u'scores': [2.680885791778564]},\n",
       "  {u'scores': [3.338879585266113]},\n",
       "  {u'scores': [4.014859199523926]},\n",
       "  {u'scores': [3.208130359649658]},\n",
       "  {u'scores': [3.897595405578613]},\n",
       "  {u'scores': [3.539793491363525]},\n",
       "  {u'scores': [3.509764671325684]},\n",
       "  {u'scores': [3.838637828826904]},\n",
       "  {u'scores': [3.371646404266357]},\n",
       "  {u'scores': [4.555177688598633]},\n",
       "  {u'scores': [4.670783996582031]},\n",
       "  {u'scores': [3.95117712020874]},\n",
       "  {u'scores': [1.992686152458191]},\n",
       "  {u'scores': [4.604983329772949]},\n",
       "  {u'scores': [3.474707126617432]},\n",
       "  {u'scores': [3.930436134338379]},\n",
       "  {u'scores': [4.267299652099609]},\n",
       "  {u'scores': [3.49917459487915]},\n",
       "  {u'scores': [3.016380786895752]},\n",
       "  {u'scores': [2.965371608734131]},\n",
       "  {u'scores': [3.633773803710938]},\n",
       "  {u'scores': [4.556313991546631]},\n",
       "  {u'scores': [2.951816082000732]},\n",
       "  {u'scores': [3.620620727539062]},\n",
       "  {u'scores': [3.462666988372803]},\n",
       "  {u'scores': [4.190325260162354]},\n",
       "  {u'scores': [4.027390480041504]},\n",
       "  {u'scores': [4.600869655609131]},\n",
       "  {u'scores': [2.636136054992676]},\n",
       "  {u'scores': [3.947603464126587]},\n",
       "  {u'scores': [3.452144622802734]},\n",
       "  {u'scores': [4.232302188873291]},\n",
       "  {u'scores': [4.585075855255127]},\n",
       "  {u'scores': [3.646722316741943]},\n",
       "  {u'scores': [3.703559398651123]},\n",
       "  {u'scores': [3.770950317382812]},\n",
       "  {u'scores': [3.315560817718506]},\n",
       "  {u'scores': [4.35302734375]},\n",
       "  {u'scores': [2.789652109146118]},\n",
       "  {u'scores': [4.358168125152588]},\n",
       "  {u'scores': [3.702219486236572]},\n",
       "  {u'scores': [2.338031053543091]},\n",
       "  {u'scores': [3.206104278564453]},\n",
       "  {u'scores': [3.759219884872436]},\n",
       "  {u'scores': [3.56958270072937]},\n",
       "  {u'scores': [2.73161792755127]},\n",
       "  {u'scores': [4.549802303314209]},\n",
       "  {u'scores': [3.849210977554321]},\n",
       "  {u'scores': [3.847560405731201]},\n",
       "  {u'scores': [4.417513370513916]},\n",
       "  {u'scores': [4.101339817047119]},\n",
       "  {u'scores': [3.560260534286499]},\n",
       "  {u'scores': [3.975748538970947]},\n",
       "  {u'scores': [3.845241069793701]},\n",
       "  {u'scores': [3.915205955505371]},\n",
       "  {u'scores': [3.443630218505859]},\n",
       "  {u'scores': [4.170815944671631]},\n",
       "  {u'scores': [2.835897445678711]},\n",
       "  {u'scores': [3.500237464904785]},\n",
       "  {u'scores': [3.235459327697754]},\n",
       "  {u'scores': [2.734475612640381]},\n",
       "  {u'scores': [3.674100399017334]},\n",
       "  {u'scores': [3.967679500579834]},\n",
       "  {u'scores': [3.916702747344971]},\n",
       "  {u'scores': [3.609325408935547]},\n",
       "  {u'scores': [3.220287084579468]},\n",
       "  {u'scores': [2.617193222045898]},\n",
       "  {u'scores': [3.744719982147217]},\n",
       "  {u'scores': [3.694251775741577]},\n",
       "  {u'scores': [4.918603420257568]},\n",
       "  {u'scores': [2.823698043823242]},\n",
       "  {u'scores': [3.558408737182617]},\n",
       "  {u'scores': [3.14494514465332]},\n",
       "  {u'scores': [3.846255779266357]},\n",
       "  {u'scores': [3.740807056427002]},\n",
       "  {u'scores': [2.854340553283691]},\n",
       "  {u'scores': [2.589787244796753]},\n",
       "  {u'scores': [4.332566261291504]},\n",
       "  {u'scores': [4.966982364654541]},\n",
       "  {u'scores': [4.052635669708252]},\n",
       "  {u'scores': [3.794896364212036]},\n",
       "  {u'scores': [2.213698148727417]},\n",
       "  {u'scores': [3.486778020858765]},\n",
       "  {u'scores': [4.894172191619873]},\n",
       "  {u'scores': [3.863940238952637]},\n",
       "  {u'scores': [3.420851230621338]},\n",
       "  {u'scores': [2.996225118637085]},\n",
       "  {u'scores': [3.658723831176758]},\n",
       "  {u'scores': [2.900485038757324]},\n",
       "  {u'scores': [4.71324872970581]},\n",
       "  {u'scores': [4.059165477752686]},\n",
       "  {u'scores': [3.248479843139648]},\n",
       "  {u'scores': [3.305771112442017]},\n",
       "  {u'scores': [3.730282306671143]},\n",
       "  {u'scores': [3.187370538711548]},\n",
       "  {u'scores': [3.040392637252808]},\n",
       "  {u'scores': [3.729519844055176]},\n",
       "  {u'scores': [3.421455383300781]},\n",
       "  {u'scores': [3.86552095413208]},\n",
       "  {u'scores': [3.274955749511719]},\n",
       "  {u'scores': [4.48236608505249]},\n",
       "  {u'scores': [3.626003503799438]},\n",
       "  {u'scores': [3.855068922042847]},\n",
       "  {u'scores': [2.69498085975647]},\n",
       "  {u'scores': [4.096959590911865]},\n",
       "  {u'scores': [2.613688230514526]},\n",
       "  {u'scores': [2.952593564987183]},\n",
       "  {u'scores': [5.053046703338623]},\n",
       "  {u'scores': [3.296112298965454]},\n",
       "  {u'scores': [4.157541751861572]},\n",
       "  {u'scores': [3.13609504699707]},\n",
       "  {u'scores': [4.21711254119873]},\n",
       "  {u'scores': [3.284129858016968]},\n",
       "  {u'scores': [3.966309070587158]},\n",
       "  {u'scores': [2.893125057220459]},\n",
       "  {u'scores': [3.25426197052002]},\n",
       "  {u'scores': [4.261108875274658]},\n",
       "  {u'scores': [2.739646911621094]},\n",
       "  {u'scores': [4.188077449798584]},\n",
       "  {u'scores': [4.88809061050415]},\n",
       "  {u'scores': [2.815988779067993]},\n",
       "  {u'scores': [4.426078796386719]},\n",
       "  {u'scores': [4.375075817108154]},\n",
       "  {u'scores': [3.533106803894043]},\n",
       "  {u'scores': [3.369050025939941]},\n",
       "  {u'scores': [3.740715503692627]},\n",
       "  {u'scores': [4.094736576080322]},\n",
       "  {u'scores': [3.744861364364624]},\n",
       "  {u'scores': [3.506355047225952]},\n",
       "  {u'scores': [2.269644021987915]},\n",
       "  {u'scores': [2.054019927978516]},\n",
       "  {u'scores': [4.144711017608643]},\n",
       "  {u'scores': [3.345140218734741]},\n",
       "  {u'scores': [3.496558427810669]},\n",
       "  {u'scores': [3.123303413391113]},\n",
       "  {u'scores': [3.561821699142456]},\n",
       "  {u'scores': [3.560322284698486]},\n",
       "  {u'scores': [1.402005434036255]},\n",
       "  {u'scores': [3.527143716812134]},\n",
       "  {u'scores': [3.845553636550903]},\n",
       "  {u'scores': [3.82410717010498]},\n",
       "  {u'scores': [3.011878490447998]},\n",
       "  {u'scores': [4.035031795501709]},\n",
       "  {u'scores': [3.724682331085205]},\n",
       "  {u'scores': [4.643886089324951]},\n",
       "  {u'scores': [3.349210500717163]},\n",
       "  {u'scores': [4.67000150680542]},\n",
       "  {u'scores': [4.581648826599121]},\n",
       "  {u'scores': [3.717679977416992]},\n",
       "  {u'scores': [3.437482118606567]},\n",
       "  {u'scores': [4.077670097351074]},\n",
       "  {u'scores': [3.19464111328125]},\n",
       "  {u'scores': [3.606767654418945]},\n",
       "  {u'scores': [2.894256591796875]},\n",
       "  {u'scores': [2.332607746124268]},\n",
       "  {u'scores': [3.402133464813232]},\n",
       "  {u'scores': [3.596270561218262]},\n",
       "  {u'scores': [3.963819980621338]},\n",
       "  {u'scores': [3.759749174118042]},\n",
       "  {u'scores': [3.189207553863525]},\n",
       "  {u'scores': [3.837972640991211]},\n",
       "  {u'scores': [3.694187164306641]},\n",
       "  {u'scores': [3.616143941879272]},\n",
       "  {u'scores': [3.408463001251221]},\n",
       "  {u'scores': [2.513867616653442]},\n",
       "  {u'scores': [4.094651699066162]},\n",
       "  {u'scores': [2.973443508148193]},\n",
       "  {u'scores': [2.519338130950928]},\n",
       "  {u'scores': [3.776060581207275]},\n",
       "  {u'scores': [3.682297945022583]},\n",
       "  {u'scores': [3.586146354675293]},\n",
       "  {u'scores': [4.088034152984619]},\n",
       "  {u'scores': [4.065868854522705]},\n",
       "  {u'scores': [1.912979483604431]},\n",
       "  {u'scores': [3.626744508743286]},\n",
       "  {u'scores': [3.875357627868652]},\n",
       "  {u'scores': [3.90692949295044]},\n",
       "  {u'scores': [3.164420604705811]},\n",
       "  {u'scores': [4.611410617828369]},\n",
       "  {u'scores': [4.214112758636475]},\n",
       "  {u'scores': [3.219503879547119]},\n",
       "  {u'scores': [3.793349981307983]},\n",
       "  {u'scores': [3.426925659179688]},\n",
       "  {u'scores': [3.534466743469238]},\n",
       "  {u'scores': [3.122014284133911]},\n",
       "  {u'scores': [3.166917324066162]},\n",
       "  {u'scores': [3.478193044662476]},\n",
       "  {u'scores': [2.911120891571045]},\n",
       "  {u'scores': [3.545165300369263]},\n",
       "  {u'scores': [2.842149496078491]},\n",
       "  {u'scores': [3.071455478668213]},\n",
       "  {u'scores': [3.223756790161133]},\n",
       "  {u'scores': [3.495774269104004]},\n",
       "  {u'scores': [2.422596454620361]},\n",
       "  {u'scores': [4.04454231262207]},\n",
       "  {u'scores': [4.859474658966064]},\n",
       "  {u'scores': [3.837933301925659]},\n",
       "  {u'scores': [2.819001197814941]},\n",
       "  {u'scores': [2.915220499038696]},\n",
       "  {u'scores': [4.562830448150635]},\n",
       "  {u'scores': [3.151931524276733]},\n",
       "  {u'scores': [3.418723583221436]},\n",
       "  {u'scores': [3.863371849060059]},\n",
       "  {u'scores': [3.943452835083008]},\n",
       "  {u'scores': [2.525421619415283]},\n",
       "  {u'scores': [2.529626369476318]},\n",
       "  {u'scores': [3.118798971176147]},\n",
       "  {u'scores': [2.919354677200317]},\n",
       "  {u'scores': [3.930105686187744]},\n",
       "  {u'scores': [3.23988676071167]},\n",
       "  {u'scores': [3.332618474960327]},\n",
       "  {u'scores': [3.813009977340698]},\n",
       "  {u'scores': [4.357968807220459]},\n",
       "  {u'scores': [3.591647624969482]},\n",
       "  {u'scores': [3.02559757232666]},\n",
       "  {u'scores': [4.014182567596436]},\n",
       "  {u'scores': [3.877151250839233]},\n",
       "  {u'scores': [3.959886789321899]},\n",
       "  {u'scores': [3.097746849060059]},\n",
       "  {u'scores': [3.848403930664062]},\n",
       "  {u'scores': [3.344630718231201]},\n",
       "  {u'scores': [2.870608806610107]},\n",
       "  {u'scores': [4.080249309539795]},\n",
       "  {u'scores': [3.137792825698853]},\n",
       "  {u'scores': [3.668915748596191]},\n",
       "  {u'scores': [3.494086027145386]},\n",
       "  {u'scores': [3.734066963195801]},\n",
       "  {u'scores': [3.679833889007568]},\n",
       "  {u'scores': [3.562232494354248]},\n",
       "  {u'scores': [3.081403970718384]},\n",
       "  {u'scores': [3.555119276046753]},\n",
       "  {u'scores': [3.81712818145752]},\n",
       "  {u'scores': [2.888335227966309]},\n",
       "  {u'scores': [3.849826335906982]},\n",
       "  {u'scores': [3.343477725982666]},\n",
       "  {u'scores': [2.920445442199707]},\n",
       "  {u'scores': [3.580098152160644]},\n",
       "  {u'scores': [4.450884342193604]},\n",
       "  {u'scores': [2.295213937759399]},\n",
       "  {u'scores': [3.817825078964233]},\n",
       "  {u'scores': [3.780523300170898]},\n",
       "  {u'scores': [4.137282371520996]},\n",
       "  {u'scores': [3.300541877746582]},\n",
       "  {u'scores': [3.265152931213379]},\n",
       "  {u'scores': [3.77969479560852]},\n",
       "  {u'scores': [5.01869535446167]},\n",
       "  {u'scores': [3.936938047409058]},\n",
       "  {u'scores': [3.917047023773193]},\n",
       "  {u'scores': [3.672102212905884]},\n",
       "  {u'scores': [4.921032428741455]},\n",
       "  {u'scores': [4.423044681549072]},\n",
       "  {u'scores': [2.431360721588135]},\n",
       "  {u'scores': [1.981424808502197]},\n",
       "  {u'scores': [4.097315311431885]},\n",
       "  {u'scores': [2.785876512527466]},\n",
       "  {u'scores': [2.509652614593506]},\n",
       "  {u'scores': [2.972007513046265]},\n",
       "  {u'scores': [4.286716938018799]},\n",
       "  {u'scores': [3.529639720916748]},\n",
       "  {u'scores': [3.635898590087891]},\n",
       "  {u'scores': [3.77436900138855]},\n",
       "  {u'scores': [1.999110460281372]},\n",
       "  {u'scores': [2.571568012237549]},\n",
       "  {u'scores': [3.132586479187012]},\n",
       "  {u'scores': [1.139345049858093]},\n",
       "  {u'scores': [3.759104251861572]},\n",
       "  {u'scores': [3.43900203704834]},\n",
       "  {u'scores': [3.992935657501221]},\n",
       "  {u'scores': [3.974253416061401]},\n",
       "  {u'scores': [3.09534740447998]},\n",
       "  {u'scores': [3.689229249954224]},\n",
       "  {u'scores': [3.058139801025391]},\n",
       "  {u'scores': [4.239078998565674]},\n",
       "  {u'scores': [4.614840030670166]},\n",
       "  {u'scores': [2.739552021026611]},\n",
       "  {u'scores': [3.870627164840698]},\n",
       "  {u'scores': [3.505227327346802]},\n",
       "  {u'scores': [3.903479099273682]},\n",
       "  {u'scores': [3.68424916267395]},\n",
       "  {u'scores': [3.258607387542725]},\n",
       "  {u'scores': [3.605384826660156]},\n",
       "  {u'scores': [4.362508773803711]},\n",
       "  {u'scores': [4.032401561737061]},\n",
       "  {u'scores': [4.373876094818115]},\n",
       "  {u'scores': [3.778334856033325]},\n",
       "  {u'scores': [4.086485862731934]},\n",
       "  {u'scores': [3.486093044281006]},\n",
       "  {u'scores': [3.861618995666504]},\n",
       "  {u'scores': [3.591409683227539]},\n",
       "  {u'scores': [2.732055187225342]},\n",
       "  {u'scores': [2.882568836212158]},\n",
       "  {u'scores': [4.859762668609619]},\n",
       "  {u'scores': [3.81625771522522]},\n",
       "  {u'scores': [4.501850128173828]},\n",
       "  {u'scores': [2.965196847915649]},\n",
       "  {u'scores': [4.078425884246826]},\n",
       "  {u'scores': [3.780061721801758]},\n",
       "  {u'scores': [3.627583026885986]},\n",
       "  {u'scores': [3.838576555252075]},\n",
       "  {u'scores': [3.548218250274658]},\n",
       "  {u'scores': [3.544673919677734]},\n",
       "  {u'scores': [3.924767255783081]},\n",
       "  {u'scores': [3.597880363464356]},\n",
       "  {u'scores': [3.43303108215332]},\n",
       "  {u'scores': [3.389338970184326]},\n",
       "  {u'scores': [2.773201942443848]},\n",
       "  {u'scores': [3.960287570953369]},\n",
       "  {u'scores': [4.485731601715088]},\n",
       "  {u'scores': [3.141443014144897]},\n",
       "  {u'scores': [2.875971555709839]},\n",
       "  {u'scores': [3.623633861541748]},\n",
       "  {u'scores': [3.556030750274658]},\n",
       "  {u'scores': [3.463184118270874]},\n",
       "  {u'scores': [2.814731121063232]},\n",
       "  {u'scores': [3.361522674560547]},\n",
       "  {u'scores': [3.502789497375488]},\n",
       "  {u'scores': [4.011049747467041]},\n",
       "  {u'scores': [2.267448425292969]},\n",
       "  {u'scores': [5.034777164459229]},\n",
       "  {u'scores': [3.673325538635254]},\n",
       "  {u'scores': [3.633205652236938]},\n",
       "  {u'scores': [3.836059808731079]},\n",
       "  {u'scores': [4.601998805999756]},\n",
       "  {u'scores': [1.877431988716126]},\n",
       "  {u'scores': [2.869510412216186]},\n",
       "  {u'scores': [2.737150192260742]},\n",
       "  {u'scores': [3.393050193786621]},\n",
       "  {u'scores': [4.828257083892822]},\n",
       "  {u'scores': [4.386583805084228]},\n",
       "  {u'scores': [2.49871826171875]},\n",
       "  {u'scores': [2.798801422119141]},\n",
       "  {u'scores': [3.351327896118164]},\n",
       "  {u'scores': [4.09960412979126]},\n",
       "  {u'scores': [3.306922674179077]},\n",
       "  {u'scores': [4.249026298522949]},\n",
       "  {u'scores': [4.494840145111084]},\n",
       "  {u'scores': [4.013064384460449]},\n",
       "  {u'scores': [3.988938808441162]},\n",
       "  {u'scores': [2.79499077796936]},\n",
       "  {u'scores': [3.052751541137695]},\n",
       "  {u'scores': [3.75729250907898]},\n",
       "  {u'scores': [4.277803897857666]},\n",
       "  {u'scores': [3.266070365905762]},\n",
       "  {u'scores': [4.012783050537109]},\n",
       "  {u'scores': [3.12437915802002]},\n",
       "  {u'scores': [3.380699396133423]},\n",
       "  {u'scores': [3.417777538299561]},\n",
       "  {u'scores': [3.625359773635864]},\n",
       "  {u'scores': [3.655940055847168]},\n",
       "  {u'scores': [3.938841342926025]},\n",
       "  {u'scores': [4.008291721343994]},\n",
       "  {u'scores': [2.817304611206055]},\n",
       "  {u'scores': [4.321483135223389]},\n",
       "  {u'scores': [2.845355987548828]},\n",
       "  {u'scores': [4.023640155792236]},\n",
       "  {u'scores': [3.201556205749512]},\n",
       "  {u'scores': [3.143137454986572]},\n",
       "  {u'scores': [4.248816013336182]},\n",
       "  {u'scores': [3.394891023635864]},\n",
       "  {u'scores': [2.911609649658203]},\n",
       "  {u'scores': [3.256815195083618]},\n",
       "  {u'scores': [2.316241979598999]},\n",
       "  {u'scores': [4.526626110076904]},\n",
       "  {u'scores': [4.219073295593262]},\n",
       "  {u'scores': [4.041622638702393]},\n",
       "  {u'scores': [3.411629199981689]},\n",
       "  {u'scores': [3.897993087768555]},\n",
       "  {u'scores': [2.828967571258545]},\n",
       "  {u'scores': [3.442208290100098]},\n",
       "  {u'scores': [3.727066040039062]},\n",
       "  {u'scores': [3.43907356262207]},\n",
       "  {u'scores': [3.585781574249268]},\n",
       "  {u'scores': [3.309940814971924]},\n",
       "  {u'scores': [4.312670230865478]},\n",
       "  {u'scores': [4.115632057189941]},\n",
       "  {u'scores': [3.869787454605102]},\n",
       "  {u'scores': [3.607881546020508]},\n",
       "  {u'scores': [3.881991863250732]},\n",
       "  {u'scores': [3.601086616516113]},\n",
       "  {u'scores': [3.69809889793396]},\n",
       "  {u'scores': [4.197874069213867]},\n",
       "  {u'scores': [3.747981786727905]},\n",
       "  {u'scores': [2.574420928955078]},\n",
       "  {u'scores': [3.66065263748169]},\n",
       "  {u'scores': [4.077579021453857]},\n",
       "  {u'scores': [3.378273487091064]},\n",
       "  {u'scores': [2.620462894439697]},\n",
       "  {u'scores': [3.45391321182251]},\n",
       "  {u'scores': [3.611242771148682]},\n",
       "  {u'scores': [3.034954071044922]},\n",
       "  {u'scores': [4.358462810516357]},\n",
       "  {u'scores': [3.489777326583862]},\n",
       "  {u'scores': [3.984406471252441]},\n",
       "  {u'scores': [1.879005193710327]},\n",
       "  {u'scores': [3.961955070495606]},\n",
       "  {u'scores': [3.474420547485352]},\n",
       "  {u'scores': [3.650741577148438]},\n",
       "  {u'scores': [2.419667482376099]},\n",
       "  {u'scores': [4.86647367477417]},\n",
       "  {u'scores': [3.91587495803833]},\n",
       "  {u'scores': [4.129869937896729]},\n",
       "  {u'scores': [3.888308763504028]},\n",
       "  {u'scores': [3.659835338592529]},\n",
       "  {u'scores': [3.334967136383057]},\n",
       "  {u'scores': [3.20406174659729]},\n",
       "  {u'scores': [1.666510820388794]},\n",
       "  {u'scores': [3.830080986022949]},\n",
       "  {u'scores': [2.692077159881592]},\n",
       "  {u'scores': [4.104893207550049]},\n",
       "  {u'scores': [4.531744003295898]},\n",
       "  {u'scores': [3.776092052459717]},\n",
       "  {u'scores': [3.245244979858398]},\n",
       "  {u'scores': [2.749903678894043]},\n",
       "  {u'scores': [3.011369228363037]},\n",
       "  {u'scores': [3.96879243850708]},\n",
       "  {u'scores': [2.087276935577393]},\n",
       "  {u'scores': [3.929692029953003]},\n",
       "  {u'scores': [3.285441875457764]},\n",
       "  {u'scores': [3.711181640625]},\n",
       "  {u'scores': [3.766509294509888]},\n",
       "  {u'scores': [2.991285562515259]},\n",
       "  {u'scores': [3.112767457962036]},\n",
       "  {u'scores': [4.561668395996094]},\n",
       "  {u'scores': [4.834347248077393]},\n",
       "  {u'scores': [3.680253982543945]},\n",
       "  {u'scores': [2.166897296905518]},\n",
       "  {u'scores': [3.009243965148926]},\n",
       "  {u'scores': [3.532864332199097]},\n",
       "  {u'scores': [4.062644958496094]},\n",
       "  {u'scores': [3.340196371078491]},\n",
       "  {u'scores': [3.602583646774292]},\n",
       "  {u'scores': [3.170194149017334]},\n",
       "  {u'scores': [4.371658802032471]},\n",
       "  {u'scores': [2.997624158859253]},\n",
       "  {u'scores': [3.96804666519165]},\n",
       "  {u'scores': [3.807641506195068]},\n",
       "  {u'scores': [3.472379684448242]},\n",
       "  {u'scores': [3.068548202514648]},\n",
       "  {u'scores': [3.872839689254761]},\n",
       "  {u'scores': [1.875838041305542]},\n",
       "  {u'scores': [3.578577518463135]},\n",
       "  {u'scores': [2.207536935806274]},\n",
       "  {u'scores': [2.963942050933838]},\n",
       "  {u'scores': [4.059837818145752]},\n",
       "  {u'scores': [3.397521734237671]},\n",
       "  {u'scores': [3.787510395050049]},\n",
       "  {u'scores': [3.712881803512573]},\n",
       "  {u'scores': [2.414552688598633]},\n",
       "  {u'scores': [4.158392429351807]},\n",
       "  {u'scores': [3.428355693817139]},\n",
       "  {u'scores': [3.670745372772217]},\n",
       "  {u'scores': [2.901856422424316]},\n",
       "  {u'scores': [3.210504055023193]},\n",
       "  {u'scores': [2.646697521209717]},\n",
       "  {u'scores': [4.490731239318848]},\n",
       "  {u'scores': [3.113760709762573]},\n",
       "  {u'scores': [3.091800212860107]},\n",
       "  {u'scores': [4.015153408050537]},\n",
       "  {u'scores': [3.989464521408081]},\n",
       "  {u'scores': [4.329281330108643]},\n",
       "  {u'scores': [3.263067245483398]},\n",
       "  {u'scores': [4.405091762542725]},\n",
       "  {u'scores': [3.176677942276001]},\n",
       "  {u'scores': [3.353760242462158]},\n",
       "  {u'scores': [4.236775875091553]},\n",
       "  {u'scores': [4.475372314453125]},\n",
       "  {u'scores': [3.74513578414917]},\n",
       "  {u'scores': [3.44668459892273]},\n",
       "  {u'scores': [3.460994243621826]},\n",
       "  {u'scores': [2.566610813140869]},\n",
       "  {u'scores': [4.240633487701416]},\n",
       "  {u'scores': [3.842214345932007]},\n",
       "  {u'scores': [3.178922414779663]},\n",
       "  {u'scores': [3.858092784881592]},\n",
       "  {u'scores': [3.889672756195068]},\n",
       "  {u'scores': [3.662747859954834]},\n",
       "  {u'scores': [3.721995830535889]},\n",
       "  {u'scores': [3.751614570617676]},\n",
       "  {u'scores': [3.650902032852173]},\n",
       "  {u'scores': [1.880496740341186]},\n",
       "  {u'scores': [4.45664644241333]},\n",
       "  {u'scores': [3.111016750335693]},\n",
       "  {u'scores': [3.505975723266602]},\n",
       "  {u'scores': [4.703279972076416]},\n",
       "  {u'scores': [3.633369445800781]},\n",
       "  {u'scores': [4.249488353729248]},\n",
       "  {u'scores': [2.946000814437866]},\n",
       "  {u'scores': [4.50231409072876]},\n",
       "  {u'scores': [3.749588012695312]},\n",
       "  {u'scores': [3.850944995880127]},\n",
       "  {u'scores': [4.237642288208008]},\n",
       "  {u'scores': [3.757544040679932]},\n",
       "  {u'scores': [3.872884273529053]},\n",
       "  {u'scores': [4.373703479766846]},\n",
       "  {u'scores': [3.117283821105957]},\n",
       "  {u'scores': [3.399205446243286]},\n",
       "  {u'scores': [3.154303789138794]},\n",
       "  {u'scores': [4.013294696807861]},\n",
       "  {u'scores': [3.518115043640137]},\n",
       "  {u'scores': [3.357535839080811]},\n",
       "  {u'scores': [3.309623241424561]},\n",
       "  {u'scores': [3.888447523117065]},\n",
       "  {u'scores': [3.94959545135498]},\n",
       "  {u'scores': [3.018123626708984]},\n",
       "  {u'scores': [4.817245960235596]},\n",
       "  {u'scores': [2.847202301025391]},\n",
       "  {u'scores': [3.128217458724976]},\n",
       "  {u'scores': [4.510003566741943]},\n",
       "  {u'scores': [4.465026378631592]},\n",
       "  {u'scores': [3.050820350646973]},\n",
       "  {u'scores': [2.586627960205078]},\n",
       "  {u'scores': [3.459756851196289]},\n",
       "  {u'scores': [4.800312519073486]},\n",
       "  {u'scores': [3.910732746124268]},\n",
       "  {u'scores': [2.042107820510864]},\n",
       "  {u'scores': [4.055731773376465]},\n",
       "  {u'scores': [3.228726387023926]},\n",
       "  {u'scores': [3.810179233551025]},\n",
       "  {u'scores': [4.047005653381348]},\n",
       "  {u'scores': [4.018333435058594]},\n",
       "  {u'scores': [4.919754505157471]},\n",
       "  {u'scores': [3.779757022857666]},\n",
       "  {u'scores': [3.46569299697876]},\n",
       "  {u'scores': [2.558987379074097]},\n",
       "  {u'scores': [3.43710207939148]},\n",
       "  {u'scores': [3.207940340042114]},\n",
       "  {u'scores': [3.03944730758667]},\n",
       "  {u'scores': [3.997821569442749]},\n",
       "  {u'scores': [4.290723323822022]},\n",
       "  {u'scores': [3.49252462387085]},\n",
       "  {u'scores': [4.036497592926025]},\n",
       "  {u'scores': [3.286251068115234]},\n",
       "  {u'scores': [4.006136417388916]},\n",
       "  {u'scores': [3.359058380126953]},\n",
       "  {u'scores': [4.677802562713623]},\n",
       "  {u'scores': [3.522632598876953]},\n",
       "  {u'scores': [3.349066734313965]},\n",
       "  {u'scores': [2.738841772079468]},\n",
       "  {u'scores': [3.986965894699097]},\n",
       "  {u'scores': [4.631117343902588]},\n",
       "  {u'scores': [3.353383541107178]},\n",
       "  {u'scores': [2.892958879470825]},\n",
       "  {u'scores': [3.541110038757324]},\n",
       "  {u'scores': [4.150703430175781]},\n",
       "  {u'scores': [3.695302248001099]},\n",
       "  {u'scores': [3.726606845855713]},\n",
       "  {u'scores': [3.571018695831299]},\n",
       "  {u'scores': [3.821243762969971]},\n",
       "  {u'scores': [3.786765813827515]},\n",
       "  {u'scores': [4.590254783630371]},\n",
       "  {u'scores': [4.280894756317139]},\n",
       "  {u'scores': [4.062764644622803]},\n",
       "  {u'scores': [4.07157039642334]},\n",
       "  {u'scores': [4.503427028656006]},\n",
       "  {u'scores': [3.961716175079346]},\n",
       "  {u'scores': [2.697338104248047]},\n",
       "  {u'scores': [2.818410634994507]},\n",
       "  {u'scores': [4.044078826904297]},\n",
       "  {u'scores': [2.913475036621094]},\n",
       "  {u'scores': [2.985724687576294]},\n",
       "  {u'scores': [2.017455577850342]},\n",
       "  {u'scores': [4.546358585357666]},\n",
       "  {u'scores': [3.506787776947022]},\n",
       "  {u'scores': [3.824615478515625]},\n",
       "  {u'scores': [4.363763809204102]},\n",
       "  {u'scores': [4.509439945220947]},\n",
       "  {u'scores': [3.595971584320068]},\n",
       "  {u'scores': [4.345828056335449]},\n",
       "  {u'scores': [3.616458892822266]},\n",
       "  {u'scores': [3.284255027770996]},\n",
       "  {u'scores': [3.345471382141113]},\n",
       "  {u'scores': [3.451710939407349]},\n",
       "  {u'scores': [3.893060922622681]},\n",
       "  {u'scores': [3.476475477218628]},\n",
       "  {u'scores': [2.681697130203247]},\n",
       "  {u'scores': [3.635228633880615]},\n",
       "  {u'scores': [3.332675457000732]},\n",
       "  {u'scores': [2.843357086181641]},\n",
       "  {u'scores': [2.614009380340576]},\n",
       "  {u'scores': [3.913774013519287]},\n",
       "  {u'scores': [3.157028675079346]},\n",
       "  {u'scores': [4.903301239013672]},\n",
       "  {u'scores': [4.271114826202393]},\n",
       "  {u'scores': [3.614034652709961]},\n",
       "  {u'scores': [3.802252054214478]},\n",
       "  {u'scores': [3.656094551086426]},\n",
       "  {u'scores': [4.526453971862793]},\n",
       "  {u'scores': [3.626518726348877]},\n",
       "  {u'scores': [3.846930027008057]},\n",
       "  {u'scores': [4.174565315246582]},\n",
       "  {u'scores': [2.86430025100708]},\n",
       "  {u'scores': [3.947283506393433]},\n",
       "  {u'scores': [3.995793342590332]},\n",
       "  {u'scores': [2.792462348937988]},\n",
       "  {u'scores': [2.976868391036987]},\n",
       "  {u'scores': [4.306495189666748]},\n",
       "  {u'scores': [4.001769065856934]},\n",
       "  {u'scores': [3.342691421508789]},\n",
       "  {u'scores': [3.507169246673584]},\n",
       "  {u'scores': [3.111598968505859]},\n",
       "  {u'scores': [4.65929651260376]},\n",
       "  {u'scores': [2.225843906402588]},\n",
       "  {u'scores': [3.311995029449463]},\n",
       "  {u'scores': [3.520091772079468]},\n",
       "  {u'scores': [3.393916130065918]},\n",
       "  {u'scores': [3.718819618225098]},\n",
       "  {u'scores': [3.476532697677612]},\n",
       "  {u'scores': [3.507391214370728]},\n",
       "  {u'scores': [2.671817064285278]},\n",
       "  {u'scores': [3.674085855484009]},\n",
       "  {u'scores': [2.842851638793945]},\n",
       "  {u'scores': [4.037326812744141]},\n",
       "  {u'scores': [3.212462902069092]},\n",
       "  {u'scores': [3.828480958938599]},\n",
       "  {u'scores': [3.313096761703491]},\n",
       "  {u'scores': [3.077396154403687]},\n",
       "  {u'scores': [3.524663209915161]},\n",
       "  {u'scores': [2.18705940246582]},\n",
       "  {u'scores': [2.796448707580566]},\n",
       "  {u'scores': [3.069734573364258]},\n",
       "  {u'scores': [3.715287685394287]},\n",
       "  {u'scores': [3.661990880966186]},\n",
       "  {u'scores': [4.135562419891357]},\n",
       "  {u'scores': [3.75812578201294]},\n",
       "  {u'scores': [3.295779705047607]},\n",
       "  {u'scores': [3.698301553726196]},\n",
       "  {u'scores': [4.500328540802002]},\n",
       "  {u'scores': [3.337789058685303]},\n",
       "  {u'scores': [3.981830358505249]},\n",
       "  {u'scores': [4.017118453979492]},\n",
       "  {u'scores': [3.246878623962402]},\n",
       "  {u'scores': [2.623090505599976]},\n",
       "  {u'scores': [3.364887475967407]},\n",
       "  {u'scores': [4.056102275848389]},\n",
       "  {u'scores': [3.125406265258789]},\n",
       "  {u'scores': [3.714457035064697]},\n",
       "  {u'scores': [3.324756860733032]},\n",
       "  {u'scores': [4.011790752410889]},\n",
       "  {u'scores': [3.482729911804199]},\n",
       "  {u'scores': [2.476569414138794]},\n",
       "  {u'scores': [3.247444868087769]},\n",
       "  {u'scores': [3.752398014068604]},\n",
       "  {u'scores': [2.987919092178345]},\n",
       "  {u'scores': [3.400344610214233]},\n",
       "  {u'scores': [3.006385803222656]},\n",
       "  {u'scores': [3.111745834350586]},\n",
       "  {u'scores': [2.70302414894104]},\n",
       "  {u'scores': [4.584415435791016]},\n",
       "  {u'scores': [3.358502864837646]},\n",
       "  {u'scores': [3.322365522384644]},\n",
       "  {u'scores': [3.516035556793213]},\n",
       "  {u'scores': [4.236436367034912]},\n",
       "  {u'scores': [3.217010498046875]},\n",
       "  {u'scores': [3.796750068664551]},\n",
       "  {u'scores': [3.6587815284729]},\n",
       "  {u'scores': [2.838878631591797]},\n",
       "  {u'scores': [3.5328049659729]},\n",
       "  {u'scores': [4.83570146560669]},\n",
       "  {u'scores': [3.304553747177124]},\n",
       "  {u'scores': [3.920702934265137]},\n",
       "  {u'scores': [2.400350570678711]},\n",
       "  {u'scores': [4.444090366363525]},\n",
       "  {u'scores': [4.08622407913208]},\n",
       "  {u'scores': [3.622132301330566]},\n",
       "  {u'scores': [3.485400676727295]},\n",
       "  {u'scores': [3.322454929351807]},\n",
       "  {u'scores': [4.42795467376709]},\n",
       "  {u'scores': [3.437130928039551]},\n",
       "  {u'scores': [4.61285400390625]},\n",
       "  {u'scores': [4.174943447113037]},\n",
       "  {u'scores': [1.860476016998291]},\n",
       "  {u'scores': [3.667826175689697]},\n",
       "  {u'scores': [3.449964046478272]},\n",
       "  {u'scores': [3.130271434783936]},\n",
       "  {u'scores': [2.176640033721924]},\n",
       "  {u'scores': [2.813016653060913]},\n",
       "  {u'scores': [3.489655494689941]},\n",
       "  {u'scores': [4.241312026977539]},\n",
       "  {u'scores': [3.168469667434692]},\n",
       "  {u'scores': [3.860477685928345]},\n",
       "  {u'scores': [4.08411979675293]},\n",
       "  {u'scores': [4.141995906829834]},\n",
       "  {u'scores': [4.915980815887451]},\n",
       "  {u'scores': [4.822662830352783]},\n",
       "  {u'scores': [3.762869358062744]},\n",
       "  {u'scores': [2.981823682785034]},\n",
       "  {u'scores': [4.437747478485107]},\n",
       "  {u'scores': [3.555580139160156]},\n",
       "  {u'scores': [3.475320100784302]},\n",
       "  {u'scores': [3.951285362243652]},\n",
       "  {u'scores': [4.726358890533447]},\n",
       "  {u'scores': [3.207788467407227]},\n",
       "  {u'scores': [3.397644996643066]},\n",
       "  {u'scores': [3.117740869522095]},\n",
       "  {u'scores': [3.45724630355835]},\n",
       "  {u'scores': [3.871891260147095]},\n",
       "  {u'scores': [3.259983539581299]},\n",
       "  {u'scores': [3.363545417785644]},\n",
       "  {u'scores': [3.636012554168701]},\n",
       "  {u'scores': [4.048416614532471]},\n",
       "  {u'scores': [3.24199652671814]},\n",
       "  {u'scores': [2.91114091873169]},\n",
       "  {u'scores': [2.505786418914795]},\n",
       "  {u'scores': [3.721383094787598]},\n",
       "  {u'scores': [4.246976375579834]},\n",
       "  {u'scores': [3.332839012145996]},\n",
       "  {u'scores': [4.246397495269775]},\n",
       "  {u'scores': [4.330927848815918]},\n",
       "  {u'scores': [3.554547548294067]},\n",
       "  {u'scores': [3.926952362060547]},\n",
       "  {u'scores': [2.643776893615723]},\n",
       "  {u'scores': [4.805612087249756]},\n",
       "  {u'scores': [3.618998050689697]},\n",
       "  {u'scores': [3.562024116516113]},\n",
       "  {u'scores': [3.945876121520996]},\n",
       "  {u'scores': [2.986503601074219]},\n",
       "  {u'scores': [3.831458568572998]},\n",
       "  {u'scores': [4.068986415863037]},\n",
       "  {u'scores': [4.117616176605225]},\n",
       "  {u'scores': [3.210430145263672]},\n",
       "  {u'scores': [4.200994491577148]},\n",
       "  {u'scores': [3.665982723236084]},\n",
       "  {u'scores': [4.091421127319336]},\n",
       "  {u'scores': [3.712700843811035]},\n",
       "  {u'scores': [3.219818592071533]},\n",
       "  {u'scores': [2.889273643493652]},\n",
       "  {u'scores': [3.493680477142334]},\n",
       "  {u'scores': [3.403697490692139]},\n",
       "  {u'scores': [4.838586330413818]},\n",
       "  {u'scores': [3.629873037338257]},\n",
       "  {u'scores': [2.703352689743042]},\n",
       "  {u'scores': [3.385695695877075]},\n",
       "  {u'scores': [3.197499752044678]},\n",
       "  {u'scores': [4.526412487030029]},\n",
       "  {u'scores': [3.469201564788818]},\n",
       "  {u'scores': [3.305745363235474]},\n",
       "  {u'scores': [3.930477142333984]},\n",
       "  {u'scores': [3.850676774978638]},\n",
       "  {u'scores': [3.359582901000977]},\n",
       "  {u'scores': [3.788987159729004]},\n",
       "  {u'scores': [3.912787437438965]},\n",
       "  {u'scores': [4.235611915588379]},\n",
       "  {u'scores': [3.825679302215576]},\n",
       "  {u'scores': [3.954121112823486]},\n",
       "  {u'scores': [2.466495275497436]},\n",
       "  {u'scores': [3.383146286010742]},\n",
       "  {u'scores': [3.694513559341431]},\n",
       "  {u'scores': [2.590495586395264]},\n",
       "  {u'scores': [2.394452810287476]},\n",
       "  {u'scores': [3.040476322174072]},\n",
       "  {u'scores': [1.240776419639587]},\n",
       "  {u'scores': [3.778498411178589]},\n",
       "  {u'scores': [3.181265830993652]},\n",
       "  {u'scores': [3.387881755828857]},\n",
       "  {u'scores': [4.320937633514404]},\n",
       "  {u'scores': [2.635511875152588]},\n",
       "  {u'scores': [3.403976440429688]},\n",
       "  {u'scores': [4.677227020263672]},\n",
       "  {u'scores': [1.315490961074829]},\n",
       "  {u'scores': [3.612713098526001]},\n",
       "  {u'scores': [3.058351039886475]},\n",
       "  {u'scores': [3.187630176544189]},\n",
       "  {u'scores': [3.487588882446289]},\n",
       "  {u'scores': [4.325321674346924]},\n",
       "  {u'scores': [3.995596647262573]},\n",
       "  {u'scores': [2.573298931121826]},\n",
       "  {u'scores': [4.355963706970215]},\n",
       "  {u'scores': [3.131378889083862]},\n",
       "  {u'scores': [3.273953676223755]},\n",
       "  {u'scores': [2.197684049606323]},\n",
       "  {u'scores': [4.162347316741943]},\n",
       "  {u'scores': [4.086633205413818]},\n",
       "  {u'scores': [4.736922740936279]},\n",
       "  {u'scores': [4.222404956817627]},\n",
       "  {u'scores': [3.268857717514038]},\n",
       "  {u'scores': [3.270190000534058]},\n",
       "  {u'scores': [3.184884786605835]},\n",
       "  {u'scores': [3.39448881149292]},\n",
       "  {u'scores': [3.674741744995117]},\n",
       "  {u'scores': [2.722317695617676]},\n",
       "  {u'scores': [3.666576862335205]},\n",
       "  {u'scores': [2.846333503723144]},\n",
       "  {u'scores': [3.049558639526367]},\n",
       "  {u'scores': [3.324144601821899]},\n",
       "  {u'scores': [2.956636905670166]},\n",
       "  {u'scores': [3.632115840911865]},\n",
       "  {u'scores': [2.547682046890259]},\n",
       "  {u'scores': [2.525599956512451]},\n",
       "  {u'scores': [2.924408912658691]},\n",
       "  {u'scores': [3.932104349136352]},\n",
       "  {u'scores': [3.220569610595703]},\n",
       "  {u'scores': [4.413779258728027]},\n",
       "  {u'scores': [3.23172116279602]},\n",
       "  {u'scores': [4.147444248199463]},\n",
       "  {u'scores': [1.702193140983582]},\n",
       "  {u'scores': [4.605425834655762]},\n",
       "  {u'scores': [3.191759586334228]},\n",
       "  {u'scores': [2.358987331390381]},\n",
       "  {u'scores': [3.760976791381836]},\n",
       "  {u'scores': [4.922826290130615]},\n",
       "  {u'scores': [2.718914031982422]},\n",
       "  {u'scores': [2.686295747756958]},\n",
       "  {u'scores': [3.49116587638855]},\n",
       "  {u'scores': [3.771432876586914]},\n",
       "  {u'scores': [4.318438053131104]},\n",
       "  {u'scores': [4.416956901550293]},\n",
       "  {u'scores': [3.050653457641602]},\n",
       "  {u'scores': [3.110618352890015]},\n",
       "  {u'scores': [4.396115779876709]},\n",
       "  {u'scores': [3.78007698059082]},\n",
       "  {u'scores': [4.933557987213135]},\n",
       "  {u'scores': [4.354561805725098]},\n",
       "  {u'scores': [3.155969619750977]},\n",
       "  {u'scores': [4.5368971824646]},\n",
       "  {u'scores': [4.154934883117676]},\n",
       "  {u'scores': [4.031212329864502]},\n",
       "  {u'scores': [2.964437484741211]},\n",
       "  {u'scores': [3.553437948226929]},\n",
       "  {u'scores': [3.284250974655151]},\n",
       "  {u'scores': [3.055984020233154]},\n",
       "  {u'scores': [3.287974834442139]},\n",
       "  {u'scores': [3.721853017807007]},\n",
       "  {u'scores': [3.831449747085571]},\n",
       "  {u'scores': [2.960166454315186]},\n",
       "  {u'scores': [3.115450859069824]},\n",
       "  {u'scores': [3.457126617431641]},\n",
       "  {u'scores': [2.71073055267334]},\n",
       "  {u'scores': [3.316432952880859]},\n",
       "  {u'scores': [3.227840662002563]},\n",
       "  {u'scores': [4.905457973480225]},\n",
       "  {u'scores': [2.715712547302246]},\n",
       "  {u'scores': [3.124344348907471]},\n",
       "  {u'scores': [4.119280815124512]},\n",
       "  {u'scores': [3.059254169464111]},\n",
       "  {u'scores': [3.536991119384766]},\n",
       "  {u'scores': [2.937248706817627]},\n",
       "  {u'scores': [3.671218156814575]},\n",
       "  {u'scores': [4.609721183776856]},\n",
       "  ...]}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison against popular libraries\n",
    "\n",
    "Below we provide a chart that compares the performance of *Object2Vec* against several algorithms implemented by popular recommendation system libraries (LibRec https://www.librec.net/ and scikit-surprise http://surpriselib.com/). The error metric we use in the chart is **root mean squared** (RMSE) instead of MSE, so that our result can be compared against the reported results in the aforementioned libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/ml-experiment-plot.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation task \n",
    "\n",
    "In this section, we showcase how to use *Object2Vec* to recommend movies, using the binarized rating labels. Here, if a movie rating label for a given user is binarized to `1`, then it means that the movie should be recommended to the user; otherwise, the label is binarized to `0`. The binarized data set is already obtained in the preprocessing section, so we will proceed to apply the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created train_c.jsonl jsonline file\n",
      "Created validation_c.jsonl jsonline file\n"
     ]
    }
   ],
   "source": [
    "## Save training and validation data locally for recommendation (classification) task\n",
    "\n",
    "### binarize the data \n",
    "\n",
    "train_c = cu.get_binarized_label(copy.deepcopy(train_data_list), 3.0)\n",
    "valid_c = cu.get_binarized_label(copy.deepcopy(validation_data_list), 3.0)\n",
    "\n",
    "cu.write_data_list_to_jsonl(train_c, 'train_c.jsonl')\n",
    "cu.write_data_list_to_jsonl(valid_c, 'validation_c.jsonl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We check whether the two classes are balanced after binarization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 fraction of positive ratings in train_c.jsonl\n",
      "There are 0 fraction of positive ratings in validation_c.jsonl\n"
     ]
    }
   ],
   "source": [
    "train_c_label = [row['label'] for row in train_c]\n",
    "valid_c_label = [row['label'] for row in valid_c]\n",
    "\n",
    "print(\"There are {} fraction of positive ratings in train_c.jsonl\".format(\n",
    "                                np.count_nonzero(train_c_label)/len(train_c_label)))\n",
    "print(\"There are {} fraction of positive ratings in validation_c.jsonl\".format(\n",
    "                                np.sum(valid_c_label)/len(valid_c_label)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We upload the binarized datasets for classification task to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded data to s3://sagemaker-ap-southeast-1-349934754982/object2vec/movielens/input/recommendation/train/train_c.jsonl\n",
      "Uploaded data to s3://sagemaker-ap-southeast-1-349934754982/object2vec/movielens/input/recommendation/validation/validation_c.jsonl\n"
     ]
    }
   ],
   "source": [
    "for data_name in ['train', 'validation']:\n",
    "    fname = '{}_c.jsonl'.format(data_name)\n",
    "    pre_key = os.path.join(input_prefix, 'recommendation', str(data_name))\n",
    "    data_path = os.path.join('s3://', bucket, pre_key, fname)\n",
    "    s3_client.upload_file(fname, bucket, os.path.join(pre_key, fname))\n",
    "    input_paths[data_name] = s3_input(data_path, distribution='ShardedByS3Key', content_type='application/jsonlines')\n",
    "    print('Uploaded data to {}'.format(data_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we already get the algorithm image from the regression task, we can directly start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.session import s3_input\n",
    "\n",
    "hyperparameters_c = {\n",
    "    \"_kvstore\": \"device\",\n",
    "    \"_num_gpus\": \"auto\",\n",
    "    \"_num_kv_servers\": \"auto\",\n",
    "    \"bucket_width\": 0,\n",
    "    \"early_stopping_patience\": 3, \n",
    "    \"early_stopping_tolerance\": 0.01,\n",
    "    \"enc0_cnn_filter_width\": 3,\n",
    "    \"enc0_layers\": \"auto\",\n",
    "    \"enc0_max_seq_len\": 1,\n",
    "    \"enc0_network\": \"pooled_embedding\",\n",
    "    \"enc0_token_embedding_dim\": 300,\n",
    "    \"enc0_vocab_size\": 944,\n",
    "    \"enc1_cnn_filter_width\": 3,\n",
    "    \"enc1_layers\": \"auto\",\n",
    "    \"enc1_max_seq_len\": 1,\n",
    "    \"enc1_network\": \"pooled_embedding\",\n",
    "    \"enc1_token_embedding_dim\": 300,\n",
    "    \"enc1_vocab_size\": 1684,\n",
    "    \"enc_dim\": 2048,\n",
    "    \"epochs\": 20,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"mini_batch_size\": 2048,\n",
    "    \"mlp_activation\": \"relu\",\n",
    "    \"mlp_dim\": 1024,\n",
    "    \"mlp_layers\": 1,\n",
    "    \"num_classes\": 2,\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"output_layer\": \"softmax\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-29 19:04:59 Starting - Starting the training job...\n",
      "2019-10-29 19:05:02 Starting - Launching requested ML instances......\n",
      "2019-10-29 19:06:04 Starting - Preparing the instances for training......\n",
      "2019-10-29 19:07:30 Downloading - Downloading input data\n",
      "2019-10-29 19:07:30 Training - Downloading the training image.....\u001b[31mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:09 INFO 139683723773760] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/default-input.json: {u'comparator_list': u'hadamard, concat, abs_diff', u'enc0_vocab_file': u'', u'output_layer': u'softmax', u'enc0_cnn_filter_width': 3, u'epochs': 30, u'mlp_dim': 512, u'enc0_freeze_pretrained_embedding': u'true', u'mlp_layers': 2, u'_num_kv_servers': u'auto', u'weight_decay': 0, u'enc0_pretrained_embedding_file': u'', u'token_embedding_storage_type': u'dense', u'enc0_token_embedding_dim': 300, u'tied_token_embedding_weight': u'false', u'learning_rate': 0.0004, u'enc1_cnn_filter_width': 3, u'negative_sampling_rate': 0, u'enc0_network': u'hcnn', u'enc1_layers': u'auto', u'early_stopping_patience': 3, u'optimizer': u'adam', u'_tuning_objective_metric': u'', u'early_stopping_tolerance': 0.01, u'dropout': 0, u'bucket_width': 0, u'enc_dim': 4096, u'enc1_vocab_file': u'', u'enc1_freeze_pretrained_embedding': u'true', u'enc0_layers': u'auto', u'mini_batch_size': 32, u'enc1_pretrained_embedding_file': u'', u'num_classes': 2, u'_num_gpus': u'auto', u'enc1_token_embedding_dim': 300, u'mlp_activation': u'linear', u'enc1_network': u'enc0', u'_kvstore': u'auto_gpu'}\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:09 INFO 139683723773760] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'output_layer': u'softmax', u'enc0_cnn_filter_width': u'3', u'epochs': u'20', u'mlp_dim': u'1024', u'mlp_layers': u'1', u'_num_kv_servers': u'auto', u'mini_batch_size': u'2048', u'enc0_token_embedding_dim': u'300', u'enc1_network': u'pooled_embedding', u'early_stopping_tolerance': u'0.01', u'enc0_network': u'pooled_embedding', u'enc1_layers': u'auto', u'early_stopping_patience': u'3', u'optimizer': u'adam', u'enc1_max_seq_len': u'1', u'enc1_cnn_filter_width': u'3', u'learning_rate': u'0.001', u'bucket_width': u'0', u'enc_dim': u'2048', u'enc0_layers': u'auto', u'enc0_max_seq_len': u'1', u'num_classes': u'2', u'_num_gpus': u'auto', u'mlp_activation': u'relu', u'enc1_token_embedding_dim': u'300', u'_kvstore': u'device', u'enc1_vocab_size': u'1684', u'enc0_vocab_size': u'944'}\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:09 INFO 139683723773760] Final configuration: {u'comparator_list': u'hadamard, concat, abs_diff', u'enc0_vocab_file': u'', u'output_layer': u'softmax', u'enc0_cnn_filter_width': u'3', u'epochs': u'20', u'mlp_dim': u'1024', u'enc0_freeze_pretrained_embedding': u'true', u'mlp_layers': u'1', u'_num_kv_servers': u'auto', u'weight_decay': 0, u'enc0_pretrained_embedding_file': u'', u'enc0_max_seq_len': u'1', u'token_embedding_storage_type': u'dense', u'enc0_token_embedding_dim': u'300', u'tied_token_embedding_weight': u'false', u'learning_rate': u'0.001', u'enc1_cnn_filter_width': u'3', u'negative_sampling_rate': 0, u'enc0_network': u'pooled_embedding', u'enc1_layers': u'auto', u'early_stopping_patience': u'3', u'optimizer': u'adam', u'enc1_max_seq_len': u'1', u'_tuning_objective_metric': u'', u'early_stopping_tolerance': u'0.01', u'dropout': 0, u'bucket_width': u'0', u'enc_dim': u'2048', u'enc1_vocab_file': u'', u'enc1_freeze_pretrained_embedding': u'true', u'enc0_layers': u'auto', u'mini_batch_size': u'2048', u'enc1_pretrained_embedding_file': u'', u'num_classes': u'2', u'_num_gpus': u'auto', u'enc1_token_embedding_dim': u'300', u'mlp_activation': u'relu', u'enc1_network': u'pooled_embedding', u'_kvstore': u'device', u'enc1_vocab_size': u'1684', u'enc0_vocab_size': u'944'}\u001b[0m\n",
      "\u001b[31mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:09 INFO 139683723773760] Using default worker.\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:09 INFO 139683723773760] Loaded iterator creator application/jsonlines for content type ('application/jsonlines', '1.0')\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:09 INFO 139683723773760] create_iter params {u'comparator_list': u'hadamard, concat, abs_diff', u'enc0_vocab_file': u'', u'output_layer': u'softmax', u'enc0_cnn_filter_width': u'3', u'epochs': u'20', u'mlp_dim': u'1024', u'enc0_freeze_pretrained_embedding': u'true', u'mlp_layers': u'1', u'_num_kv_servers': u'auto', u'weight_decay': 0, u'enc0_pretrained_embedding_file': u'', u'enc0_max_seq_len': u'1', u'token_embedding_storage_type': u'dense', u'enc0_token_embedding_dim': u'300', u'tied_token_embedding_weight': u'false', u'learning_rate': u'0.001', u'enc1_cnn_filter_width': u'3', u'negative_sampling_rate': 0, u'enc0_network': u'pooled_embedding', u'enc1_layers': u'auto', u'early_stopping_patience': u'3', u'optimizer': u'adam', u'enc1_max_seq_len': u'1', u'_tuning_objective_metric': u'', u'early_stopping_tolerance': u'0.01', u'dropout': 0, u'bucket_width': u'0', u'enc_dim': u'2048', u'enc1_vocab_file': u'', u'enc1_freeze_pretrained_embedding': u'true', u'enc0_layers': u'auto', u'mini_batch_size': u'2048', u'enc1_pretrained_embedding_file': u'', u'num_classes': u'2', u'_num_gpus': u'auto', u'enc1_token_embedding_dim': u'300', u'mlp_activation': u'relu', u'enc1_network': u'pooled_embedding', u'_kvstore': u'device', u'enc1_vocab_size': u'1684', u'enc0_vocab_size': u'944'}\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:09 INFO 139683723773760] create_iter content_params {}\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:09 INFO 139683723773760] Parameters of encoders: [{u'layers': u'auto', u'vocab_size': u'944', u'network': u'pooled_embedding', u'vocab_file': u'', u'cnn_filter_width': u'3', u'token_embedding_dim': u'300', u'max_seq_len': u'1', u'freeze_pretrained_embedding': u'true', u'pretrained_embedding_file': u''}, {u'layers': u'auto', u'vocab_size': u'1684', u'network': u'pooled_embedding', u'vocab_file': u'', u'cnn_filter_width': u'3', u'token_embedding_dim': u'300', u'max_seq_len': u'1', u'freeze_pretrained_embedding': u'true', u'pretrained_embedding_file': u''}]\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:09 INFO 139683723773760] Inconsistent enc_dim and token_embedding_dim found for token-embedding-encoder: 2048 vs 300. Setting token embedding dim to be 2048\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:09 INFO 139683723773760] Inconsistent enc_dim and token_embedding_dim found for token-embedding-encoder: 2048 vs 300. Setting token embedding dim to be 2048\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:09 INFO 139683723773760] Encoder configs: [{'vocab_size': 944, 'enc_index': 0, 'pretrained_embedding_file_path': None, 'vocab_dict': None, 'token_embedding_dim': 2048, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'num_layers': 1, 'is_train': True, 'dropout': 0.0, 'pretrained_embedding_file': ''}, {'vocab_size': 1684, 'enc_index': 1, 'pretrained_embedding_file_path': None, 'vocab_dict': None, 'token_embedding_dim': 2048, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'num_layers': 1, 'is_train': True, 'dropout': 0.0, 'pretrained_embedding_file': ''}]\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:09 INFO 139683723773760] Config: {'comparator_list': ['hadamard', 'concat', 'abs_diff'], 'epochs': 20, 'mini_batch_size': 2048, 'optimizer': 'adam', 'output_layer': 'softmax', 'token_embedding_storage_type': 'dense', 'mlp_dim': 1024, 'early_stopping_tolerance': 0.01, 'dropout': 0.0, 'bucket_width': 0, 'enc_dim': 2048, 'negative_sampling_rate': 0, 'early_stopping_patience': 3, 'learning_rate': 0.001, 'max_seq_lens': [1, 1], 'tied_token_embedding_weight': False, 'enc_configs': [{'vocab_size': 944, 'enc_index': 0, 'pretrained_embedding_file_path': None, 'vocab_dict': None, 'token_embedding_dim': 2048, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'num_layers': 1, 'is_train': True, 'dropout': 0.0, 'pretrained_embedding_file': ''}, {'vocab_size': 1684, 'enc_index': 1, 'pretrained_embedding_file_path': None, 'vocab_dict': None, 'token_embedding_dim': 2048, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'num_layers': 1, 'is_train': True, 'dropout': 0.0, 'pretrained_embedding_file': ''}], 'mlp_layers': 1, 'weight_decay': 0.0, 'mlp_activation': 'relu', 'num_classes': 2}\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:09 INFO 139683723773760] use bucketing: False\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:09 INFO 139683723773760] Creating data iterator for /opt/ml/input/data/train\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:12 INFO 139683723773760] Source words: 90570\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:12 INFO 139683723773760] Target words: 90570\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:12 INFO 139683723773760] Total: 90570 samples in 1 buckets\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:12 INFO 139683723773760] Bucket of (1, 1) : 90570 samples in 44 batches of 2048, approx 2048.0 words/batch\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:12 INFO 139683723773760] 0 sentence pairs discarded\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:12 INFO 139683723773760] fill up mode: replicate\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:12 INFO 139683723773760] \u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:12 INFO 139683723773760] Negative sampling not used\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:12 INFO 139683723773760] Replicating 1590 random sentences from bucket (1, 1) to size it to multiple of 2048\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:12 INFO 139683723773760] Bucket batch sizes: [BucketBatchSize(batch_size=2048, average_words_per_batch=2048)]\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:12 INFO 139683723773760] create_iter params {u'comparator_list': u'hadamard, concat, abs_diff', u'enc0_vocab_file': u'', u'output_layer': u'softmax', u'enc0_cnn_filter_width': u'3', u'epochs': u'20', u'mlp_dim': u'1024', u'enc0_freeze_pretrained_embedding': u'true', u'mlp_layers': u'1', u'_num_kv_servers': u'auto', u'weight_decay': 0, u'enc0_pretrained_embedding_file': u'', u'enc0_max_seq_len': u'1', u'token_embedding_storage_type': u'dense', u'enc0_token_embedding_dim': u'300', u'tied_token_embedding_weight': u'false', u'learning_rate': u'0.001', u'enc1_cnn_filter_width': u'3', u'negative_sampling_rate': 0, u'enc0_network': u'pooled_embedding', u'enc1_layers': u'auto', u'early_stopping_patience': u'3', u'optimizer': u'adam', u'enc1_max_seq_len': u'1', u'_tuning_objective_metric': u'', u'early_stopping_tolerance': u'0.01', u'dropout': 0, u'bucket_width': u'0', u'enc_dim': u'2048', u'enc1_vocab_file': u'', u'enc1_freeze_pretrained_embedding': u'true', u'enc0_layers': u'auto', u'mini_batch_size': u'2048', u'enc1_pretrained_embedding_file': u'', u'num_classes': u'2', u'_num_gpus': u'auto', u'enc1_token_embedding_dim': u'300', u'mlp_activation': u'relu', u'enc1_network': u'pooled_embedding', u'_kvstore': u'device', u'enc1_vocab_size': u'1684', u'enc0_vocab_size': u'944'}\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:12 INFO 139683723773760] create_iter content_params {}\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:12 INFO 139683723773760] Parameters of encoders: [{u'layers': u'auto', u'vocab_size': u'944', u'network': u'pooled_embedding', u'vocab_file': u'', u'cnn_filter_width': u'3', u'token_embedding_dim': u'300', u'max_seq_len': u'1', u'freeze_pretrained_embedding': u'true', u'pretrained_embedding_file': u''}, {u'layers': u'auto', u'vocab_size': u'1684', u'network': u'pooled_embedding', u'vocab_file': u'', u'cnn_filter_width': u'3', u'token_embedding_dim': u'300', u'max_seq_len': u'1', u'freeze_pretrained_embedding': u'true', u'pretrained_embedding_file': u''}]\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:12 INFO 139683723773760] Inconsistent enc_dim and token_embedding_dim found for token-embedding-encoder: 2048 vs 300. Setting token embedding dim to be 2048\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:12 INFO 139683723773760] Inconsistent enc_dim and token_embedding_dim found for token-embedding-encoder: 2048 vs 300. Setting token embedding dim to be 2048\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:12 INFO 139683723773760] Encoder configs: [{'vocab_size': 944, 'enc_index': 0, 'pretrained_embedding_file_path': None, 'vocab_dict': None, 'token_embedding_dim': 2048, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'num_layers': 1, 'is_train': True, 'dropout': 0.0, 'pretrained_embedding_file': ''}, {'vocab_size': 1684, 'enc_index': 1, 'pretrained_embedding_file_path': None, 'vocab_dict': None, 'token_embedding_dim': 2048, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'num_layers': 1, 'is_train': True, 'dropout': 0.0, 'pretrained_embedding_file': ''}]\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:12 INFO 139683723773760] Config: {'comparator_list': ['hadamard', 'concat', 'abs_diff'], 'epochs': 20, 'mini_batch_size': 2048, 'optimizer': 'adam', 'output_layer': 'softmax', 'token_embedding_storage_type': 'dense', 'mlp_dim': 1024, 'early_stopping_tolerance': 0.01, 'dropout': 0.0, 'bucket_width': 0, 'enc_dim': 2048, 'negative_sampling_rate': 0, 'early_stopping_patience': 3, 'learning_rate': 0.001, 'max_seq_lens': [1, 1], 'tied_token_embedding_weight': False, 'enc_configs': [{'vocab_size': 944, 'enc_index': 0, 'pretrained_embedding_file_path': None, 'vocab_dict': None, 'token_embedding_dim': 2048, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'num_layers': 1, 'is_train': True, 'dropout': 0.0, 'pretrained_embedding_file': ''}, {'vocab_size': 1684, 'enc_index': 1, 'pretrained_embedding_file_path': None, 'vocab_dict': None, 'token_embedding_dim': 2048, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'num_layers': 1, 'is_train': True, 'dropout': 0.0, 'pretrained_embedding_file': ''}], 'mlp_layers': 1, 'weight_decay': 0.0, 'mlp_activation': 'relu', 'num_classes': 2}\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:12 INFO 139683723773760] use bucketing: False\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:12 INFO 139683723773760] Creating data iterator for /opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:12 INFO 139683723773760] Source words: 9430\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:12 INFO 139683723773760] Target words: 9430\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:12 INFO 139683723773760] Total: 9430 samples in 1 buckets\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:12 INFO 139683723773760] Bucket of (1, 1) : 9430 samples in 4 batches of 2048, approx 2048.0 words/batch\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:12 INFO 139683723773760] 0 sentence pairs discarded\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:12 INFO 139683723773760] fill up mode: replicate\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:12 INFO 139683723773760] \u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:12 INFO 139683723773760] Negative sampling not used\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:12 INFO 139683723773760] Replicating 810 random sentences from bucket (1, 1) to size it to multiple of 2048\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:12 INFO 139683723773760] Parameters of encoders: [{u'layers': u'auto', u'vocab_size': u'944', u'network': u'pooled_embedding', u'vocab_file': u'', u'cnn_filter_width': u'3', u'token_embedding_dim': u'300', u'max_seq_len': u'1', u'freeze_pretrained_embedding': u'true', u'pretrained_embedding_file': u''}, {u'layers': u'auto', u'vocab_size': u'1684', u'network': u'pooled_embedding', u'vocab_file': u'', u'cnn_filter_width': u'3', u'token_embedding_dim': u'300', u'max_seq_len': u'1', u'freeze_pretrained_embedding': u'true', u'pretrained_embedding_file': u''}]\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:12 INFO 139683723773760] Inconsistent enc_dim and token_embedding_dim found for token-embedding-encoder: 2048 vs 300. Setting token embedding dim to be 2048\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:12 INFO 139683723773760] Inconsistent enc_dim and token_embedding_dim found for token-embedding-encoder: 2048 vs 300. Setting token embedding dim to be 2048\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:12 INFO 139683723773760] Encoder configs: [{'vocab_size': 944, 'enc_index': 0, 'pretrained_embedding_file_path': None, 'vocab_dict': None, 'token_embedding_dim': 2048, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'num_layers': 1, 'is_train': True, 'dropout': 0.0, 'pretrained_embedding_file': ''}, {'vocab_size': 1684, 'enc_index': 1, 'pretrained_embedding_file_path': None, 'vocab_dict': None, 'token_embedding_dim': 2048, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'num_layers': 1, 'is_train': True, 'dropout': 0.0, 'pretrained_embedding_file': ''}]\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:12 INFO 139683723773760] Config: {'comparator_list': ['hadamard', 'concat', 'abs_diff'], 'epochs': 20, 'mini_batch_size': 2048, 'optimizer': 'adam', 'output_layer': 'softmax', 'token_embedding_storage_type': 'dense', 'mlp_dim': 1024, 'early_stopping_tolerance': 0.01, 'dropout': 0.0, 'bucket_width': 0, 'enc_dim': 2048, 'negative_sampling_rate': 0, 'early_stopping_patience': 3, 'learning_rate': 0.001, 'max_seq_lens': [1, 1], 'tied_token_embedding_weight': False, 'enc_configs': [{'vocab_size': 944, 'enc_index': 0, 'pretrained_embedding_file_path': None, 'vocab_dict': None, 'token_embedding_dim': 2048, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'num_layers': 1, 'is_train': True, 'dropout': 0.0, 'pretrained_embedding_file': ''}, {'vocab_size': 1684, 'enc_index': 1, 'pretrained_embedding_file_path': None, 'vocab_dict': None, 'token_embedding_dim': 2048, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'num_layers': 1, 'is_train': True, 'dropout': 0.0, 'pretrained_embedding_file': ''}], 'mlp_layers': 1, 'weight_decay': 0.0, 'mlp_activation': 'relu', 'num_classes': 2}\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:12 INFO 139683723773760] Creating new state\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:12 INFO 139683723773760] params {u'comparator_list': u'hadamard, concat, abs_diff', u'enc0_vocab_file': u'', u'output_layer': u'softmax', u'enc0_cnn_filter_width': u'3', u'epochs': u'20', u'mlp_dim': u'1024', u'enc0_freeze_pretrained_embedding': u'true', u'mlp_layers': u'1', u'_num_kv_servers': u'auto', u'weight_decay': 0, u'enc0_pretrained_embedding_file': u'', u'enc0_max_seq_len': u'1', u'token_embedding_storage_type': u'dense', u'enc0_token_embedding_dim': u'300', u'tied_token_embedding_weight': u'false', u'learning_rate': u'0.001', u'enc1_cnn_filter_width': u'3', u'negative_sampling_rate': 0, u'enc0_network': u'pooled_embedding', u'enc1_layers': u'auto', u'early_stopping_patience': u'3', u'optimizer': u'adam', u'enc1_max_seq_len': u'1', u'_tuning_objective_metric': u'', u'early_stopping_tolerance': u'0.01', u'dropout': 0, u'bucket_width': u'0', u'enc_dim': u'2048', 'default_bucket_key': (1, 1), u'enc1_vocab_file': u'', u'enc1_freeze_pretrained_embedding': u'true', u'enc0_layers': u'auto', u'mini_batch_size': u'2048', u'enc1_pretrained_embedding_file': u'', u'num_classes': u'2', u'_num_gpus': u'auto', u'enc1_token_embedding_dim': u'300', u'mlp_activation': u'relu', u'enc1_network': u'pooled_embedding', u'_kvstore': u'device', u'enc1_vocab_size': u'1684', u'enc0_vocab_size': u'944'}\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:12 INFO 139683723773760] default_bucket_key (1, 1)\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:12 INFO 139683723773760] nvidia-smi took: 0.0251839160919 secs to identify 1 gpus\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:12 INFO 139683723773760] Number of GPUs being used: 1\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:12 INFO 139683723773760] context [gpu(0)]\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:12 INFO 139683723773760] Create Store: device\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:12 INFO 139683723773760] Number of GPUs being used: 1\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:12 WARNING 139683723773760] dense token embedding is used in a multi-gpu setting...consider changing 'token_embedding_storage_type' to 'row_sparse'\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:12 INFO 139683723773760] data_names: ['source', 'target']\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:12 INFO 139683723773760] label_names: ['out_layer_label']\u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mLayer (type)                                        Output Shape            Param #     Previous Layer                  \u001b[0m\n",
      "\u001b[31m========================================================================================================================\u001b[0m\n",
      "\u001b[31msource(null)                                        1                       0                                           \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31membed_0(Embedding)                                  1x2048                  0           source                          \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31m_not_equal_scalar0(_not_equal_scalar)               1                       0           source                          \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mreshape0(Reshape)                                   1x1                     0           _not_equal_scalar0              \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mbroadcast_mul0(broadcast_mul)                       1x2048                  0           embed_0                         \n",
      "                                                                                        reshape0                        \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31msum0(sum)                                           2048                    0           broadcast_mul0                  \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31msum1(sum)                                           1                       0           reshape0                        \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mzeros_like0(zeros_like)                             1                       0           sum1                            \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31m_equal0(_equal)                                     1                       0           sum1                            \n",
      "                                                                                        zeros_like0                     \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31m_plus0(elemwise_add)                                1                       0           sum1                            \n",
      "                                                                                        _equal0                         \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mbroadcast_div0(broadcast_div)                       2048                    0           sum0                            \n",
      "                                                                                        _plus0                          \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mdropout0(Dropout)                                   2048                    0           broadcast_div0                  \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31membed_1(Embedding)                                  1x2048                  0                                           \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31m_not_equal_scalar1(_not_equal_scalar)               1                       0                                           \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mreshape1(Reshape)                                   1x1                     0           _not_equal_scalar1              \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mbroadcast_mul1(broadcast_mul)                       1x2048                  0           embed_1                         \n",
      "                                                                                        reshape1                        \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31msum2(sum)                                           2048                    0           broadcast_mul1                  \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31msum3(sum)                                           1                       0           reshape1                        \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mzeros_like1(zeros_like)                             1                       0           sum3                            \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31m_equal1(_equal)                                     1                       0           sum3                            \n",
      "                                                                                        zeros_like1                     \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31m_plus1(elemwise_add)                                1                       0           sum3                            \n",
      "                                                                                        _equal1                         \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mbroadcast_div1(broadcast_div)                       2048                    0           sum2                            \n",
      "                                                                                        _plus1                          \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mdropout1(Dropout)                                   2048                    0           broadcast_div1                  \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31m_mul0(elemwise_mul)                                 2048                    0           dropout0                        \n",
      "                                                                                        dropout1                        \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31m_minus0(elemwise_sub)                               2048                    0           dropout0                        \n",
      "                                                                                        dropout1                        \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mabs0(abs)                                           2048                    0           _minus0                         \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mconcat0(Concat)                                     8192                    0           _mul0                           \n",
      "                                                                                        dropout0                        \n",
      "                                                                                        dropout1                        \n",
      "                                                                                        abs0                            \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mmlp_fc0(FullyConnected)                             1024                    8389632     concat0                         \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mactivation0(Activation)                             1024                    0           mlp_fc0                         \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mdropout2(Dropout)                                   1024                    0           activation0                     \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31moutput_layer(FullyConnected)                        2                       2050        dropout2                        \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mout_layer(SoftmaxOutput)                            2                       0           output_layer                    \u001b[0m\n",
      "\u001b[31m========================================================================================================================\u001b[0m\n",
      "\u001b[31mTotal params: 8391682\u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:12 INFO 139683723773760] data_shapes [DataDesc[source,(2048, 1),<type 'numpy.float32'>,NTC], DataDesc[target,(2048, 1),<type 'numpy.float32'>,NTC]]\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:12 INFO 139683723773760] label_shapes [DataDesc[out_layer_label,(2048,),<type 'numpy.float32'>,NTC]]\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:12 INFO 139683723773760] fixed_param_names: []\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:12 INFO 139683723773760] Initialized BucketingPlus Module\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:17 INFO 139683723773760] arg_params keys for module initialization: []\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:17 INFO 139683723773760] all params:['output_layer_weight', 'mlp_fc0_weight', 'mlp_fc0_bias', 'output_layer_bias', 'embed_1_weight', 'embed_0_weight']\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"initialize.time\": {\"count\": 1, \"max\": 4797.783851623535, \"sum\": 4797.783851623535, \"min\": 4797.783851623535}}, \"EndTime\": 1572376097.594089, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1572376089.659886}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}}, \"EndTime\": 1572376097.594289, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1572376097.594215}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2019-10-29 19:08:06 Training - Training image download completed. Training in progress.\u001b[31m[10/29/2019 19:08:21 INFO 139683723773760] **************\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:21 INFO 139683723773760] Completed Epoch: 0, time taken: 0:00:04.084438\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:21 INFO 139683723773760] Epoch 0 Training metrics:   perplexity: 1.853 cross_entropy: 0.617 accuracy: 0.658 \u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:21 INFO 139683723773760] #quality_metric: host=algo-1, epoch=0, train cross_entropy <loss>=0.616652282079\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:21 INFO 139683723773760] #quality_metric: host=algo-1, epoch=0, train accuracy <score>=0.658289930556\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:22 INFO 139683723773760] Epoch 0 Validation metrics: perplexity: 1.784 cross_entropy: 0.579 accuracy: 0.699 \u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:22 INFO 139683723773760] #quality_metric: host=algo-1, epoch=0, validation cross_entropy <loss>=0.578885519505\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:22 INFO 139683723773760] #quality_metric: host=algo-1, epoch=0, validation accuracy <score>=0.69873046875\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:22 INFO 139683723773760] **************\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"epochs\": {\"count\": 1, \"max\": 20, \"sum\": 20.0, \"min\": 20}, \"early_stop.time\": {\"count\": 1, \"max\": 0.5738735198974609, \"sum\": 0.5738735198974609, \"min\": 0.5738735198974609}, \"update.time\": {\"count\": 1, \"max\": 4202.481985092163, \"sum\": 4202.481985092163, \"min\": 4202.481985092163}}, \"EndTime\": 1572376102.021148, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1572376097.59417}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:22 INFO 139683723773760] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 45, \"sum\": 45.0, \"min\": 45}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 45, \"sum\": 45.0, \"min\": 45}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 92160, \"sum\": 92160.0, \"min\": 92160}, \"Total Batches Seen\": {\"count\": 1, \"max\": 45, \"sum\": 45.0, \"min\": 45}, \"Total Records Seen\": {\"count\": 1, \"max\": 92160, \"sum\": 92160.0, \"min\": 92160}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 92160, \"sum\": 92160.0, \"min\": 92160}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1572376102.021534, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\", \"epoch\": 0}, \"StartTime\": 1572376097.81863}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:22 INFO 139683723773760] #throughput_metric: host=algo-1, train throughput=21926.585039 records/second\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:26 INFO 139683723773760] **************\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:26 INFO 139683723773760] Completed Epoch: 1, time taken: 0:00:04.082282\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:26 INFO 139683723773760] Epoch 1 Training metrics:   perplexity: 1.724 cross_entropy: 0.544 accuracy: 0.721 \u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:26 INFO 139683723773760] #quality_metric: host=algo-1, epoch=1, train cross_entropy <loss>=0.544377018346\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:26 INFO 139683723773760] #quality_metric: host=algo-1, epoch=1, train accuracy <score>=0.720930989583\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:26 INFO 139683723773760] Epoch 1 Validation metrics: perplexity: 1.771 cross_entropy: 0.571 accuracy: 0.702 \u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:26 INFO 139683723773760] #quality_metric: host=algo-1, epoch=1, validation cross_entropy <loss>=0.571497237682\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:26 INFO 139683723773760] #quality_metric: host=algo-1, epoch=1, validation accuracy <score>=0.70205078125\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:26 INFO 139683723773760] **************\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"early_stop.time\": {\"count\": 1, \"max\": 3.2460689544677734, \"sum\": 3.2460689544677734, \"min\": 3.2460689544677734}, \"update.time\": {\"count\": 1, \"max\": 4201.760053634644, \"sum\": 4201.760053634644, \"min\": 4201.760053634644}}, \"EndTime\": 1572376106.301295, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1572376102.021272}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:26 INFO 139683723773760] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 45, \"sum\": 45.0, \"min\": 45}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 45, \"sum\": 45.0, \"min\": 45}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 92160, \"sum\": 92160.0, \"min\": 92160}, \"Total Batches Seen\": {\"count\": 1, \"max\": 90, \"sum\": 90.0, \"min\": 90}, \"Total Records Seen\": {\"count\": 1, \"max\": 184320, \"sum\": 184320.0, \"min\": 184320}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 92160, \"sum\": 92160.0, \"min\": 92160}, \"Reset Count\": {\"count\": 1, \"max\": 2, \"sum\": 2.0, \"min\": 2}}, \"EndTime\": 1572376106.30159, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\", \"epoch\": 1}, \"StartTime\": 1572376102.099508}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:26 INFO 139683723773760] #throughput_metric: host=algo-1, train throughput=21930.9988187 records/second\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:30 INFO 139683723773760] **************\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:30 INFO 139683723773760] Completed Epoch: 2, time taken: 0:00:04.174224\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:30 INFO 139683723773760] Epoch 2 Training metrics:   perplexity: 1.658 cross_entropy: 0.506 accuracy: 0.749 \u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:30 INFO 139683723773760] #quality_metric: host=algo-1, epoch=2, train cross_entropy <loss>=0.505827460024\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:30 INFO 139683723773760] #quality_metric: host=algo-1, epoch=2, train accuracy <score>=0.749294704861\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:30 INFO 139683723773760] Epoch 2 Validation metrics: perplexity: 1.802 cross_entropy: 0.589 accuracy: 0.694 \u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:30 INFO 139683723773760] #quality_metric: host=algo-1, epoch=2, validation cross_entropy <loss>=0.588629579544\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:30 INFO 139683723773760] #quality_metric: host=algo-1, epoch=2, validation accuracy <score>=0.69365234375\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:30 INFO 139683723773760] **************\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"early_stop.time\": {\"count\": 1, \"max\": 0.027179718017578125, \"sum\": 0.027179718017578125, \"min\": 0.027179718017578125}, \"update.time\": {\"count\": 1, \"max\": 4289.453029632568, \"sum\": 4289.453029632568, \"min\": 4289.453029632568}}, \"EndTime\": 1572376110.612292, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1572376106.301371}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:30 INFO 139683723773760] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 45, \"sum\": 45.0, \"min\": 45}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 45, \"sum\": 45.0, \"min\": 45}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 92160, \"sum\": 92160.0, \"min\": 92160}, \"Total Batches Seen\": {\"count\": 1, \"max\": 135, \"sum\": 135.0, \"min\": 135}, \"Total Records Seen\": {\"count\": 1, \"max\": 276480, \"sum\": 276480.0, \"min\": 276480}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 92160, \"sum\": 92160.0, \"min\": 92160}, \"Reset Count\": {\"count\": 1, \"max\": 3, \"sum\": 3.0, \"min\": 3}}, \"EndTime\": 1572376110.612579, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\", \"epoch\": 2}, \"StartTime\": 1572376106.322813}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:30 INFO 139683723773760] #throughput_metric: host=algo-1, train throughput=21482.9534559 records/second\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:34 INFO 139683723773760] **************\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:34 INFO 139683723773760] Completed Epoch: 3, time taken: 0:00:04.084932\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:34 INFO 139683723773760] Epoch 3 Training metrics:   perplexity: 1.407 cross_entropy: 0.342 accuracy: 0.857 \u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:34 INFO 139683723773760] #quality_metric: host=algo-1, epoch=3, train cross_entropy <loss>=0.341699398226\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:34 INFO 139683723773760] #quality_metric: host=algo-1, epoch=3, train accuracy <score>=0.857335069444\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:34 INFO 139683723773760] Epoch 3 Validation metrics: perplexity: 2.068 cross_entropy: 0.727 accuracy: 0.672 \u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:34 INFO 139683723773760] #quality_metric: host=algo-1, epoch=3, validation cross_entropy <loss>=0.726678037643\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:34 INFO 139683723773760] #quality_metric: host=algo-1, epoch=3, validation accuracy <score>=0.671875\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:34 INFO 139683723773760] **************\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:34 INFO 139683723773760] patience losses: [0.5788855195045471, 0.5714972376823425, 0.5886295795440674]\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:34 INFO 139683723773760] min patience losses: 0.571497237682\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:34 INFO 139683723773760] current loss: 0.726678037643\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:34 INFO 139683723773760] absolute loss difference: 0.155180799961\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:34 INFO 139683723773760] Bad epoch: loss has not improved (enough). Bad count:1\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"early_stop.time\": {\"count\": 1, \"max\": 0.4940032958984375, \"sum\": 0.4940032958984375, \"min\": 0.4940032958984375}, \"update.time\": {\"count\": 1, \"max\": 4199.553966522217, \"sum\": 4199.553966522217, \"min\": 4199.553966522217}}, \"EndTime\": 1572376114.816145, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1572376110.612382}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:34 INFO 139683723773760] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 45, \"sum\": 45.0, \"min\": 45}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 45, \"sum\": 45.0, \"min\": 45}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 92160, \"sum\": 92160.0, \"min\": 92160}, \"Total Batches Seen\": {\"count\": 1, \"max\": 180, \"sum\": 180.0, \"min\": 180}, \"Total Records Seen\": {\"count\": 1, \"max\": 368640, \"sum\": 368640.0, \"min\": 368640}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 92160, \"sum\": 92160.0, \"min\": 92160}, \"Reset Count\": {\"count\": 1, \"max\": 4, \"sum\": 4.0, \"min\": 4}}, \"EndTime\": 1572376114.816428, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\", \"epoch\": 3}, \"StartTime\": 1572376110.616573}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:34 INFO 139683723773760] #throughput_metric: host=algo-1, train throughput=21942.9092097 records/second\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:38 INFO 139683723773760] **************\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:38 INFO 139683723773760] Completed Epoch: 4, time taken: 0:00:04.094751\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:38 INFO 139683723773760] Epoch 4 Training metrics:   perplexity: 1.090 cross_entropy: 0.086 accuracy: 0.978 \u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:38 INFO 139683723773760] #quality_metric: host=algo-1, epoch=4, train cross_entropy <loss>=0.0862347765929\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:38 INFO 139683723773760] #quality_metric: host=algo-1, epoch=4, train accuracy <score>=0.978211805556\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:39 INFO 139683723773760] Epoch 4 Validation metrics: perplexity: 2.422 cross_entropy: 0.885 accuracy: 0.687 \u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:39 INFO 139683723773760] #quality_metric: host=algo-1, epoch=4, validation cross_entropy <loss>=0.884527397156\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:39 INFO 139683723773760] #quality_metric: host=algo-1, epoch=4, validation accuracy <score>=0.68662109375\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:39 INFO 139683723773760] **************\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:39 INFO 139683723773760] patience losses: [0.5714972376823425, 0.5886295795440674, 0.7266780376434326]\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:39 INFO 139683723773760] min patience losses: 0.571497237682\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:39 INFO 139683723773760] current loss: 0.884527397156\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:39 INFO 139683723773760] absolute loss difference: 0.313030159473\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:39 INFO 139683723773760] Bad epoch: loss has not improved (enough). Bad count:2\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"early_stop.time\": {\"count\": 1, \"max\": 0.49114227294921875, \"sum\": 0.49114227294921875, \"min\": 0.49114227294921875}, \"update.time\": {\"count\": 1, \"max\": 4210.055112838745, \"sum\": 4210.055112838745, \"min\": 4210.055112838745}}, \"EndTime\": 1572376119.030544, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1572376114.816236}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:39 INFO 139683723773760] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 45, \"sum\": 45.0, \"min\": 45}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 45, \"sum\": 45.0, \"min\": 45}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 92160, \"sum\": 92160.0, \"min\": 92160}, \"Total Batches Seen\": {\"count\": 1, \"max\": 225, \"sum\": 225.0, \"min\": 225}, \"Total Records Seen\": {\"count\": 1, \"max\": 460800, \"sum\": 460800.0, \"min\": 460800}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 92160, \"sum\": 92160.0, \"min\": 92160}, \"Reset Count\": {\"count\": 1, \"max\": 5, \"sum\": 5.0, \"min\": 5}}, \"EndTime\": 1572376119.030839, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\", \"epoch\": 4}, \"StartTime\": 1572376114.820468}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:39 INFO 139683723773760] #throughput_metric: host=algo-1, train throughput=21888.0587083 records/second\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:43 INFO 139683723773760] **************\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:43 INFO 139683723773760] Completed Epoch: 5, time taken: 0:00:04.084169\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:43 INFO 139683723773760] Epoch 5 Training metrics:   perplexity: 1.015 cross_entropy: 0.015 accuracy: 0.998 \u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:43 INFO 139683723773760] #quality_metric: host=algo-1, epoch=5, train cross_entropy <loss>=0.0147698789628\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:43 INFO 139683723773760] #quality_metric: host=algo-1, epoch=5, train accuracy <score>=0.998470052083\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:43 INFO 139683723773760] Epoch 5 Validation metrics: perplexity: 2.779 cross_entropy: 1.022 accuracy: 0.693 \u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:43 INFO 139683723773760] #quality_metric: host=algo-1, epoch=5, validation cross_entropy <loss>=1.02212487459\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:43 INFO 139683723773760] #quality_metric: host=algo-1, epoch=5, validation accuracy <score>=0.6927734375\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:43 INFO 139683723773760] **************\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:43 INFO 139683723773760] patience losses: [0.5886295795440674, 0.7266780376434326, 0.8845273971557617]\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:43 INFO 139683723773760] min patience losses: 0.588629579544\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:43 INFO 139683723773760] current loss: 1.02212487459\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:43 INFO 139683723773760] absolute loss difference: 0.433495295048\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:43 INFO 139683723773760] Bad epoch: loss has not improved (enough). Bad count:3\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"early_stop.time\": {\"count\": 1, \"max\": 0.38504600524902344, \"sum\": 0.38504600524902344, \"min\": 0.38504600524902344}, \"update.time\": {\"count\": 1, \"max\": 4198.048114776611, \"sum\": 4198.048114776611, \"min\": 4198.048114776611}}, \"EndTime\": 1572376123.232876, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1572376119.03064}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:43 INFO 139683723773760] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 45, \"sum\": 45.0, \"min\": 45}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 45, \"sum\": 45.0, \"min\": 45}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 92160, \"sum\": 92160.0, \"min\": 92160}, \"Total Batches Seen\": {\"count\": 1, \"max\": 270, \"sum\": 270.0, \"min\": 270}, \"Total Records Seen\": {\"count\": 1, \"max\": 552960, \"sum\": 552960.0, \"min\": 552960}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 92160, \"sum\": 92160.0, \"min\": 92160}, \"Reset Count\": {\"count\": 1, \"max\": 6, \"sum\": 6.0, \"min\": 6}}, \"EndTime\": 1572376123.233164, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\", \"epoch\": 5}, \"StartTime\": 1572376119.034803}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:43 INFO 139683723773760] #throughput_metric: host=algo-1, train throughput=21950.7070782 records/second\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:47 INFO 139683723773760] **************\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:47 INFO 139683723773760] Completed Epoch: 6, time taken: 0:00:04.090080\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:47 INFO 139683723773760] Epoch 6 Training metrics:   perplexity: 1.003 cross_entropy: 0.003 accuracy: 1.000 \u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:47 INFO 139683723773760] #quality_metric: host=algo-1, epoch=6, train cross_entropy <loss>=0.00323355547152\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:47 INFO 139683723773760] #quality_metric: host=algo-1, epoch=6, train accuracy <score>=0.999978298611\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:47 INFO 139683723773760] Epoch 6 Validation metrics: perplexity: 2.961 cross_entropy: 1.086 accuracy: 0.699 \u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:47 INFO 139683723773760] #quality_metric: host=algo-1, epoch=6, validation cross_entropy <loss>=1.08552434444\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:47 INFO 139683723773760] #quality_metric: host=algo-1, epoch=6, validation accuracy <score>=0.6986328125\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:47 INFO 139683723773760] **************\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:47 INFO 139683723773760] patience losses: [0.7266780376434326, 0.8845273971557617, 1.0221248745918274]\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:47 INFO 139683723773760] min patience losses: 0.726678037643\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:47 INFO 139683723773760] current loss: 1.08552434444\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:47 INFO 139683723773760] absolute loss difference: 0.358846306801\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:47 INFO 139683723773760] Bad epoch: loss has not improved (enough). Bad count:4\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:47 INFO 139683723773760] Bad epochs exceeded patience. Stopping training early!\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:47 INFO 139683723773760] Early stopping criterion met! Stopping training at epoch: 6\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"early_stop.time\": {\"count\": 1, \"max\": 0.6439685821533203, \"sum\": 0.6439685821533203, \"min\": 0.6439685821533203}, \"update.time\": {\"count\": 1, \"max\": 4205.258846282959, \"sum\": 4205.258846282959, \"min\": 4205.258846282959}}, \"EndTime\": 1572376127.442445, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1572376123.23297}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:47 INFO 139683723773760] Early stop condition met. Stopping training.\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:47 INFO 139683723773760] #progress_metric: host=algo-1, completed 100 % epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 45, \"sum\": 45.0, \"min\": 45}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 45, \"sum\": 45.0, \"min\": 45}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 92160, \"sum\": 92160.0, \"min\": 92160}, \"Total Batches Seen\": {\"count\": 1, \"max\": 315, \"sum\": 315.0, \"min\": 315}, \"Total Records Seen\": {\"count\": 1, \"max\": 645120, \"sum\": 645120.0, \"min\": 645120}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 92160, \"sum\": 92160.0, \"min\": 92160}, \"Reset Count\": {\"count\": 1, \"max\": 7, \"sum\": 7.0, \"min\": 7}}, \"EndTime\": 1572376127.442831, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\", \"epoch\": 6}, \"StartTime\": 1572376123.237163}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:47 INFO 139683723773760] #throughput_metric: host=algo-1, train throughput=21912.5916271 records/second\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:47 WARNING 139683723773760] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:47 INFO 139683723773760] Best model based on epoch 1. Best loss: 0.571\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 1.8820762634277344, \"sum\": 1.8820762634277344, \"min\": 1.8820762634277344}}, \"EndTime\": 1572376127.445113, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1572376127.442529}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:47 INFO 139683723773760] Serializing model to /opt/ml/model/model_algo-1\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:47 INFO 139683723773760] Saved checkpoint to \"/tmp/tmpW3N3Tb/state-0001.params\"\u001b[0m\n",
      "\u001b[31m[10/29/2019 19:08:47 INFO 139683723773760] Test data is not provided.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2019-10-29 19:08:53 Uploading - Uploading generated training model\u001b[31m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 38107.52320289612, \"sum\": 38107.52320289612, \"min\": 38107.52320289612}, \"model.serialize.time\": {\"count\": 1, \"max\": 222.04113006591797, \"sum\": 222.04113006591797, \"min\": 222.04113006591797}, \"setuptime\": {\"count\": 1, \"max\": 57.032108306884766, \"sum\": 57.032108306884766, \"min\": 57.032108306884766}}, \"EndTime\": 1572376127.67192, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1572376127.44522}\n",
      "\u001b[0m\n",
      "\n",
      "2019-10-29 19:09:06 Completed - Training job completed\n",
      "Training seconds: 126\n",
      "Billable seconds: 126\n"
     ]
    }
   ],
   "source": [
    "## get estimator\n",
    "classifier = sagemaker.estimator.Estimator(container,\n",
    "                                    role, \n",
    "                                    train_instance_count=1, \n",
    "                                    train_instance_type='ml.p2.xlarge',\n",
    "                                    output_path=output_path,\n",
    "                                    sagemaker_session=sess)\n",
    "\n",
    "## set hyperparameters\n",
    "classifier.set_hyperparameters(**hyperparameters_c)\n",
    "\n",
    "## train, tune, and test the model\n",
    "classifier.fit(input_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we can create, deploy, and validate the model after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "classification_model = classifier.create_model(\n",
    "                        serializer=json_serializer,\n",
    "                        deserializer=json_deserializer,\n",
    "                        content_type='application/json',\n",
    "                        name='recommendationModel')\n",
    "\n",
    "predictor_2 = classification_model.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_c_data, valid_c_label = cu.data_list_to_inference_format(copy.deepcopy(validation_data_list), \n",
    "                                                            label_thres=3, binarize=True)\n",
    "predictions = predictor_2.predict(valid_c_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy on the binarized validation set is 0.703\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"The accuracy on the binarized validation set is %.3f\" %cu.get_class_accuracy(predictions, valid_c_label, 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy on validation set you would get should be approximately 0.704."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the following deletion code after finishing the labs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "## clean up\n",
    "sess.delete_endpoint(predictor.endpoint)\n",
    "sess.delete_endpoint(predictor_2.endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p27",
   "language": "python",
   "name": "conda_mxnet_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
